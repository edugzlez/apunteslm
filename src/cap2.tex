\chapter{Lógica de primer orden}

\section{Introducción}

En el anterior capítulo, construímos con éxito un lenguaje formal que nos permitía traducir frases informales del español a expresiones formales, además de formalizar los conceptos de implicación y equivalencia lógica. Sin embargo, se puede reprochar que la lógica proposicional es demasiado \textit{simple} en el sentido siguiente: $\\$

Consideremos el silogismo: 

\begin{center}
\syllog{Todo hombre es mortal}
{Sócrates es un hombre}
{Sócrates es mortal}
\end{center}

En este caso, podríamos pensar que la consecuencia lógica se trata de una del tipo $p \land (p \rightarrow q) \rightarrow q$. Pero, por otro lado, parece evidente que depende de elementos más básicos que los símbolos de proposición. Sería, entonces, más conveniente una formalización del tipo:

\begin{center}
\syllog{Para todo $x$, si $x$ es hombre entonces es mortal}
{\textit{Sócrates} es hombre}
{\textit{Sócrates} es mortal}
\end{center}

Hemos empleado los términos `hombre', `mortal' y `para todo' en un sentido puramente formal. Como ocurría con las proposiciones, existen múltiples frases y expresiones informales distintas que corresponden al silogismo que acabamos de exponer.$\\$

A continuación vamos a definir, igual que en lógica proposicional, el alfabeto que usaremos para construir fórmulas en los lenguajes de primer orden. Pero además, en este caso, habrá múltiples lenguajes de primer orden, y cada uno tendrá unos ciertos elementos que lo caractericen, que resumimos en el concepto de `signatura':


\begin{comment}
En general, los componentes en los que se pueden reducir las proposiciones son de tres tipos: \textit{constantes}, como `Sócrates' en el ejemplo anterior; \textit{predicados}, como `hombre' y `mortal' en el silogismo anterior y \textit{funciones}, como la función `sucesor de $n$' en los números naturales. De forma similar a como hicimos con los símbolos de proposición, definimos una serie de símbolos para referirnos a las anteriores clases de elementos. Esto nos lleva a la siguiente
\end{comment}

\begin{definition}\label{sig}
Una \textit{signatura} $S$ es una tupla $\langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ donde:
\begin{itemize}
    \item $Ct_{S}$ es el conjunto de símbolos de constante.
    \item $Fn_{S}$ es el conjunto de símbolos de función con determinada aridad\footnote{Por ahora, nos referimos por \textit{aridad} de un símbolo de función o de predicado como el número de argumentos que admite. Más adelante especificaremos lo que significa esta idea.}.
    \item $Pd_{S}$ es el conjunto de símbolos de predicado con determinada aridad.
\end{itemize} 
Dado un símbolo $\Gamma$ de función o predicado, denotamos por $\Gamma|_{n}$ que es $n$-ario.
\end{definition}


\begin{example}\label{nat}
La signatura $Nat := \langle \{0\}, \{+|_2, s|_1\}, \{<|_2\}\rangle$ para los números naturales. Es decir:
\begin{itemize}
    \item Hay un símbolo de constante, $0$.
    \item Los símbolos de función serán el símbolo de función binaria $+$, que llamaremos `suma', y el símbolo de función 1-aria, $s$, que llamaremos `sucesor'.
    \item Tenemos un símbolo de predicado 2-ario, $<$.
\end{itemize}
A veces en la signatura $Nat$ incluiremos un otro símbolo de función 2-aria, $*$, que llamaremos `producto'.
\end{example}

\begin{definition}
Dada la signatura $S$, definimos el alfabeto asociado como:
$$A_{S} := Ct_S \cup Fn_S \cup Pd_S \cup Var \cup \{\neg, \land, \lor, \rightarrow, \leftrightarrow, \top, \bot \} \cup \{(, )\} \cup \{\exists, \forall\} \cup \{ \doteq \},$$
donde:
\begin{itemize}
    \item $Ct_S,Fn_S,Pd_S$ vienen dados por \ref{sig}.
    \item $Var$ son los símbolos de variable: \{$x,y,z,x_1,\dots\}$.
    \item $\neg, \land, \lor, \rightarrow, \leftrightarrow, \top, \bot,(,)$ son los símbolos de conectiva y los paréntesis, al igual que en lógica proposicional.
    \item $\exists$ (para todo) y $\forall$ (existe) son los \textit{cuantificadores lógicos}. Llamamos a $\forall$ \textit{cuantificador universal} y a $\exists$ \textit{cuantificador existencial}.
    \item $\doteq$, el símbolo de igualdad. Usamos $\doteq$ en vez de $=$ para distinguirlo de la igualdad de fórmulas. Por ejemplo, si escribimos $\varphi = t \doteq s$ queremos decir que $\varphi$ es igual a $t \doteq s$.
\end{itemize}

\end{definition}

Como ocurría con las proposiciones, nos interesa distinguir las expresiones del alfabeto anterior que están bien formadas. Para ello, primero necesitaremos definir los \textit{términos}, que podemos interpretar como las expresiones que usaremos para nombrar objetos, y después las \textit{fórmulas}, expresiones que usaremos para denotar afirmaciones sobre los objetos.

\begin{definition}\label{term}
Dada la signatura $S$, el \textit{conjunto de términos} de $S$, $TERM_S$, es el menor subconjunto de $A_{S}^*$ que verifica:\footnote{Recordemos que $A_{S}^*$ es el cierre de Kleene de $A_{S}$, como definimos en \ref{klee}.}
\begin{enumerate}
    \item $Ct_S\subseteq TERM_S$.
    \item $Var\subseteq TERM_S$.
    \item Si $f|_{n} \in Fn_S$ y $t_1, .., t_n \in TERM_S$, entonces $f(t_1, ..., t_n) \in TERM_S$. 
\end{enumerate}
\end{definition}

Si $f$ es una función 2-aria, a veces usaremos la notación tradicional $xfy$ en vez de $f(x,y)$. Por ejemplo, en $Nat$ diremos $x+y$ en vez de $+(x,y)$.

\begin{example}
Siguiendo con la signatura $Nat$, algunos ejemplos de elementos de $TERM_{NAT}$ serían  $0, s(s(0)), x, y, z,+(s(s(0)), s(0))$ y $s(+(x,s(s(s(0)))))$.
\end{example}

La siguiente proposición nos da una definición constructiva de $TERM_S$: 
\begin{prop}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos los conjuntos:
$$T_{S}^{0} := Ct_S \cup Var$$
$$T_{S}^{n+1} := T_{S}^{n} \cup \bigcup\limits_{k \in \mathbb{N}} \{f(t_1, \dots, t_k) \, \, | \, \, t_1, \dots, t_k \in T_{S}^{n}, \, f|_{k} \in Fn_S\}$$
Entonces $\bigcup\limits_{i \in \mathbb{N}} T_{S}^{i} = TERM_S$.
\end{prop}
\begin{proof}
La demostración es análoga a la de \ref{ind}.
\end{proof}

Ahora podemos construir fórmulas a partir de estos elementos básicos que ya hemos definido. Comenzamos por 

\begin{definition}
Dada la signatura $S$, el \textit{conjunto de fórmulas atómicas} de $S$, $FORMAT_S$, es el menor subconjunto de $A_{S}^*$ que verifica:
\begin{enumerate}
    \item Si $t_1, t_2 \in TERM_S$, $t_1 \doteq t_2 \in FORMAT_S$.
    \item Si $R|_{n} \in Pd_S$ y $t_1, \dots, t_n \in TERM_S$, $R(t_1, \dots, t_n) \in FORMAT_S$.
    \item $\top, \bot \in FORMAT_S$.
\end{enumerate}
\end{definition}

Si $R$ es un predicado 2-ario, a veces usaremos la notación tradicional $xRy$ en vez de $R(x,y)$. Por ejemplo, en $Nat$ diremos $x<y$ en vez de $<(x,y)$.

\begin{definition}\label{form}
Dada la signatura $S$, el \textit{conjunto de fórmulas} de $S$, $FORM_S$, es el menor subconjunto de $A_{S}^*$ que verifica:
\begin{enumerate}
    \item $FORMAT_S \subseteq FORM_S$.
    \item Si $\varphi_1, \varphi_2 \in FORM_S$, $(\neg \varphi_1), (\varphi_1 \square \varphi_2) \in FORM_S$.
    \item Si $x \in Var$ y $\varphi \in FORM_S$, $(Qx \, \varphi) \in FORM_S$, siendo $Q\in\{\forall,\exists\}$
\end{enumerate}
\end{definition}

A partir de ahora, usaremos para mayor brevedad el símbolo $Q$ como intercambiable por $\forall$ o $\exists$ a no ser que se indique lo contrario.$\\$

Damos una definición constructiva de $FORM_S$:

\begin{prop}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos los conjuntos:
$$F_{S}^{0} := FORMAT_S$$
$$F_{S}^{n+1} := F_{S}^{n} \cup \{ (\neg \varphi) \, | \, \varphi \in F_{S}^{n}\} \cup \{ (\varphi \square \psi) \, | \, \varphi, \psi \in F_{S}^{n}\} \cup \{(Qx \, \varphi) \, | \, x \in Var, \, \varphi \in F_{S}^{n}\}$$
Entonces $\bigcup\limits_{i \in \mathbb{N}} F_{S}^{i} = FORM_S$.
\end{prop}
\begin{proof}
De nuevo, la demostración es análoga a la de \ref{ind}.
\end{proof}


\section{Inducción estructural y recursión}

Tal y como ocurría con la lógica proposicional, la recursión y la inducción estructural son las dos principales herramientas empleadas en las definiciones y demostraciones de la lógica de primer orden. Sin embargo, ahora tenemos que tratar separadamente los conjuntos $TERM_S$ y $FORM_S$ asociados a cierta signatura $S$. $\\$

Comenzamos con los teoremas de inducción estructural y recursión para $TERM_S$, dada una signatura $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$:

\begin{prop}(Inducción estructural)
Sean $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ una signatura y $P$ una propiedad. Si se cumple que:
\begin{enumerate}
    \item $P$ es válida para todo elemento de $T_{S}^{0}$.
    \item Sea $f|_k \in Fn_S$. Si $P$ es válida para todo elemento de $T_{S}^{n}$, entonces es válida para $f(t_1, \dots t_k)$, con $t_1, \dots, t_k \in T_{S}^{n}$.
\end{enumerate}
Entonces $P$ es válida para todo elemento de $TERM_S$.
\end{prop}
\begin{proof}
Si la propiedad $P$ cumple 1, 2 y 3, entonces el conjunto de términos que cumplen $P$ cumple las tres propiedades de la definición \ref{term}, por tanto contiene a $TERM_S$.
\end{proof}



 \begin{prop} El esquema de definición recursiva da como resultado una única función, es decir, dadas:
\begin{enumerate}
    \item $F_0: Ct_S \cup Var \rightarrow A$.
    \item $F_f: A^{k} \rightarrow A$, para cada función $f|_{k} \in Fn_S$.
\end{enumerate}
existe una única función $F: TERM_S \rightarrow A$ tal que:
\begin{enumerate}
    \item $F(t)=F_0(t)$, para todo $t\in Ct_S \cup Var$.
    \item $F(f(t_1,\dots,t_k))=F_f(F(t_1),\dots,F(t_k))$, para cada $f|_{k} \in Fn_S$ y $t_1,\dots,t_k\in TERM_S$.
\end{enumerate}
\begin{proof}
Se omite la demostración.
\end{proof}
\end{prop}


\begin{example}
Una función que nos será de utilidad será $var$, que nos lleva cada elemento de $TERM_S$ al conjunto de variables que aparecen en él. La definimos recursivamente como:
\begin{enumerate}
    \item Caso base: $var_{0}: Ct_S \cup Var \rightarrow \mathcal{P} (Var)$, dada por $var_{0}(c) = \emptyset$ si $c \in Ct_S$ y $var(x) = \{x\}$ si $x \in Var$.
    \item Caso recursivo: Dado $f|_{k} \in Fn_S$, $var_{f}: (\mathcal{P} (Var))^{k} \rightarrow \mathcal{P} (Var)$, dada por $var_{f}(f(t_1, \dots t_k)) = \bigcup\limits_{i = 1}^{k} var(t_i)$.
\end{enumerate}
\end{example}


Ahora enunciamos los teoremas de inducción estructural y recursión para $FORM_S$, dada una signatura $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$:

\begin{prop}(Inducción estructural)
Sean $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ una signatura y $P$ una propiedad. Si se cumple que:
\begin{enumerate}
    \item $P$ es válida para todo elemento de $FORMAT_S$.
    \item Si $\varphi_1, \varphi_2 \in FORM_S$ y se cumplen $P(\varphi_1),P(\varphi_2)$, entonces tenemos $P((\neg \varphi_1))$ y  $P((\varphi_1 \square \varphi_2))$.
    \item Si $x \in Var$ y $\varphi \in FORM_S$, y se cumple $P(\varphi)$, entonces tenemos $P((Q x \varphi))$.
\end{enumerate}
Entonces $P$ es válida para todo elemento de $FORM_S$.
\end{prop}
\begin{proof}
Si la propiedad $P$ cumple 1, 2 y 3, entonces el conjunto de términos que cumplen $P$ cumple las tres propiedades de la definición \ref{form}, por tanto contiene a $FORM_S$.
\end{proof}

 \begin{prop} El esquema de definición recursiva da como resultado una única función, es decir, dadas:
\begin{enumerate}
    \item $F_{AT}: FORMAT_S \rightarrow A$.
    \item $F_{\neg}: A \rightarrow A$.
    \item $F_{\square}: A \times A \rightarrow A$.
    \item $F_Q:Var\times A\rightarrow A$.
\end{enumerate}
existe una única función $F: FORM_S \rightarrow A$ tal que:
\begin{enumerate}
    \item $F(\varphi) = F_{AT}(\varphi)$, para toda $\varphi \in FORMAT_S$.
    \item $F((\neg \varphi)) = F_{\neg}(F(\varphi))$.
    \item $F((\varphi_1 \square \varphi_2)) = F_{\square}(F(\varphi_1), F(\varphi_2))$.
    \item $F((Qx\,\varphi))=F_Q(x,F(\varphi))$.
\end{enumerate}
\begin{proof}
     Se omite la demostración.
\end{proof}
\end{prop}


\begin{example}
Extendamos la función $var$ al conjunto $FORM_S$. Por comodidad, omitimos las funciones auxiliares:
\begin{enumerate}
    \item Caso base:
        \begin{itemize}
            \item $var(\top) = var(\bot) = \emptyset.$
            \item Sean $p|_k \in Pd_S$, $t_1, \dots t_n \in TERM_S$. Entonces $var(p(t_1, \dots t_n)) = \bigcup\limits_{i=1}^{k} var(t_i).$
            \item Sean $t, s \in TERM_S$. Entonces $var(t \doteq s) = var(t) \cup var(s)$.
        \end{itemize} 
    \item Caso recursivo:
        \begin{itemize}
            \item $var((\neg \varphi)) = var(\varphi)$.
            \item $var((\varphi \square \psi)) = var(\varphi) \cup var(\psi)$.
            \item $var((Qx \, \varphi)) = \{x\} \cup var(\varphi)$.
        \end{itemize}
\end{enumerate}
\end{example}


\begin{comment}

\section{Eliminación de paréntesis}
Al igual que en lógica proposicional, nos serán útiles unas reglas de omisión de paréntesis:
\begin{enumerate}
    \item Los paréntesis externos pueden omitirse. Esto no da lugar a ambigüedad.
    \item Conectivas y cuantificadores se aplicarán en este orden: $\neg, \land, \lor, \to, \leftrightarrow, \forall, \exists$.
    \item Cuando hay varias conectivas del mismo tipo seguidas, se asocia siempre por la izquierda.
\end{enumerate}
Un par de ejemplos de aplicación de estas reglas en fórmulas con cuantificadores:$\\[8pt]$
\begin{equation*}
\begin{array}{ccc}
     \forall x \, \varphi\to\psi  & \text{es} & (\forall x \, (\varphi\to\psi))\\
     \exists x \, \varphi \land \forall y \psi & \text{es} & 
     (\exists x \, (\varphi \land (\forall y \psi)))\\
\end{array}
\end{equation*}

\end{comment}




\section{Variables libres y ligadas}
Consideremos las siguientes fórmulas de primer orden:
\begin{itemize}
    \item $\forall x\;x\doteq3$
    \item $x\doteq3$
\end{itemize}
La primera fórmula se puede traducir informalmente como `para todo $x$, $x$ es igual a 3'. Intuitivamente, podemos decir que el cuantificador $\forall$ está afectando al significado de $x$. Sin embargo, en la segunda fórmula, $x$ no aparece afectada por ningún cuantificador. En general, diremos que una variable es \textit{ligada} en una fórmula $\varphi$ si siempre aparece afectada por un cuantificador, como en el primer ejemplo, y diremos que es una variable \textit{libre} en $\varphi$ si aparece alguna vez sin estar afectada por un cuantificador. Formalicemos estos conceptos:


\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos recursivamente la función $lib: FORM_S \rightarrow \mathcal{P}(Var)$, que nos lleva cada fórmula al conjunto de sus variables libres:
\begin{enumerate}
    \item Caso base: Sea $\varphi \in FORMAT_S$. Entonces, $lib(\varphi) = var(\varphi)$.
    \item Caso recursivo: 
        \begin{itemize}
            \item $lib(\neg \varphi) = lib(\varphi)$.
            \item $lib(\varphi \square \psi) = lib(\varphi) \cup lib(\psi)$.
            \item $lib(Qx \, \varphi) = lib(\varphi) \setminus \{x\}$.
        \end{itemize}
\end{enumerate}
\end{definition}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos el \textit{conjunto de sentencias}, $SENT_S$, como el formado por aquellas $\varphi \in FORM_S$ tales que $lib(\varphi) = \emptyset$.
\end{definition}


\section{Álgebras e interpretaciones}
Hasta ahora hemos venido considerando cuestiones sintácticas sobre las fórmulas. Lo que queremos ahora es abordar su semántica, esto es, su comportamiento cuando les damos una interpretación determinada. Comenzamos definiendo la estructura de la que tomamos el significado de los símbolos de una signatura:

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ una signatura. Una \textit{S-álgebra} es una tupla 
$$\mathfrak{A} := \langle A, \{ c^{\mathfrak{A}} \, | \, c \in Ct_S\}, \{f^{\mathfrak{A}} \, | \, f \in Fn_S\}, \{p^{\mathfrak{A}} \, | \, p \in Pd_S\}\rangle$$
De modo que:
\begin{itemize}
    \item $A$, el \textit{conjunto soporte}, verifica que $A \neq \emptyset$.
    \item Si $c \in Ct_S$, $c^{\mathfrak{A}} \in A$.
    \item Si $f|_k \in Fn_S$, $f^{\mathfrak{A}}: A^{k} \rightarrow A$.
    \item Si $p|_k \in Pd_S$, $p^{\mathfrak{A}}: A^{k} \rightarrow Bool$.
\end{itemize}
\end{definition}
$\\$
Por convenio, un símbolo $f$ de función 0-aria tendrá asociada una función $f^{\mathfrak{A}}: \{\emptyset\} \rightarrow A$. Es decir, será una función desde el conjunto de un elemento $\{\emptyset\}$ en $A$. Está claro que estas funciones pueden identificarse con elementos de $A$, identificando $f$ con $f(\emptyset)$. De modo que las funciones 0-arias van a llevar a cabo esencialmente la misma función que las constantes, y de hecho, aunque aquí usaremos constantes, toda la lógica de primer orden se puede desarrollar sin constantes usando funciones 0-arias.$\\$

De igual forma, un símbolo $p$ de predicado 0-ario tendrá asociada una función $p^{\mathfrak{A}}: \{\emptyset\} \rightarrow Bool$. Es decir, igual que con las funciones 0-arias, podemos asociar a cada predicado 0-ario un valor de $Bool$, $V$ o $F$. En esto se asemejarán a los símbolos de proposición de lógica proposicional, a los cuales asignábamos (mediante las asignaciones de verdad) un valor de $Bool$.

\begin{example}\label{anat}
Consideremos la signatura $Nat := \langle \{0\}, \{+|_2,*|_2, s|_1\}, \{<|_2\}\rangle$ que presentamos previamente. La forma natural (aunque no la única) de asignar significados a estos símbolos sería la $S$-álgebra:
$$\mathfrak{A}_{Nat} := \langle \mathbb{N}, \{ 0^{\mathfrak{A}_{Nat}}\}, \{+^{\mathfrak{A}_{Nat}},*^{\mathfrak{A}_{Nat}},s^{\mathfrak{A}_{Nat}}\}, \{<^{\mathfrak{A}_{Nat}}\}\rangle \text{, donde:}$$
\begin{itemize}
    \item $\mathbb{N}$ es el conjunto de los números naturales: $\{0,1,2,\dots\}$.
    \item $0^{\mathfrak{A}_{Nat}}$ será el número natural 0.
    \item $+^{\mathfrak{A}_{Nat}}$ será la función suma en los naturales, $+:\mathbb{N}^2\to\mathbb{N};(m,n)\mapsto m+n$. $\\$
    $*^{\mathfrak{A}_{Nat}}$ será la función producto en los naturales, $*:\mathbb{N}^2\to\mathbb{N};(m,n)\mapsto m*n$.$\\$
    $s^{\mathfrak{A}_{Nat}}$ será la función sucesor en los naturales, $s:\mathbb{N}\to\mathbb{N};n\mapsto n+1$.
    \item $<^{\mathfrak{A}_{Nat}}:\mathbb{N}^2\to Bool$ será la función que cumpla $<^{\mathfrak{A}_{Nat}}(m,n)=V$ si $m<n$, y $<^{\mathfrak{A}_{Nat}}(m,n)=F$ en caso contrario. Es decir, $<^{\mathfrak{A}_{Nat}}(m,n)$ será verdadero si y solo si $m<n$.
\end{itemize}
Es importante distinguir los símbolos de sus objetos asociados, ya que en algunos casos, como 0, suma y producto en este ejemplo, representamos igual ambas cosas. En el siguiente ejemplo habrá una clara distinción entre los símbolos y sus objetos asociados.
\end{example}


\begin{example}Vamos a ver otro ejemplo de álgebra para la signatura $Nat$.
Sea $\mathfrak{A} = \langle \{\bigtriangleup, \bigcirc \}, \{0^{\mathfrak{A}}\}, \{+^{\mathfrak{A}}, *^{\mathfrak{A}}, s^{\mathfrak{A}}\}, \{<^{\mathfrak{A}}\}\rangle$ tal que:
\begin{itemize}
    \item $0^{\mathfrak{A}} = \bigtriangleup$.
    \item $s^{\mathfrak{A}}: \{\bigtriangleup, \bigcirc \} \rightarrow \{\bigtriangleup, \bigcirc\}$, $x \mapsto \bigtriangleup$.
    \item $*^{\mathfrak{A}}, +^{\mathfrak{A}}: \{\bigtriangleup, \bigcirc \}^{2} \rightarrow \{\bigtriangleup, \bigcirc\}$, $(x, y) \mapsto \bigcirc$.
    \item $<^{\mathfrak{A}}: \{\bigtriangleup, \bigcirc \}^{2} \rightarrow Bool$, $(x, y) \mapsto V$.
\end{itemize}
Como veremos en interpretaciones, la expresión $$*(+(s(0), s(0)), s(s(s(0))))$$ en $\mathfrak{A}$ se refiere a $\bigcirc$ ya que, desarrollando, esa expresión corresponde a:
\begin{align*}
&*^{\mathfrak{A}}(+^{\mathfrak{A}}(s^{\mathfrak{A}}(0^{\mathfrak{A}}), s^{\mathfrak{A}}(0^{\mathfrak{A}})), s^{\mathfrak{A}}(s^{\mathfrak{A}}(s^{\mathfrak{A}}(0^{\mathfrak{A}}))))\\
&=*^{\mathfrak{A}}(+^{\mathfrak{A}}(s^{\mathfrak{A}}(\bigtriangleup), s^{\mathfrak{A}}(\bigtriangleup)), s^{\mathfrak{A}}(s^{\mathfrak{A}}(s^{\mathfrak{A}}(\bigtriangleup))))\\
&=*^{\mathfrak{A}}(+^{\mathfrak{A}}(\bigtriangleup, \bigtriangleup), s^{\mathfrak{A}}(s^{\mathfrak{A}}(\bigtriangleup)))\\
&=*^{\mathfrak{A}}(\bigcirc, s^{\mathfrak{A}}(\bigtriangleup))\\
&=*^{\mathfrak{A}}(\bigcirc, \bigtriangleup)\\
&=\bigcirc
\end{align*}


, mientras que en $\mathfrak{A}_{Nat}$ podemos ver de forma similar que la expresión se refiere a $6$.$\\$
Sin embargo, si intentamos ver a qué se refiere el término $+(s(x), s(0))$, tiene una variable que todavía no sabemos como interpretar. Informalmente, las variables suelen referirse a objetos que no hemos determinado. En nuestra segunda álgebra, $x$ podría referirse a $\bigtriangleup$ o a $\bigcirc$. En ambos casos, $+(s(x), s(0))$ se refiere a $\bigcirc$ en $\mathfrak{A}$. Sin embargo, en $\mathfrak{A}_{Nat}$, el valor que tome la expresión dependerá del valor que tome la $x$.
\end{example}

Lo anterior muestra que es necesario definir una función especial para dotar de significado a las variables:

\begin{definition}
Sea $S$ signatura. Una \textit{S-interpretación} es una tupla $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$ con:
\begin{itemize}
    \item $\mathfrak{A}$ es \textit{S-álgebra} de soporte $A$.
    \item $\sigma : Var \rightarrow A$.
\end{itemize}
\end{definition}

\begin{example}
Así, en el ejemplo anterior, tomando una $Nat$-interpretación $\sigma: Var \rightarrow \mathbb{N}$, podemos interpretar $+(s(x), s(0))$: si por ejemplo $\sigma(x) = 7$, estamos `asignando' a la variable $x$ el valor 7, por tanto a la expresión total le asignaríamos el valor:
\begin{align*}
&+^{\mathfrak{A}_{Nat}}(s^{\mathfrak{A}_{Nat}}(\sigma(x)), s^{\mathfrak{A}_{Nat}}(0^{\mathfrak{A}_{Nat}}))\\
&=+^{\mathfrak{A}_{Nat}}(s^{\mathfrak{A}_{Nat}}(7), s^{\mathfrak{A}_{Nat}}(0))\\
&=+^{\mathfrak{A}_{Nat}}(8,1)\\
&=9
\end{align*}
\end{example}

Ahora extendemos este concepto a términos, como ya hemos hecho intuitivamente en los dos últimos ejemplos:

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura, $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$ $S$-interpretación. Definimos recursivamente la \textit{interpretación de los términos} $t \in TERM_S$, $t^{\mathfrak{I}}$, como:
\begin{itemize}
    \item Caso base:
        \begin{itemize}
            \item Si $c \in Ct_S$, $c^{\mathfrak{I}} = c^{\mathfrak{A}}$.
            \item Si $x \in Var$, $x^{\mathfrak{I}} = \sigma(x)$.
        \end{itemize}
    \item Caso recursivo:
        \begin{itemize}
           \item Si $f|_k \in Fn_S$, $t_1, \dots, t_k \in TERM_S$, $f(t_1, \dots, t_k)^{\mathfrak{I}} = f^{\mathfrak{A}}(t_{1}^{\mathfrak{I}}, \dots, t_{k}^{\mathfrak{I}})$.
        \end{itemize}
\end{itemize}
\end{definition}

Antes de pasar a la interpretación de fórmulas, conviene establecer la siguiente notación: dada la $S$-interpretación $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$, por el símbolo $\mathfrak{I}[a/x]$ designamos la $S$-interpretación determinada por $\langle \mathfrak{A}, \sigma[a/x]\rangle$.\footnote{Recordemos que denotamos respectivamente por $f[b/a](x)$ a $f(x)$, si $x \neq a$, y a $b$, si $x = a$.}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$, $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$ $S$-interpretación, con $A$ conjunto soporte.  Definimos recursivamente la \textit{interpretación de las fórmulas} $\varphi \in FORM_S$, $\varphi^{\mathfrak{I}}$, como:
\begin{itemize}
    \item Caso base:
        \begin{itemize}
            \item Si $\varphi = \top$, $\varphi^{\mathfrak{I}} = V$.
            \item Si $\varphi = \bot$, $\varphi^{\mathfrak{I}} = F$.
            \item Si $\varphi = t \doteq s$, con $t, s \in TERM_S$; entonces $\varphi^{\mathfrak{I}} = V$ si $t^{\mathfrak{I}} = s^{\mathfrak{I}}$ y $\varphi^{\mathfrak{I}} = F$ en otro caso.
            \item Si $\varphi = p(t_1, \dots, t_k)$, con $t_1, \dots, t_k \in TERM_S$, $p|_k \in Pd_S$; entonces $\varphi^{\mathfrak{I}} = V$ si $p^{\mathfrak{A}}(t_{1}^{\mathfrak{I}}, \dots, t_{k}^{\mathfrak{I}}) = V$ y $\varphi^{\mathfrak{I}} = F$ en otro caso. 
        \end{itemize}
    \item Caso recursivo:
        \begin{itemize}
            \item Si $\varphi = \neg \varphi_1$,  $\varphi^{\mathfrak{I}} = v_{\neg}(\varphi_{1}^{\mathfrak{I}})$.
            \item Si $\varphi = \varphi_1 \square \varphi_2$,  $\varphi^{\mathfrak{I}} = v_{\square}(\varphi_{1}^{\mathfrak{I}}, \varphi_{2}^{\mathfrak{I}})$.
            \item Si $\varphi = \forall x \, \varphi_1$, con $x \in Var$; entonces $\varphi^{\mathfrak{I}} = V$, si para todo $a \in A$, $\varphi_1^{\mathfrak{I}[a/x]} = V$; y $\varphi^{\mathfrak{I}} = F$ en otro caso.
            \item Si $\varphi = \exists x \, \varphi_1$, con $x \in Var$; entonces $\varphi^{\mathfrak{I}} = V$, si existe $a \in A$ tal que $\varphi_1^{\mathfrak{I}[a/x]} = V$; y $\varphi^{\mathfrak{I}} = F$ en otro caso.
        \end{itemize}
\end{itemize}
\end{definition}

Describamos el concepto de \textit{consecuencia lógica} para lógica de primer orden: 

\begin{definition}
Sea $S$ signatura. Sean $\Phi \subseteq FORM_S$, $\varphi \in FORM_S$, $\mathfrak{I}$ $S$-interpretación. Decimos que $\mathfrak{I}$ \textit{satisface} $\varphi$, $\mathfrak{I} \vDash \varphi$, si $\varphi^{\mathfrak{I}} = V$. 
Análogamemente, $\mathcal{\A}$ \textit{satisface} $\Phi$, $\mathfrak{I} \vDash \Phi$, si $\psi^{\mathfrak{I}} = V$, para cada $\psi \in \Phi$.
\end{definition}

\begin{definition}
Sea $S$ signatura. Dados $\Phi \subseteq FORM_S$ y $\varphi \in FORM_S$, decimos que $\varphi$ es \textit{consecuencia lógica} de $\Phi$, $\Phi\vDash\varphi$, si toda $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I}\vDash \Phi$ verifica $\mathfrak{I} \vDash \varphi$.
\end{definition}

Está claro que $\emptyset\vDash\varphi$ es equivalente a que toda interpretación verifica $\varphi$. En estos casos, podemos escribir $\vDash\varphi$ en vez de $\emptyset\vDash\varphi$.

\begin{definition}
Sea $S$ signatura. $\Phi \subseteq FORM_S$ se dice \textit{satisfactible} si existe una $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \Phi$. $\Phi$ se dice \textit{insatisfactible} si no existe tal $S$-interpretación $\mathfrak{I}$.
\end{definition}
$\\$
Fijada una signatura $S$, podemos clasificar cada fórmula $\varphi$ como:
\begin{itemize}
    \item \textit{Satisfactible}, si existe alguna $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \varphi$. 
    \begin{itemize}
        \item \textit{Tautología}, si $\mathfrak{I} \vDash \varphi$ para toda $S$-interpretación $\mathfrak{I}$, es decir, $\vDash\varphi$
        \item \textit{Contingencia}, si es satisfactible pero no tautología.
    \end{itemize}
    \item \textit{Contradicción}, si no es satisfactible. 
\end{itemize}

$\\$
Veamos algunos ejemplos:

\begin{example}
La fórmula $\varphi=\exists x \, x \doteq x$ siempre es una tautología.
En esta afirmación juega un papel importante que el conjunto soporte, $A$, no es vacío. Por tanto dada una signatura $S$ y una $S$-interpretación $\mathfrak{I}$, existe un elemento $a\in A$. De modo que llamando $\varphi_1=x \doteq x$, tenemos que $\varphi_1^{\mathfrak{I}[a/x]} = V$, ya que se cumple que $a=a$. Como hay un elemento $a\in A$ tal que $\varphi_1^{\mathfrak{I}[a/x]} = V$, tenemos que $\varphi^{\mathfrak{I}} = V$. De hecho, como esto sucede para todo elemento $a\in A$, también será una tautología la fórmula $\forall x \, x \doteq x$.
\end{example}

\begin{example}\label{complejo}
Consideremos la signatura $S:= \langle \emptyset, \emptyset, \{ R|_2\}\rangle$ y las fórmulas 
$$\varphi := \exists x \, \forall y \, R(x, y)$$
$$\psi := \forall y \, \exists x \, R(x, y)$$
Veamos que $\varphi \vDash \psi$. Para ello, vamos a ver qué significan $\varphi$ y $\psi$ en términos del conjunto soporte.

Sea $\mathfrak{I}$ $S$-interpretación de soporte $A$ tal que $\mathfrak{I} \vDash \varphi$. Entonces, existe un $a \in A$ tal que $\mathfrak{I}[a/x] \vDash \forall y \, R(x, y)$. Por tanto, para todo $b \in A$ se cumple que $\mathfrak{I}[a/x][b/y] \vDash R(x, y)$. 

Es decir, $\mathfrak{I} \vDash \varphi$ significa que existe un elemento $a\in A$ que está relacionado con todos los elementos del conjunto soporte $A$ mediante la relación $R$.$\\$

Ahora, sea $\mathfrak{I}$ $S$-interpretación de soporte $A$ tal que $\mathfrak{I} \vDash \psi$. Entonces, para todo $c \in A$, $\mathfrak{I}[c/y]\vDash \exists x \, R(x, y)$. De la misma forma, existe $d \in A$ tal que $\mathfrak{I}[c/y][d/x] \vDash R(x, y)$. 

Es decir, $\mathfrak{I} \vDash \psi$ significa que para todo elemento $c\in A$ existe algún elemento $d$ del conjunto soporte $A$ tal que $d$ está relacionado con $c$.$\\$

Claramente, si tenemos el primer caso tenemos el segundo, porque para todo elemento $c\in A$, $a$ está relacionado con $c$, por tanto existe algún elemento relacionado con $c$. Por tanto, $\varphi \vDash \psi$.$\\[5pt]$

Veamos que la implicación recíproca, $\psi \vDash \varphi$, no es cierta en general. 

Para ello damos el siguiente contraejemplo: sea el $S$-álgebra $\mathfrak{A} := \langle A, \emptyset, \{R^{\mathfrak{A}} \}\rangle$, con $A :=  \{1, 2, 3 \}$ y $R^{\mathfrak{A}}: A^{2} \rightarrow Bool$ dada por $(1, 2), (2, 3), (3, 1) \mapsto V$, $(x, y) \mapsto F$ en otro caso\footnote{En ocasiones es más cómoda la notación conjuntista, es decir, en vez de dar $R^\mathfrak{A}$ como una función $R^{\mathfrak{A}}:A^n\to Bool$, podemos darla como el subconjunto $\{a\in\mathfrak{A}^n\, | \, R^{\mathfrak{A}}(a)=V\}$. Por ejemplo, en este caso, $R^{\mathfrak{A}}$ sería el conjunto $\{(1, 2), (2, 3), (3, 1)\}$}.$\\$

Sea $\mathcal{G}=\langle\mathfrak{A},\sigma \rangle$ una $S$-interpretación. Evidentemente, para todo $a \in A$ existe $b \in A$ tal que $\mathcal{G}[a/y][b/x] \vDash R(x, y)$: si $a = 1$, $b = 3$; si $a = 2$, $b = 1$; si $a= 3$, $b = 2$. Por otro lado, es imposible que exista $c \in A$ tal que, para todo $d \in A$, $\mathfrak{I}[c/x][d/y] \vDash R(x, y)$, ya que ningún elemento está relacionado con todos. Por tanto $\mathcal{G}$ satisface $\psi$ pero no satisface $\varphi$.
\end{example}

\begin{example}
$\varphi_{=\infty} := (\exists z \, \forall x \, \neg f(x) \doteq z) \land (\forall x \, \forall y \, f(x) \doteq f(y) \rightarrow x \doteq y)$ es una contingencia. Nótese que nos dice que $f$ es (símbolo de) una función inyectiva y no sobreyectiva. En concreto, esto implica que el cardinal del conjunto soporte de cualquier $S$-álgebra inducida por una $S$-interpretación $\mathfrak{I}$ que satisface $\varphi_{=\infty}$ tiene que ser infinito. Esto se debe a que el símbolo de función $f$ tiene asociada una función $f^\mathfrak{A}:A\to A$ que es inyectiva y no sobreyectiva, lo cual no puede pasar si $A$ es finito.
\end{example}

\begin{example}
$\varphi_{=2} := (\exists x \, \exists y \, \neg x \doteq y) \land \forall z \, (z \doteq y \lor z \doteq x)$ es una contingencia. Nos dice, en concreto, que el cardinal del conjunto soporte de cualquier $S$-álgebra inducida por una $S$-interpretación tiene que ser igual a 2.
\end{example}


\subsection{Axiomas de Peano}
Recordemos la signatura $Nat$ definida en \ref{nat}. Este lenguaje fue introducido por Peano para describir los números naturales usando los símbolos de suma, producto, sucesor y menor o igual. También introdujo los que ahora conocemos como \textit{axiomas de Peano}:
\begin{enumerate}
    \item $\forall x \; \neg s(x)\doteq 0$
    \item $\forall x \, \forall y \; s(x)\doteq s(y)\to x\doteq y$
    \item $\forall x \; x+0\doteq x$
    \item $\forall x \, \forall y \; x+s(y)\doteq s(x+y)$
    \item $\forall x \; x*0\doteq 0$
    \item $\forall x \, \forall y \; x*s(y)\doteq (x*y)+x$
    \item $\forall x \, \forall y \; (x<y \leftrightarrow \exists z \; x+s(z)\doteq y)$
\end{enumerate}
Llamamos $\Phi_{Peano}$ al conjunto de las anteriores sentencias.
Es fácil comprobar que en la $Nat$-álgebra $\mathfrak{A}_{Nat}$, introducida en \ref{anat}, cualquier interpretación satisface los axiomas de Peano. Sin embargo, también hay otras estructuras con esta propiedad.

\begin{comment}
como la siguiente:
$$\mathcal{N}_2=\{\{0,1\}\times \mathbb{N},\{0^{\mathcal{N}_2}\},\{+^{\mathcal{N}_2},*^{\mathcal{N}_2},s^{\mathcal{N}_2}\},\{<^{\mathcal{N}_2}\}\}$$
siendo:
\begin{itemize}
    \item $0^{\mathcal{N}_2}=(0,0)$.
    \item $\begin{array}{clcl}
         +^{\mathcal{N}_2}:&(\{0,1\}\times \mathbb{N})\times(\{0,1\}\times \mathbb{N})&\to& \{0,1\}\times\mathbb{N};\\
         & ((x,m),(y,n))&\mapsto& (max(x,y),m+n)
    \end{array}.$
    \item $\begin{array}{clcl}
         *^{\mathcal{N}_2}:&(\{0,1\}\times \mathbb{N})\times(\{0,1\}\times \mathbb{N})&\to& \{0,1\}\times\mathbb{N};\\
         & ((x,m),(y,n))&\mapsto& (max(x*y,x),m*n)
    \end{array}.$
    \item $s^{\mathcal{N}_2}:\{0,1\}\times\mathbb{N}\to \{0,1\}\times\mathbb{N}; (x,m)\mapsto (x,m+1)$
    \item $<^{\mathcal{N}_2}((x,m),(y,n))=V$ si y solo si $x\leq y$ y $m<n$.
\end{itemize}

Donde hemos usado las operaciones $+,*$ habituales de los naturales, y $max(x,y)$ es 0 si $x,y$ son 0 y 1 si no.
\end{comment}




\section{Sustitución}

El ejemplo \ref{complejo} muestra que la determinación de la consecuencia lógica en particular y de la satisfactibilidad en general es una tarea costosa. Motivados por este hecho, investigamos relaciones sintácticas que nos permitan trabajar más cómodamente. Comenzamos por el concepto de \textit{sustitución}, que ya estuvo presente a lo largo del anterior capítulo. 

De ahora en adelante, denotamos vectores de elementos de un determinado conjunto con una raya horizontal sobre una letra. Normalmente empleamos la misma letra para referirnos a los elementos de tal vector. Por ejemplo, dada la signatura $S$ y el conjunto soporte de cierta $S$-álgebra, $A$, designamos $\bar{a} := (a_1, \dots, a_n)$ con $a_i \in A$, para todo $i =1, \dots, n$.\\

Comenzamos definiendo la sustitución para términos:

\begin{definition}
Sea $S$ signatura. Sean $t \in TERM_S$, $\bar{x} := (x_1, \dots, x_n)$ vector de $Var$ y $\bar{s} := (s_1, \dots, s_n)$ vector de $TERM_S$. Definimos la \textit{sustitución de} $\bar{x}$ \textit{por} \bar{s} \textit{en t} como:
\begin{itemize}
    \item Si $t \in Ct_S$, $t[\bar{s}/\bar{x}] = t$.
    \item Si $t \in Var$, $t[\bar{s}/\bar{x}] = s_i$ si $t = x_i$, para cierto $i$, y $t[\bar{s}/\bar{x}] = t$ si $t \neq x_i$, para todo $i$.
    \item $f(t_1, \dots t_n)[\bar{s}/\bar{x}] = f(t_1[\bar{s}/\bar{x}], \dots, t_n[\bar{s}/\bar{x}]).$
\end{itemize}
\end{definition}

Pasamos a la sustitución para fórmulas:
\begin{definition}
Sea $S$ signatura. Sean $\varphi \in FORM_S$, $\bar{x} := (x_1, \dots, x_n)$ vector de $Var$ y $\bar{s} := (s_1, \dots, s_n)$ vector de $TERM_S$. Definimos la \textit{sustitución de} $\bar{x}$ \textit{por} \bar{s} \textit{en $\varphi$} como:
\begin{itemize}
    \item Caso base:
    \begin{itemize}
        \item $\top[\bar{s}/\bar{x}]=\top$.
        \item $\bot[\bar{s}/\bar{x}]=\bot$.
        \item $(t_1\doteq t_2)[\bar{s}/\bar{x}]=(t_1[\bar{s}/\bar{x}]\doteq t_2[\bar{s}/\bar{x}])$.
        \item Si $p|_k\in Pd_S$ y $t_1,\dots,t_k\in TERM_S$, $p(t_1,\dots,t_k)[\bar{s}/\bar{x}]=p(t_1[\bar{s}/\bar{x}],\dots,t_k[\bar{s}/\bar{x}])$.
    \end{itemize}
    \item Caso recursivo:
    \begin{itemize}
        \item $(\neg\varphi)[\bar{s}/\bar{x}]=(\neg\varphi[\bar{s}/\bar{x}])$.
        \item $(\varphi_1\square\varphi_2)[\bar{s}/\bar{x}]=(\varphi_1[\bar{s}/\bar{x}]\square\varphi_2[\bar{s}/\bar{x}])$.
        \item $(Qx\;\varphi)[\bar{s}/\bar{x}]$ se define por casos:
        \begin{itemize}
            \item $(Qx\;\varphi[\bar{s}/\bar{x}])$, si $x\notin\bar{x}$ y $x\notin\bigcup_{i=1}^nvar(t_i)$.
            \item $(Qx\;\varphi[(s_1,\dots,s_{i-1},s_{i+1},\dots,s_n)/(x_1,\dots,x_{i-1},x_{i+1}\dots,x_n)])$, si $x=x_i\in\bar{x}$ y $x\notin\bigcup_{i=1}^nvar(t_i)$.
            \item $(Qz\;\varphi[z/x][\bar{s}/\bar{x}])$ si $x\in\bigcup_{i=1}^nvar(t_i)$, siendo z una variable que no está en $\bar{x}$ ni en $\bigcup_{i=1}^nvar(t_i)$.
        \end{itemize}
    \end{itemize}
\end{itemize}
\end{definition}

Si queremos sustituir un solo elemento, no un vector con varios, podemos omitir la raya horizontal sobre la letra (aunque también puede interpretarse como un vector de un elemento).\\

En ocasiones haremos uso de la siguiente notación:
$$f(t_1, \dots t_n)[\bar{s}/\bar{x}] = f(t_1, \dots t_n)[s_1/x_1, \dots s_n/x_n].$$


\begin{example}
Si llamamos $a:= h(x)$ y $b:= f(x, y)$, entonces $$f(x, y)[h(x)/x, f(x, y)/y] = f(h(x), f(x, y)).$$
\end{example}


\begin{note}

Si no nombramos adecuadamente a las variables que estamos manipulando podemos llegar a tener una \textit{colisión}, es decir, que mediante una sustitución una variable pase de estar libre a estar ligada. 
 
Por ejemplo, sean $\varphi := \forall z \, p(x, z)$ y $t := f(z)$. Entonces la sustitución 
$$\varphi[t/x] = \forall z \, p(f(z), z)$$ 
daría lugar a una colisión porque la variable $z$ está libre en $t$, pero ligada al sustituirla en $\varphi$ por $x$. Habrá ocasiones en que esto no nos sea conveniente. En estos casos podremos cambiar $t=f(z)$ por $f(y)$, obteniendo
$$\varphi[t/x] = \forall z \, p(f(y), z),$$
de modo que ya no tenemos el problema anterior.
\end{note}


\section{Lema de coincidencia}

Más adelante nos será útil el estudiar las relaciones entre diferentes interpretaciones y signaturas. Para ello nos será útil el lema de coincidencia, además de para demostrar el lema de sustitución de la próxima sección.

Comencemos con la siguiente

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos recursivamente el \textit{vocabulario para términos}, $voc$, como:
\begin{itemize}
    \item Caso base: 
        \begin{itemize}
            \item $voc(c) = \{c\}$, para todo $c \in Ct_S$.
            \item $voc(x) = \emptyset$, para todo $x \in Var$.
        \end{itemize}
    \item Caso recursivo: $voc(f(t_1, \dots, t_k)) = \{ f\} \cup \bigcup \limits_{i = 1}^{k} voc(t_i)$, con $f|_k \in Fn_S$, $t_1 \dots t_k \in TERM_S$.
\end{itemize}
\end{definition}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos recursivamente el \textit{vocabulario para fórmulas}, $voc$, como:
\begin{itemize}
    \item Caso base:
        \begin{itemize}
            \item $voc(p(t_1, \dots, t_k)) = \{ p\} \cup \bigcup \limits_{i = 1}^{k} voc(t_i)$, con $p|_k \in Pd_S$, $t_1 \dots t_k \in TERM_S$.
            \item $voc(t \doteq s) = voc(t) \cup voc(s)$, con $t, s\in TERM_S$.
            \item $voc(\top) = voc(\bot) = \emptyset$.
        \end{itemize}
    \item Caso recursivo:
        \begin{itemize}
            \item $voc(\neg \varphi) = voc(\varphi)$, con $\varphi \in FORM_S$.
            \item $voc(\varphi \square \psi) = voc(\varphi) \cup voc(\psi)$, con $\varphi, \psi \in FORM_S$.
            \item $voc(Qx \, \varphi) = voc(\varphi)$, con $\varphi \in FORM_S$ y $x \in Var$.
        \end{itemize}
\end{itemize}
\end{definition}

Es decir, el vocabulario de una expresión, sea término o fórmula, es el conjunto de elementos de la signatura (símbolos de constante, función y predicado) que aparecen en ella.\\

Ahora consideramos:

\begin{definition}
Sean $S_1 = \langle Ct_{S_1}, Fn_{S_1}, Pd_{S_1}\rangle$, $S_2 = \langle Ct_{S_2}, Fn_{S_2}, Pd_{S_2}\rangle$ signaturas. Definimos la \textit{signatura unión} y la \textit{signatura intersección} respectivamente como:
$$S_1 \cup S_2 := \langle Ct_{S_1} \cup Ct_{S_2}, Fn_{S_1} \cup Fn_{S_2}, Pd_{S_1} \cup Pd_{S_2} \rangle, $$
$$S_1 \cap S_2 := \langle Ct_{S_1} \cap Ct_{S_2}, Fn_{S_1} \cap Fn_{S_2}, Pd_{S_1} \cap Pd_{S_2} \rangle. $$
\end{definition}

Ya que podemos obtener nuevas signaturas a partir de otras, es decir, nuevos conjuntos de símbolos, nos interesa estudiar qué ocurre con las interpretaciones, es decir, con los significados de los símbolos. Esto motiva la noción de \textit{coincidencia}:

\begin{definition}
Sean $S_1, S_2$ signaturas, $\mathfrak{I}_{1} = \langle \mathfrak{A}_1, \sigma_1 \rangle$ una $S_1$-interpretación y $\mathfrak{I}_{2} = \langle \mathfrak{A}_2, \sigma_2 \rangle$ una $S_2$-interpretación con el mismo conjunto soporte. Consideremos $S := S_1 \cap S_2$, $t \in TERM_S$. Decimos que $\mathfrak{I}_{1}$ \textit{y} $\mathfrak{I}_{2}$ \textit{coinciden en} $t$, $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, si:
\begin{enumerate}
    \item $c^{\mathfrak{I}_{1}} = c^{\mathfrak{I}_{2}}$, para todo $c \in voc(t)$, $c \in Ct_S$.
    \item $x^{\mathfrak{I}_{1}} = x^{\mathfrak{I}_{2}}$, para todo $x \in var(t)$.
    \item $f^{\mathfrak{A}_{1}} = f^{\mathfrak{A}_{2}}$, para todo $f \in voc(t)$, $f \in Fn_S$.
\end{enumerate}
\end{definition}

\begin{definition}
Sean $S_1, S_2$ signaturas, $\mathfrak{I}_{1} = \langle \mathfrak{A}_1, \sigma_1 \rangle$ una $S_1$-interpretación y $\mathfrak{I}_{2} = \langle \mathfrak{A}_2, \sigma_2 \rangle$ una $S_2$-interpretación con el mismo conjunto soporte. Consideremos $S := S_1 \cap S_2$, $ \varphi \in FORM_S$. Decimos que $\mathfrak{I}_{1}$ \textit{y} $\mathfrak{I}_{2}$ \textit{coinciden en} $\varphi$, $\mathfrak{I}_{1} \sim_{\varphi} \mathfrak{I}_{2}$, si:
\begin{enumerate}
    \item $c^{\mathfrak{I}_{1}} = c^{\mathfrak{I}_{2}}$, para todo $c \in voc(\varphi)$, $c \in Cts_S$.
    \item $\sigma_1(x) = \sigma_2(x)$, para todo $x \in lib(\varphi)$.
    \item $f^{\mathfrak{A}_{1}} = f^{\mathfrak{A}_{2}}$, para todo $f \in voc(\varphi)$, $f \in Fn_S$.
    \item $p^{\mathfrak{A}_{1}} = p^{\mathfrak{A}_{2}}$, para todo $p \in voc(\varphi)$, $p \in Pd_S$.
\end{enumerate}
\end{definition}

Ya estamos en disposición de enunciar el resultado que da nombre a esta sección:
\begin{theorem}(Lema de coincidencia)\label{coinc}
Sean $S_1, S_2$ signaturas, $\mathfrak{I}_{1} = \langle \mathfrak{A}_1, \sigma_1 \rangle$ una $S_1$-interpretación y $\mathfrak{I}_{2} = \langle \mathfrak{A}_2, \sigma_2 \rangle$ una $S_2$-interpretación con el mismo conjunto soporte. Consideremos $S := S_1 \cap S_2$.
\begin{enumerate}
    \item Si $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, con $t \in TERM_S$, entonces  $t^{\mathfrak{I}_{1}} = t^{\mathfrak{I}_{2}}$.
    \item Si $\mathfrak{I}_{1} \sim_{\varphi} \mathfrak{I}_{2}$, con $\varphi \in FORM_S$, entonces  $\varphi^{\mathfrak{I}_{1}} = \varphi^{\mathfrak{I}_{2}}$.
\end{enumerate}
\end{theorem}

Es decir, la primera parte nos dice que el significado de un término bajo una interpretación solo depende de los significados de las constantes, variables y funciones que aparecen en ella. La segunda nos dice algo parecido para fórmulas, solo que además nos dice que el significado de una fórmula \textbf{no} depende del significado de sus variables ligadas, solo importan las libres.
\begin{proof}\mbox{}
\begin{enumerate}
    \item Inducción estructural.
    Caso base:
    \begin{itemize}
        \item Si $t=p$ con $p\in Ct_S$, entonces $p\in voc(t)$, por tanto como $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, tenemos que $p^{\mathfrak{I}_1}=p^{\mathfrak{I}_2}$.
        \item Si $t=x$ con $x\in var$, entonces $x\in var(t)$, por tanto como $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, se cumple $x^{\mathfrak{I}_1}=x^{\mathfrak{I}_2}$.
    \end{itemize} 
    Caso inductivo: $t=f(t_1,\dots,t_n)$, para $t_1,\dots,t_n\in TERM_S.$ Como $voc(t_i)\subseteq voc(t)$ y $var(t_i)\subseteq var(t)$, se cumple que $\mathfrak{I}_{1} \sim_{t_i} \mathfrak{I}_{2}, i=1,\dots,n$.\\
    Por tanto por inducción tenemos $t_i^{\mathfrak{I}_1}=t_i^{\mathfrak{I}_2}$, de modo que:
    $$f(t_1,\dots,t_n)^{\mathfrak{I}_1}=f^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1},\dots,t_n^{\mathfrak{I}_1})=f^{\mathfrak{A}_2}(t_2^{\mathfrak{I}_2},\dots,t_n^{\mathfrak{I}_2})=f(t_1,\dots,t_n)^{\mathfrak{I}_2},$$
    Donde hemos usado que $f\in voc(t)$, por tanto $f^{\mathfrak{A}_1}=f^{\mathfrak{A}_2}$.
    \item De nuevo, inducción estructural.
    Caso base:
    \begin{itemize}
        \item $\varphi$ es $\top$ o $\bot$. Caso obvio.
        \item $\varphi=t_1\doteq t_2$. En este caso, $voc(t_i)\subseteq voc(\varphi)$ y $var(t_i)\subseteq var(\varphi)$. De modo que $\mathfrak{I}_{1} \sim_{t_i} \mathfrak{I}_{2}, i=1,2$, y por el apartado anterior se cumple que $t_i^{\mathfrak{I}_{1}} = t_i^{\mathfrak{I}_{2}},i=1,2$. Por tanto $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $t_1^{\mathfrak{I}_{1}} = t_1^{\mathfrak{I}_{2}}$ si y solo si $t_2^{\mathfrak{I}_{1}} = t_2^{\mathfrak{I}_{2}}$ si y solo si $\varphi^{\mathfrak{I}_2}$.
        \item $\varphi=p(t_1,\dots,t_k)$. En este caso,igual que en el anterior tenemos $t_i^{\mathfrak{I}_1}=t_i^{\mathfrak{I}_2}$. Además, $p\in voc(\varphi)$, por tanto $p^{\mathfrak{A}_1}=p^{\mathfrak{A}_2}$. De modo que $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $p^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1},\dots,t_n^{\mathfrak{I}_1})=V$ si y solo si $p^{\mathfrak{A}_2}(t_1^{\mathfrak{I}_2},\dots,t_n^{\mathfrak{I}_2})=V$ si y solo si $\varphi^{\mathfrak{I}_2}$ es $V$.
    \end{itemize}
    Caso inductivo:
    \begin{itemize}
        \item $\varphi=\neg\varphi_1$. Entonces $voc(\varphi)=voc(\varphi_1)$ y $lib(\varphi)=lib(\varphi_1)$. Por tanto, $\mathfrak{I}_{1} \sim_{\varphi_1} \mathfrak{I}_{2}$, y por hipótesis de inducción, $\varphi_1^{\mathfrak{I}_1}=\varphi_1^{\mathfrak{I}_2}$. De modo que
        $\varphi^{\mathfrak{I}_1}=v_\neg(\varphi_1^{\mathfrak{I}_1})=v_\neg(\varphi_1^{\mathfrak{I}_2})=\varphi^{\mathfrak{I}_2}$.
        
        \item Si $\varphi=\varphi_1\square\varphi_2$. Igual que en el caso anterior, tenemos que $\varphi_i^{\mathfrak{I}_1}=\varphi_i^{\mathfrak{I}_2},i=1,2$. De modo que:
        $\varphi^{\mathfrak{I}_1}=v_\square(\varphi_1^{\mathfrak{I}_1},\varphi_2^{\mathfrak{I}_1})=v_\square(\varphi_1^{\mathfrak{I}_2},\varphi_2^{\mathfrak{I}_2})=\varphi^{\mathfrak{I}_2}$.
        
        \item $\varphi=\exists x \varphi_1$. Como $\mathfrak{I}_{1} \sim_{\varphi} \mathfrak{I}_{2}$, y tenemos $voc(\varphi)=voc(\varphi_1)$, $lib(\varphi)=lib(\varphi_1)\setminus \{x\}$, sabemos que $\mathfrak{I}_1[a/x]\sim_{\varphi_1}\mathfrak{I}_2[a/x]$, ya que la única diferencia de interpretaciones de $\mathfrak{I}_1$ y $\mathfrak{I}_2$ en $\varphi_1$ que no se da en $\varphi$ es en la variable $x$, y $\mathfrak{I}_1[a/x]$ y $\mathfrak{I}_2[a/x]$ coinciden en la variable $x$. Ahora,
        $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si existe $a\in A$ tal que $\varphi_1^{\mathfrak{I}_1[a/x]} = V$. Pero esto equivale a que exista $a\in A$ tal que $\varphi_1^{\mathfrak{I}_2[a/x]} = V$, es decir, a que $\varphi^{\mathfrak{I}_2}$ sea $V$.
        
        \item $\varphi=\forall x \varphi_1$. Igual que en el caso anterior, sabemos que $\mathfrak{I}_1[a/x]\sim_{\varphi_1}\mathfrak{I}_2[a/x]$. Ahora,
        $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si para todo $a\in A$ se cumple $\varphi_1^{\mathfrak{I}_1[a/x]} = V$. Pero esto equivale a que para todo $a\in A$ se cumpla $\varphi_1^{\mathfrak{I}_2[a/x]} = V$, lo cual equivale a que $\varphi^{\mathfrak{I}_2}$ sea $V$.
    \end{itemize}
\end{enumerate}
\end{proof}

\begin{example}
Sean $t \in TERM_S$, $\varphi \in FORM_S$ tales que existen $x_1, \dots, x_n \in Var$ de modo que $var(t) \subseteq \{x_1, \dots, x_n\}$ y $lib(\varphi) \subseteq \{x_1, \dots, x_n\}$. El Lema de Coincidencia nos dice que el significado que tome cada variable que no pertenezca a $\{x_1, \dots, x_n \}$ no afectará a los significados de $t$ y $\varphi$.\\
Es decir, dada una interpretación $\mathfrak{I}=\langle \mathfrak{A}, \sigma \rangle$, $\varphi^\mathfrak{I}$ solo depende de $\mathfrak{A}$ y de $\sigma(x_1),\dots,\sigma(x_n)$.
\end{example}

\begin{example}
En el ejemplo anterior, si $\varphi$ es una fórmula cerrada, $lib(\varphi) = \emptyset$ y entonces podemos tomar $n=0$. Es decir, el significado de $\varphi$ depende solo de el álgebra, no de la interpretación.
\end{example}


\section{Isomorfía}

Seguimos nuestro estudio de las relaciones entre signaturas e interpretaciones. Introducimos a continuación un concepto empleado constantemente en matemáticas. En nuestro caso, captura la idea de una aplicación que `preserva el significado' entre dos álgebras de la misma signatura:

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sean $\mathfrak{A}_1$ y $\mathfrak{A}_2$ $S$-álgebras de conjuntos soporte respectivos $A_1$ y $A_2$. Una aplicación $h: A_1 \rightarrow A_2$ es \textit{isomorfismo de S-álgebras} si:
\begin{itemize}
    \item $h$ es biyectiva.
    \item $h(c^{\mathfrak{A}_1}) = c^{\mathfrak{A}_2}$, para todo $c \in Ct_S$.
    \item $h(f^{\mathfrak{A}_1}(a_1, \dots, a_n)) = f^{\mathfrak{A}_2}(h(a_1), \dots, h(a_n))$, con $f|_n \in Fn_S$, $a_1, \dots, a_n \in A_1$.
    \item $p^{\mathfrak{A}_1}(a_1, \dots, a_n) = p^{\mathfrak{A}_2}(h(a_1), \dots, h(a_n))$, con $p|_n \in Pn_S$, $a_1, \dots, a_n \in A_1$.
\end{itemize}
Si existe un isomorfismo entre $\mathfrak{A}_1$ y $\mathfrak{A}_2$, decimos que son \textit{isomorfas} y lo denotamos por $\mathfrak{A}_1 \approx \mathfrak{A}_2$.
\end{definition}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sean $\mathfrak{I}_1 = \langle \mathfrak{A}_1, \sigma_1 \rangle$ y $\mathfrak{I}_2 = \langle \mathfrak{A}_2, \sigma_2 \rangle$ $S$-intepretaciones. Una aplicación $h$ es \textit{isomorfismo de S-interpretaciones} si:
\begin{itemize}
    \item $h$ es isomorfismo entre las $S$-álgebras $\mathfrak{A}_1$ y $\mathfrak{A}_2$.
    \item $h(\sigma_1(x)) = \sigma_2(x)$, para todo $x \in Var$.
\end{itemize}
Cuando existe un isomorfismo entre $\mathfrak{I}_1$ y $\mathfrak{I}_2$, decimos que son \textit{isomorfas} y lo simbolizamos por $\mathfrak{I}_1 \approx \mathfrak{I}_2$.
\end{definition}

\begin{example}
Consideremos la signatura característica de los grupos, $S := \langle \{e\}, \{*|_2\}, \emptyset \rangle$. Sean los grupos $(\mathbb{Z}_2, +)$ y $(A, \cdot)$ dado por $A = \{a, b\}$ con:
\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline 
    $\cdot$ & $a$ & $b$ \\ \hline
    $a$ & $a$ & $b$\\ \hline
    $b$ & $b$ & $a$\\ \hline
    \end{tabular}
    \end{center}
    \end{table}
\end{example}
Entonces tenemos dos $S$-álgebras:
$$\mathfrak{A}_1 = \langle \mathbb{Z}_2, \{ 0,1\}, \{ +\}, \emptyset \rangle$$
$$\mathfrak{A}_2 = \langle A, \{a,b\}, \{\cdot \}, \emptyset \rangle$$
Entonces, la aplicación $h: \mathbb{Z}_2 \rightarrow A$ dada por $h(0) = a$ y $h(1) = b$ es un isomorfismo, es decir, $h:\mathfrak{A}_1 \approx \mathfrak{A}_2$. 

Este lema técnico nos permitirá probar el siguiente teorema:

\begin{lema}\label{sustiso}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sean $\mathfrak{I}_1 = \langle \mathfrak{A}_1, \sigma_1 \rangle$ y $\mathfrak{I}_2 = \langle \mathfrak{A}_2, \sigma_2 \rangle$ $S$-interpretaciones de conjuntos soporte $A_1,A_2$ tales que existe $h: \mathfrak{I}_1 \approx \mathfrak{I}_2$. Sea $a\in A_1$.\\
Entonces, $\mathfrak{I}_1[a/x]\approx\mathfrak{I}_2[h(a)/x]$. De hecho, la misma función $h:A_1\to A_2$ es isomorfismo entre $\mathfrak{I}_1[a/x]$ y $\mathfrak{I}_2[h(a)/x]$.
\end{lema}
\begin{proof}
Está claro que se cumple $h(\sigma_1(y)) = \sigma_2(y)$ para todas las variables excepto x, ya que si $y\in Var\setminus \{x\}$, $h(\sigma_1[a/x](y))=h(\sigma_1(y))=\sigma_2(y)=\sigma_2[h(a)/x](y)$.\\
Respecto a la variable $x$, $h(\sigma_1[a/x](x))=h(a)=\sigma_2[h(a)/x](x)$.\\
Queda entonces comprobar que $h$ es isomorfismo entre las álgebras de $\mathfrak{I}_1$ y $\mathfrak{I}_2$. Pero esto es directo, ya que estas álgebras son $\mathfrak{A}_1$ y $\mathfrak{A}_2$.
\end{proof}

El siguiente resultado muestra que los isomorfismos entre $S$-interpretaciones se extienden a las fórmulas y los términos de tal signatura $S$.

\begin{theorem}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sea $h$ isomorfismo entre las $S$-interpretaciones $\mathfrak{I}_1$ y $\mathfrak{I}_2$. Entonces:
\begin{enumerate}
    \item Para todo $t \in TERM_S$, $h(t^{\mathfrak{I}_1}) = t^{\mathfrak{I}_2}$.
    \item Para toda $\varphi \in FORM_S$, $\varphi^{\mathfrak{I}_1} = \varphi^{\mathfrak{I}_2}$, y por tanto $\mathfrak{I}_1 \vDash \varphi$ si y solo si $\mathfrak{I}_2 \vDash \varphi$.
\end{enumerate}
\end{theorem}
\begin{proof} \mbox{}
\begin{enumerate}
    \item Por inducción estructural sobre $t \in TERM_S$:
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                \item Si $t = c$, con $c \in Ct_S$, entonces $h(t^{\mathfrak{I}_1}) = h(c^{\mathfrak{I}_1}) = c^{\mathfrak{I}_2} = t^{\mathfrak{I}_2}$.
                \item Si $t = x$, con $x \in Var$, entonces $h(t^{\mathfrak{I}_1}) = h(x^{\mathfrak{I}_1}) = h(\sigma_1(x)) = \sigma_2(x) = x^{\mathfrak{I}_2} = t^{\mathfrak{I}_2}$.
                 \end{itemize}
            \item Caso recursivo: Si $t = f(t_1, \dots, t_n)$, con $f|_n \in Fn_S$ y $t_1, \dots, t_n \in TERM_S$ cumplen el enunciado, entonces: 
            
            $h(f(t_1, \dots, t_n)^{\mathfrak{I}_1}) = h(f^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1}, \dots, t_n^{\mathfrak{I}_1})) = f^{\mathfrak{A}_2}(h(t_1^{\mathfrak{I}_1}), \dots, h(t_n^{\mathfrak{I}_1})) =  f^{\mathfrak{A}_2}(t_1^{\mathfrak{I}_2}, \dots, t_n^{\mathfrak{I}_2}) = f(t_1, \dots, t_n)^{\mathfrak{I}_2}$
        \end{itemize}
    \item Por inducción estructural sobre $\varphi \in FORM_S$:
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                    \item Si $\varphi = \top$, entonces $\varphi^{\mathfrak{I}_1} = \top^{\mathfrak{I}_1} = V = \top^{\mathfrak{I}_2} = \varphi^{\mathfrak{I}_2}$ y análogo con $\bot$.
                    \item Si $\varphi = t \doteq s$ para $t, s \in TERM_S$, entonces $\mathfrak{I}_1 \vDash \varphi$ si y solo si $t^{\mathfrak{I}_1} = s^{\mathfrak{I}_1}$ si y solo si (por ser $h$ inyectiva) $h(t^{\mathfrak{I}_1}) = h(s^{\mathfrak{I}_1})$ si y solo si $t^{\mathfrak{I}_2} = s^{\mathfrak{I}_2}$ si y solo si  $\mathfrak{I}_1 \vDash \varphi$.
                    \item Si $\varphi = p(t_1, \dots, t_n)$, con $p|_n \in Pd_S$ y $t_1, \dots, t_n \in TERM_S$ cumplen el enunciado, entonces $p(t_1, \dots, t_n)^{\mathfrak{I}_1} = V$, si y solo si $p^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1}, \dots, t_n^{\mathfrak{I}_1}) = V$ si y solo si  $p^{\mathfrak{A}_2}(h(t_1^{\mathfrak{I}_1}), \dots, h(t_n^{\mathfrak{I}_1})) = V$ si y solo si  $p^{\mathfrak{A}_2}(t_1^{\mathfrak{I}_2}, \dots, t_n^{\mathfrak{I}_2}) = V$
                \end{itemize}
            \item Caso recursivo:
                \begin{itemize}
                    \item $\varphi=\neg\varphi_1$. Entonces, $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $v_\neg(\varphi_1^{\mathfrak{I}_1})$ es $V$ si y solo si $v_\neg(\varphi_1^{\mathfrak{I}_2})$ es $V$ si y solo si 
                    $\varphi^{\mathfrak{I}_2}$ es $V$.
                    \item $\varphi=\varphi_1\square\varphi_2$. Entonces, 
                    $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $v_\square(\varphi_1^{\mathfrak{I}_1},\varphi_2^{\mathfrak{I}_1})$ es $V$ si y solo si $v_\square(\varphi_1^{\mathfrak{I}_2},\varphi_1^{\mathfrak{I}_2})$ es $V$ si y solo si 
                    $\varphi^{\mathfrak{I}_2}$ es $V$.
                    \item $\varphi=\exists x \, \varphi_1$. Entonces, $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si existe $a$ que cumple $\varphi_1^{\mathfrak{I}_1[a/x]}=V$. Como por hipótesis inductiva el enunciado se cumple para $\varphi_1$, usando el lema \ref{sustiso} tenemos que $\varphi_1^{\mathfrak{I}_1[a/x]}=V$ equivale a $\varphi_1^{\mathfrak{I}_2[a/x]}=V$. Y que exista $a$ que cumpla esto es equivalente a que $\varphi^{\mathfrak{I}_2}$ sea $V$, como queríamos.
                    \item $\varphi=\forall x \, \varphi_1$. Entonces, $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si para todo $a$ se cumple $\varphi_1^{\mathfrak{I}_1[a/x]}=V$. Como por hipótesis inductiva el enunciado se cumple para $\varphi_1$, usando el lema \ref{sustiso} tenemos que $\varphi_1^{\mathfrak{I}_1[a/x]}=V$ equivale a $\varphi_1^{\mathfrak{I}_2[a/x]}=V$. Y que esto se cumpla para todo $a$ es equivalente a que $\varphi^{\mathfrak{I}_2}$ sea $V$, como queríamos.
                    
                \end{itemize}
        \end{itemize}
\end{enumerate}
\end{proof}

\section{Lema de sustitución}

Proseguimos nuestro estudio de la sustitución. A continuación obtenemos el resultado análogo al que ya demostramos en lógica proposicional.

\begin{theorem}(Lema de sustitución)\label{sustprim}
Sean $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura, $\mathfrak{I}$ $S$-interpretación de conjunto soporte $A$. Sean $\bar{x} := (x_1, \dots, x_n)$ y $\bar{t} := (t_1, \dots, t_n)$ vectores de $Var$ y $TERM_S$, respectivamente. Denotemos $\bar{t}^{\mathfrak{I}} := (t_1^{\mathfrak{I}}, \dots, t_n^{\mathfrak{I}})$ y $\mathcal{J} := \mathfrak{I}[\bar{t}^{\mathfrak{I}}/\bar{x}]$.
Entonces:
\begin{enumerate}
    \item Si $s \in TERM_S$, $(s[\bar{t}/\bar{x}])^{\mathfrak{I}} = s^{\mathcal{J}}$.
    \item Si $\varphi \in FORM_S$, $(\varphi[\bar{t}/\bar{x}])^{\mathfrak{I}} = \varphi^{\mathcal{J}}$, es decir, $\mathfrak{I} \vDash \varphi[\bar{t}/\bar{x}]$ si y solo si $\mathcal{J} \vDash \varphi$.
\end{enumerate}
\end{theorem}
\begin{proof}\mbox{}
\begin{enumerate} 
    \item Por inducción estructural.
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                    \item Si $s = c$, con $c \in Ct_S$, entonces $s=s[\bar{t}/\bar{x}]=c$, y se cumple $c^{\mathfrak{I}}=c^{\mathcal{J}}$, ya que $\mathfrak{I}$ y $\mathcal{J}$ tienen la misma álgebra.
                    \item Sea $s = x$, con $x \in Var$. Si $x$ no está en $\bar{x}$, entonces $x[\bar{t}/\bar{x}]=x$, y como $x^{\mathfrak{I}}=x^{\mathcal{J}}$, tenemos el resultado. Si $x = x_i$, con $x_i$ el elemento $i$-ésimo de $\bar{x}$, $(x[\bar{t}/\bar{x}])^{\mathfrak{I}} = t_i^{\mathfrak{I}} = x^{\mathfrak{I}[\bar{t}/\bar{x}]} = x^{\mathcal{J}}$.
                \end{itemize}
            \item Caso recursivo: Sea $s = f(r_1, \dots, r_k)$, con $f|_k \in Fn_S$ y $r_1, \dots, r_k \in TERM_S$. Entonces, $(f(r_1, \dots, r_k)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (f(r_1[\bar{t}/\bar{x}], \dots, r_k[\bar{t}/\bar{x}]))^{\mathfrak{I}} = f^{\mathfrak{A}}((r_1[\bar{t}/\bar{x}])^{\mathfrak{I}}, \dots, (r_k[\bar{t}/\bar{x}])^{\mathfrak{I}})$ y aplicando la hipótesis de inducción, lo anterior es igual $f^{\mathfrak{A}}(r_1^{\mathcal{J}}, \dots, r_k^{\mathcal{J}}) = f(r_1, \dots, r_k)^{\mathcal{J}}.$
        \end{itemize}
    \item Por inducción estructural.
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                    \item Si $\varphi = \top$, $(\varphi[\bar{t}/\bar{x}])^{\mathfrak{I}} = V = \varphi^{\mathcal{J}}$. Análogo con $\bot$.
                    \item Si $\varphi = r \doteq s$, con $r, s \in TERM_S$. Entonces $((r \doteq s)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (r[\bar{t}/\bar{x}] \doteq s[\bar{t}/\bar{x}])^{\mathfrak{I}}$, que es cierto si y solo si $r[\bar{t}/\bar{x}])^{\mathfrak{I}} = s[\bar{t}/\bar{x}]^{\mathfrak{I}}$ si y solo si, por hipótesis de inducción, $r^{\mathcal{J}} = s^{\mathcal{J}}$, es decir, si y solo si $\mathcal{J} \vDash r \doteq s$.
                    \item Si $\varphi = p(r_1, \dots, r_k)$, con $p|_k \in Pd_S$, $r_1, \dots r_k \in TERM_S$, entonces $(p(r_1, \dots, r_k)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (p(r_1[\bar{t}/\bar{x}], \dots, r_k[\bar{t}/\bar{x}]))^{\mathfrak{I}}$ es igual a  $p^{\mathfrak{A}}((r_1[\bar{t}/\bar{x}])^{\mathfrak{I}}, \dots, (r_k[\bar{t}/\bar{x}])^{\mathfrak{I}})$, que por hipótesis de inducción es igual a $p^{\mathcal{A}}(r_1^{\mathcal{J}}, \dots, r_k^{\mathcal{J}}) = p(r_1, \dots, r_k)^{\mathcal{J}}$.
                \end{itemize}
            \item Caso inductivo:
                    \begin{itemize}
                        \item Si $\varphi = \neg \psi$, entonces $((\neg \psi)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (\neg \psi[\bar{t}/\bar{x}])^{\mathfrak{I}} = v_{\neg}((\psi[\bar{t}/\bar{x}])^{\mathfrak{I}})$, que por hipótesis de inducción es $v_{\neg}(\psi^{\mathcal{J}}) = (\neg \psi)^{\mathcal{J}}$.
                        \item Si $\varphi = \psi \square \chi$, entonces $((\psi \square \chi)[\bar{t}/\bar{x}])^{\mathfrak{I}} = ((\psi[\bar{t}/\bar{x}]) \square (\chi[\bar{t}/\bar{x}]))^{\mathfrak{I}} = v_{\square}((\psi[\bar{t}/\bar{x}])^{\mathfrak{I}}, (\chi[\bar{t}/\bar{x}])^{\mathfrak{I}})$, que por hipótesis de inducción es $v_{\square}(\psi^{\mathcal{J}}, \chi^{\mathcal{J}}) = (\psi \square \chi)^{\mathcal{J}}$.
                        \item Veamos el caso $\forall x \, \varphi$. Supongamos que $x$ no es ninguno de los elementos del vector $\bar{x}$, ya que si esto fuera cierto y $x$ correspondiera a la variable $i$-ésima de $\bar{x}$, $x_i$, por cómo hemos definido sustitución tendríamos que 
                        $$(\forall x\;\varphi)[\bar{t}/\bar{x}]=(\forall x\;\varphi)[(t_1,\dots t_{i-1},t_{i+1},\dots,t_n)/(x_1,\dots x_{i-1},x_{i+1},\dots,x_n)],$$
                        es decir, nuestra sustitución es igual a otra sustitución en que $x\notin\bar{x}$.
    
    Tenemos entonces dos casos, $x \in var(t_i)$ para algún $i=1,\dots,n$ o no. El primero resulta ser más complicado y nos limitamos a hacer ese:\\
    Supongamos $x \in var(t_i)$ para cierto $1 \leq i \leq n$, con $t_i$ el $i$-ésimo elemento de $\bar{t}$. Entonces, introduciendo la variable nueva $z$, 
    $$(\forall x \, \varphi)[\bar{t}/\bar{x}] = \forall z \, \varphi[z/x][\bar{t}/\bar{x}]$$
    Entonces, $\mathfrak{I} \vDash \forall z \, \varphi[z/x][\bar{t}/\bar{x}]$ es equivalente a que para todo $a \in A$, $\mathfrak{I}[a/z] \vDash \varphi[z/x][\bar{t}/\bar{x}]$. Aplicando la hipótesis de inducción a $\mathfrak{I}[a/z]$ y a $\varphi$, lo anterior equivale a que para todo $a \in A$,
    $$(\mathfrak{I}[a/z])[\bar{t}^{\mathfrak{I}[a/z]}/\bar{x}] \vDash \varphi[z/x]$$
    Nótese que, al ser $z$ variable nueva, $z \notin var(t_i)$, para todo $1 \leq i \leq n$ y por \ref{coinc}, $t_i^{\mathfrak{I}[a/z]} = t_i^{\mathfrak{I}}$. Lo anterior es entonces equivalente a que para todo $a \in A$:
    $$(\mathfrak{I}[a/z])[\bar{t}^{\mathfrak{I}}/\bar{x}] \vDash \varphi[z/x]$$
    Por ser $z$ nueva, se sigue también que es distinta de todo elemento de $\bar{x}$. De modo que
    $(\mathfrak{I}[a/z])[\bar{t}^{\mathfrak{I}}/\bar{x}] = \mathfrak{I}[\bar{t}^{\mathfrak{I}}/\bar{x}][a/z] = \mathcal{J}[a/z]$, y entonces lo anterior es cierto si y solo si para todo $a \in A$, 
    $$\mathcal{J}[a/z] \vDash \varphi[z/x]$$
    De nuevo, por hipótesis de inducción sobre $\mathcal{J}[a/z]$ y $\varphi$, lo anterior se da si y solo si, para todo $a \in A$,
    $$\mathcal{J}[a/z][z^{\mathcal{J}[a/z]}/x] \vDash \varphi$$
    esto es, usando que $z^{\mathcal{J}[a/z]} = a$, 
    $$(\mathcal{J}[a/z])[a/x] \vDash \varphi$$
    Por ser $z$ variable nueva, $\mathcal{J}[a/z] \sim_{\varphi} \mathcal{J}$ y empleando \ref{coinc}, $\varphi^{\mathcal{J}[a/z]} = \varphi^{\mathcal{J}}$. Finalmente, lo anterior es equivalente a que para todo $a \in A$,
    $$\mathcal{J}[a/x] \vDash \varphi$$
    es decir, $\mathcal{J} \vDash \forall x \, \varphi$.
    El caso $\exists x \, \varphi$ es análogo.
                    \end{itemize}
        \end{itemize}
    
\end{enumerate}
\end{proof}


\section{Equivalencia lógica}

Algunos de los ejemplos precedentes muestran que operar con interpretaciones no es tarea cómoda. Por ello, debemos investigar relaciones entre los signos, que nos faciliten un futuro estudio de su semántica. De nuevo, la noción principal para este propósito es la de \textit{equivalencia lógica}:

\begin{definition}
Sea $S$ signatura, $\varphi, \psi \in FORM_S$. $\varphi$ y $\psi$ son \textit{lógicamente equivalentes}, $\varphi \sim \psi$, si para toda $S$-intepretación $\mathfrak{I}$, $\varphi^{\mathfrak{I}} = \psi^{\mathfrak{I}}$, es decir, $\mathfrak{I} \vDash \varphi$ si y solo si $\mathfrak{I} \vDash \psi$\footnote{No es difícil demostrar que $\sim$ es reflexiva, simétrica y transitiva, es decir, es relación de equivalencia sobre $FORM_S$.}.
\end{definition}



\begin{prop}\label{fund}
Sea $S$ signatura, $\varphi, \psi \in FORM_S$. Entonces son equivalentes:
\begin{enumerate}
    \item $\varphi \sim \psi$.
    \item $\vDash \varphi \leftrightarrow \psi$.
    \item $\varphi \vDash \psi$ y $\psi \vDash \varphi$.
\end{enumerate}
\end{prop}
\begin{proof}$\\$
\be
(1)$\implies$(2): Si $\varphi \sim \psi$, $\varphi^{\mathfrak{I}} = \psi^{\mathfrak{I}}$ para toda $S$-interpretación $\mathfrak{I}$, por tanto toda interpretación $\mathfrak{I}$ cumple $\mathfrak{I} \vDash \varphi\leftrightarrow \psi$, como queríamos.\\

\noindent (2)$\implies$(3):  Si $\vDash \varphi \leftrightarrow \psi$, toda interpretación $\mathfrak{I}$ solo puede satisfacer $\varphi$ y $\psi$ o no satisfacer $\varphi$ ni $\psi$. Por tanto, si una interpretación satisface $\varphi$, satisface $\psi$ y viceversa.  \\


\noindent (3)$\implies$(1): Si $\varphi \vDash \psi$ y $\psi \vDash \varphi$, entonces una interpretación satisface $\psi$ si satisface $\varphi$ y viceversa, por tanto satisface $\psi$ si y solo si satisface $\varphi$.
\end{proof}

Evidentemente, las leyes de equivalencia del cálculo proposicional siguen siendo válidas en lógica de primer orden. Además, introducimos nuevas leyes en las que aparezcen cuantificadores:

\begin{theorem}(Leyes de equivalencia lógica con cuantificadores)\mbox{}
\begin{enumerate}
    \item $Q x \, \varphi \sim Q u \, \varphi[u/x]$, siendo $u$ variable nueva.
    \item Si $\varphi \sim \psi$, entonces $Qx \, \varphi \sim Qx \, \psi$.
    \item $\neg \forall x \, \varphi \sim \exists x \, \neg \varphi,  \quad \neg \exists x \, \varphi \sim \forall x \, \neg \varphi$.
    \item $\forall x \, \varphi \sim \neg \exists x \, \neg \varphi, \quad \exists x \, \varphi \sim \neg \forall x \neg \varphi$.
    \item Si $x \neq y$, entonces $Qx \, Qy \, \varphi \sim Qy \, Qx \, \varphi$.
    \item $\forall x \, (\varphi \land \psi) \sim \forall x \, \varphi \land \forall x\, \psi, \quad \exists x \, (\varphi \lor \psi) \sim \exists x \, \varphi \lor \exists x\, \psi$.
    \item Si $x \notin lib(\psi)$, $Qx \, \psi \sim \psi$.
    \item Si $x \notin lib(\psi)$, $(\forall x \, \varphi) \land \psi \sim \forall x \, (\varphi \land \psi), \quad  (\exists x \, \varphi) \lor \psi \sim \exists x \, (\varphi \lor \psi)$.
    \item Si $x \notin lib(\psi)$, $\forall x \, (\varphi \lor \psi) \sim \forall x \, \varphi \lor \forall x \, \psi, \quad \exists x \, (\varphi \land \psi) \sim \exists x \, \varphi \land \exists x \, \psi$.
    \item Si $x \notin lib(\psi)$, $(\forall x \, \varphi) \rightarrow \psi \sim \exists x \, (\varphi \rightarrow  \psi), \quad (\exists x \, \varphi) \rightarrow \psi \sim \forall x (\varphi \rightarrow  \psi)$.
\end{enumerate}
\end{theorem}
\begin{proof} \mbox{}
\begin{enumerate}
    \item Demostremos el caso $\forall$, el $\exists$ se hace de forma análoga.
    Sea $\mathfrak{I}$ $S$-interpretación de conjunto soporte $A$. $\mathfrak{I} \vDash \forall u\;\varphi[u/x]$ es por definición equivalente a que, para todo $a \in A$, 
    $$\mathfrak{I}[a/u] \vDash \varphi[u/x].$$ 
    Como $u^{\mathfrak{I}[a/u]} = a$, aplicando el lema de sustitución \ref{sustprim} lo anterior es cierto si y solo si, para todo $a \in A$, 
    $$(\mathfrak{I}[a/u])[a/x]\vDash \varphi$$
    Al ser $u$ variable nueva, $(\mathfrak{I}[a/u])[a/x] \sim_{\varphi} \mathfrak{I}[a/x]$ y \ref{coinc} nos dice que lo anterior equivale a que, para todo $a \in A$, 
    $$\mathfrak{I}[a/x] \vDash \varphi,$$
    que es la definición de $\mathfrak{I} \vDash \forall x \, \varphi$.
    \item Sea $\mathfrak{I}$ $S$-interpretación tal que $\mathfrak{I} \vDash \exists x \, \varphi$, es decir, tal que existe $a \in A$ con $\mathfrak{I}[a/x] \vDash \varphi$, y al ser $\varphi \sim \psi$, lo anterior se da si y solo si existe $a \in A$ con $\mathfrak{I}[a/x] \vDash \psi$, es decir, la definición de $\mathfrak{I} \vDash \exists x \, \psi$. El caso $\forall$ es análogo.
    \item Sea $\mathfrak{I}$ $S$-interpretación tal que $\mathfrak{I} \vDash \neg \forall x \, \varphi$, es decir, $\mathfrak{I} \nvDash \forall x \, \varphi$. Equivalentemente, existe $a \in A$ tal que $\mathfrak{I}[a/x] \vDash \neg \varphi$, que es la definición de $\mathfrak{I} \vDash \exists x \, \neg \varphi$. El caso $\exists$ es análogo.
    \item $\varphi \sim \neg \neg \varphi$ luego, aplicando (2), $\forall x \, \varphi \sim \forall x \, \neg \neg \varphi$ y, por (3), $\forall x \, \neg \neg \varphi \sim \neg \exists x \, \neg \varphi$. El caso $\exists$ es análogo.
    \item $\mathfrak{I}\vDash \exists x\;\exists y\;\varphi$ si y solo si existe $a\in A$ tal que $\mathfrak{I}[a/x]\vDash\exists y\;\varphi$ si y solo si existen $a,b\in A$ tal que $\mathfrak{I}[a/x][b/y]\vDash\varphi$. Como $x\neq y$, $\mathfrak{I}[a/x][b/y]=\mathfrak{I}[b/y][a/x]$, por tanto lo anterior equivale a que existan $a,b\in A$ tales que $\mathfrak{I}[b/y][a/x]\vDash\varphi$. Igual que antes, vemos que esto es equivalente a que $\mathfrak{I}\vDash \exists y\;\exists x\;\varphi$. El caso $\forall$ es análogo.
    
    \item Sea $\mathfrak{I}$ $S$-interpretación tal que $\mathfrak{I} \vDash \forall x \, \varphi \land \forall x \, \psi$. Esto, por \ref{fund}, es equivalente a que $\mathfrak{I} \vDash \forall x \, \varphi $ y $\mathfrak{I} \vDash \forall x \, \psi$. Entonces, en el primer caso tenemos que, para todo $a \in A$, $\mathfrak{I}[a/x] \vDash \varphi$ y en el segundo que, para todo $b \in A$, $\mathfrak{I}[b/x] \vDash \psi$. De esta forma, lo anterior es equivalente a que, para todo $c \in A$, $\mathfrak{I}[c/x] \vDash \varphi$ y $\mathfrak{I}[c/x] \vDash \psi$, es decir, $\mathfrak{I}[c/x] \vDash \varphi \land \psi$, es decir, $\mathfrak{I} \vDash \varphi \land \psi$.\\
    El otro caso se puede probar a partir del primero, ya que:
    \begin{multline*}
        \exists x \, (\varphi \lor \psi) \sim \neg\neg(\exists x \, (\varphi \lor \psi))\sim\neg(\forall x\,\neg(\varphi\lor\psi))\sim\neg(\forall x\,(\neg\varphi\land\neg\psi))\sim \\ \sim\neg((\forall x\,\neg\varphi)\land(\forall x\neg\psi))\sim\neg(\forall x\,\neg\varphi)\lor\neg(\forall x\neg\psi)\sim(\exists x\,\neg\neg\varphi)\lor(\exists x\,\neg\neg\psi)\sim\exists x\varphi\lor\exists x\psi,
    \end{multline*}
    donde hemos usado las leyes de equivalencia de lógica proposicional, el primer apartado de este ejercicio y la regla (4) para negar cuantificadores.
    \item En este caso, solo es necesario notar que $\mathfrak{I}[a/x] \sim_{\psi} \mathfrak{I}$ y aplicar el Lema de Coincidencia, \ref{coinc}.
    \item Es una consecuencia directa de los apartados 6 y 7.
    \item Comencemos con el caso $\forall$.\\ 
    Queremos demostrar que $\mathfrak{I}\vDash\forall x\,\varphi\lor\psi$ si y solo si $\mathfrak{I}\vDash\forall x\,\varphi\lor\forall x\psi$\\
    $\implies$) Si $\mathfrak{I}\vDash\forall x\,\varphi\lor\psi$, para todo $a\in A$ se cumple $\mathfrak{I}[a/x]\vDash\varphi\lor\psi$. Dividimos en casos:
    \begin{itemize}
        \item $\mathfrak{I}\vDash\forall x\,\varphi$. En este caso, es obvio que se cumple $\mathfrak{I}\vDash\forall x\,\varphi\lor\forall x\psi$.
        \item En caso contrario, existe $a\in A$ tal que $\mathfrak{I}[a/x]\nvDash\varphi$. Entonces para ese $a$ tiene que cumplirse $\mathfrak{I}[a/x]\vDash\psi$. Pero entonces por la regla (7), $\mathfrak{I}[a/x]\vDash\forall x\psi$, por tanto $\mathfrak{I}\vDash\forall x\,\varphi\lor\forall x\psi$.
    \end{itemize}
    $\Longleftarrow$) $\mathfrak{I}\vDash\forall x \psi\lor\forall x \psi$. Tenemos dos casos:
    \begin{itemize}
        \item $\mathfrak{I}\vDash\forall x \psi$, es decir, para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\psi$. Esto implica que para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\varphi\lor\psi$, es decir, $\mathfrak{I}\vDash\forall x (\varphi\lor\psi)$.
        \item $\mathfrak{I}\vDash\forall x \varphi$, es decir, para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\varphi$. Esto implica que para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\varphi\lor\psi$, es decir, $\mathfrak{I}\vDash\forall x (\varphi\lor\psi)$.
    \end{itemize}
    Pasamos a la segunda parte. Esta se puede hacer de forma análoga a la anterior, aunque es más rápido deducirla de la anterior:
    \begin{multline*}
        \exists x\,(\varphi\land\psi)\sim\neg\neg\exists x(\varphi\land\psi)\sim\neg\forall x (\neg\varphi\lor\neg\psi)\sim\\\sim\neg((\forall x \neg \varphi)\lor(\forall x \neg\psi))\sim(\neg\forall x\neg\varphi)\land(\neg\forall x\neg\psi)\sim\exists x\varphi\land\exists x\psi.
    \end{multline*}
    Hemos podido usar la parte anterior de la regla ya que $x\in lib(\psi)$ si y solo si $x\in lib(\neg\psi)$.
    \item Estas últimas reglas se pueden deducir de las anteriores:
    \begin{multline*}
        (\forall x\,\varphi)\to\psi\sim\neg(\forall x\,\varphi)\lor\psi\sim\\\sim(\exists x\,\neg\varphi)\lor\psi\sim\exists x\,(\neg\varphi\lor\psi)\sim\exists x\,\varphi\to\psi.
    \end{multline*}
    \begin{multline*}
        (\exists x\,\varphi)\to\psi\sim\neg(\exists x\,\varphi)\lor\psi\sim(\forall x\,\neg\varphi)\lor\psi\sim\\\sim(\forall x\,\neg\varphi)\lor(\forall x\,\psi)\sim\forall x (\neg\varphi\lor\psi)\sim\forall x(\varphi\to\psi).
    \end{multline*}
\end{enumerate}
\end{proof}

Las leyes de equivalencia como 6, 8, 9 o 10 permiten escribir los cuantificadores \textit{al principio} de las fórmulas. Esto nos lleva a la siguiente
\begin{definition}
Sea $S$ signatura. Se dice que $\varphi \in FORM_S$ \textit{está en forma prenexa} si se puede escribir como:
$Q_1 x_1 \,, \dots, Q_n x_n \, \psi$, con $x_i$ variable y $Q_i$ cuantificador, para cada $1 \leq i \leq n$, y $\psi$ libre de cuantificadores. $\psi$ recibe el nombre de \textit{núcleo}.
\end{definition}

Ahora bien, ¿toda fórmula tiene una fórmula equivalente en forma prenexa? Antes de dar una respuesta afirmativa a esta pregunta necesitamos el siguiente lema:
\begin{lema}\label{lemita2345}
Sea $S$ signatura. Sean $\varphi,\psi \in FORM_S$, $x \in lib(\psi)$, $u \in Var$ tal que $u$ una variable nueva. Entonces 
$$Q x \, \varphi \lor \psi \sim Q u \, (\varphi[u/x] \lor \psi).$$
\begin{proof}
Es consecuencia de las reglas de equivalencia:
$$\forall x \, \varphi \lor \psi \sim \forall u \, \varphi[u/x] \lor \psi \sim \forall u \, \varphi[u/x] \lor \forall u\, \psi \sim \forall u \, (\varphi[u/x] \lor \psi)$$
$$\exists x \, \varphi \lor \psi \sim \exists u \, \varphi[u/x] \lor \psi \sim \exists u \, \varphi[u/x] \lor \exists u\, \psi \sim \exists u \, (\varphi[u/x] \lor \psi),$$
donde en el caso $\forall$ hemos usado que $u$ no aparece libre en $\psi$.
\end{proof}
\end{lema}

\begin{prop}
Sea $S$ signatura. Entonces, para cada $\varphi \in FORM_S$ existe $\psi \in FORM_S$ en forma prenexa tal que $\varphi \sim \psi$.
\end{prop}
\begin{proof}
La demostración se lleva a cabo por inducción estructural. Es rutinaria salvo por el paso inductivo en fórmulas, que demostramos para $\neg$ y $\lor$ \footnote{En realidad no hace falta demostrar el paso inductivo para más conectivas ya que el resto de conectivas pueden expresarse en términos de $\neg$ y $\lor$, como vimos en \ref{cosasfunccomp}}.$\\$

\noindent ($\neg$) Sea $\varphi=\neg \varphi_1$. Por hipótesis de inducción, existe $\psi \in FORM_S$ en forma prenexa tal que $\varphi_1 \sim \psi$, con $\psi = Q_1 x_1 \, \dots Q_n x_n \, \chi$. Entonces $\varphi\sim\neg \varphi_1 \sim \neg \psi \sim Q'_1 x_1 \, \dots Q'_n x_n \, \neg \chi$, donde $Q'_i = \forall$ si $Q_i = \exists$ y $Q'_i = \exists$ si $Q'_i = \forall$, para cada $1 \leq i \leq n$. $\\$

\noindent ($\lor$) Sea $\varphi=\varphi_1 \lor \varphi_2$. Por hipótesis de inducción, existen los respectivos núcleos $\chi_1$, $\chi_2$, tales que $\varphi_1 \sim Q^{1}_1 x_1 \, \dots Q^{1}_n x_n \, \chi_1$ y $\varphi_2 \sim Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2$. Consideremos los vectores de variables nuevas $\bar{u}= (u_1, \dots, u_n)$ y $\bar{v} = (v_1, \dots, v_m)$. Entonces, $\varphi_1 \sim Q^{1}_1 u_1 \, \dots Q^{1}_n u_n \, \chi_1[\bar{u}/\bar{x}]$ y $\varphi_2 \sim Q^{2}_1 v_1 \, \dots Q^{2}_m v_m \, \chi_2[\bar{v}/\bar{y}]$. Ahora, como $\bar{u}$ y $\bar{v}$ son variables nuevas, aplicando repetidamente el lema \ref{lemita2345}, obtenemos:

\begin{array}{ccl}
 \varphi_1 \lor \varphi_2 &\sim&Q^{1}_1 x_1(Q^1_2 x_2 \, \dots Q^{1}_n x_n \, \chi_1)\lor Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2 \\
     &\sim& Q^{1}_1u_1(Q^{1}_2 x_2 \, \dots Q^{1}_n x_n \, \chi_1[u_1/x_1]\lor Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2)\\
     &\vdots&\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n (\chi_1[\bar{u}/\bar{x}]\lor Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2)\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n (Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2\lor\chi_1[\bar{u}/\bar{x}])\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n Q^2_1 v_1 (Q^{2}_2 y_2 \, \dots Q^{2}_m y_m \, \chi_2[v_1/y_1]\lor\chi_1[\bar{u}/\bar{x}])\\
     &\vdots&\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n Q^2_1 v_1\dots Q^2_m v_m(\chi_2[\bar{v}/\bar{y}]\lor \chi_1[\bar{u}/\bar{x}]),
\end{array}

y ya tenemos una forma prenexa.
\end{proof}


\section{Método de los \textit{tableaux}}

En esta sección desarrollaremos el método de los \textit{tableaux} para lógica de primer orden, análogo al que ya presentamos en el anterior capítulo. Por ello, remitimos toda motivación informal acerca de este procedimiento a lo que ya dijimos allí. Para aprender métodos de este tipo siempre son de ayuda los ejemplos, que hemos incluido al final de la siguiente subsección.

\subsection{Nociones básicas y ejemplos}

Como veremos durante esta sección, para aplicar una regla de construcción de \textit{tableaux} necesitaremos unas constantes auxiliares. Por tanto, supondremos la existencia de un conjunto de constantes auxiliares $C_{A} = \{c_0,c_1, \dots \}$ en nuestra signatura.

Siempre que tengamos una fórmula existencial en un \textit{tableaux} podremos seleccionar un elemento del conjunto $C_A$ que la verifica. Más adelante veremos un ejemplo. 


Las fórmulas que pueden aparecer ahora en nuestros \textit{tableaux} obviamente incluyen a las que lo hacían en los del cálculo proposicional, pero se incorporan algunas nuevas. Es decir, además de las $\alpha$, $\beta$, $\sigma$-fórmulas, definimos:
\begin{itemize}
    \item $\gamma$-\textit{fórmulas} (también llamadas \textit{universales}):
    \begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|}
    \hline
    $\gamma$ & $\gamma(t)$ \\
    \hline \hline
    $\forall x \, \varphi$ & $\varphi[t/x]$ \\ \hline
    $\neg \exists x \, \varphi$ & $\neg \varphi[t/x]$\\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    Siendo $t \in TERM_S$.
    
    \item $\delta$-\textit{fórmulas} (también llamadas \textit{existenciales}):
    \begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|}
    \hline
    $\delta$ & $\delta(c)$ \\
    \hline \hline
    $\exists x \, \varphi$ & $\varphi[c/x]$ \\ \hline
    $\neg \forall x \, \varphi$ & $\neg \varphi[c/x]$\\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    Siendo $c \in C_A$.
    
    \item \textit{Axiomas de igualdad}, $EQ_S$:
    \begin{itemize}
        \item[(RF)] $\forall x \, x \doteq x$.
        \item[(IM)] $\forall x \, \forall y \, x \doteq y \rightarrow y \doteq x$.
        \item[(TR)] $\forall x \, \forall y \, \forall z \, x \doteq y \land y \doteq z \rightarrow x \doteq z$.
        \item[(ST_{1})] Sea $f|_n \in Fn_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \rightarrow f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
        \item[(ST_{2})] Sea $p|_n \in Pd_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \land  p(x_1, \dots, x_n) \rightarrow p(y_1, \dots, y_n).$$
    \end{itemize}
\end{itemize}
Los nombres de las reglas $RF,IM,TR$ se deben a que a estas propiedades se conocen como reflexiva, simétrica y transitiva. En el caso de las dos últimas se debe a que son reglas de sustitución.

Un resultado análogo al correspondiente de lógica proposicional es el siguiente:

\begin{prop}
Sean $S$ signatura, $\varphi \in FORM_S$. Entonces $\varphi$ verifica una de las siguientes condiciones:
\begin{enumerate}
    \item Es de la forma $\psi$, $\neg \psi$, $\bot$ o $\top$, con $\psi \in FORMAT_S$.
    \item Es $\sigma$-fórmula.
    \item Es $\alpha$-fórmula.
    \item Es $\beta$-fórmula.
    \item Es $\gamma$-fórmula.
    \item Es $\delta$-fórmula.
\end{enumerate}
\end{prop}

Esto asegura que nuestro método nos permitirá descomponer fórmulas arbitrarias en otras de la forma $\bot$, $\top$ $\psi$ o $\neg \psi$, con $\psi \in FORMAT_S$. \\\

Ahora describimos las reglas para la construcción de \textit{tableaux} asociados a un conjunto de fórmulas $\Sigma$:
\begin{itemize}
    \item Las reglas $R_{ini}, R_{hip}, R_{\sigma}, R_{\alpha}, R_{\beta}$.
    \item \textit{Regla} $\gamma$, $R_{\gamma}$: Sea 
    \begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \gamma \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head]                                           & {}
\end{tikzcd}
\end{center}
\textit{tableau} de $\Sigma$, donde $\gamma$ es $\gamma$-fórmula y $\gamma(t)$ su versión simplificada. Entonces 
\begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \gamma \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head] \arrow[d, no head]                        & {} \\
                      & \gamma(t)                                                        &   
\end{tikzcd}
\end{center}
es \textit{tableau} de $\Sigma$.$\\$
Es decir, siempre podemos añadir a una rama abierta una versión simplificada de cualquier $\gamma$-fórmula suya y seguimos teniendo un \textit{tableau} de $\Sigma$.

    \item \textit{Regla} $\delta$, $R_{\delta}$: Sea 
    \begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \delta \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head]                                           & {}
\end{tikzcd}
\end{center}
\textit{tableau} de $\Sigma$, donde $\delta$ es $\delta$-fórmula y $\delta(c)$ su versión simplificada. Entonces 
\begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \delta \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head] \arrow[d, no head]                        & {} \\
                      & \delta(c)                                                        &   
\end{tikzcd}
\end{center}
es \textit{tableau} de $\Sigma$.$\\$
Es decir, siempre que tengamos una rama abierta que contenga una $\delta$-fórmula, $\delta$, la podemos extender con su versión simplificada $\delta(c)$, siendo $c \in C_A$ nueva en tal rama, y seguimos teniendo un \textit{tableau} de $\Sigma$.

    \item Dado un axioma de igualdad, $\theta \in EQ_S$, la \textit{regla} $\theta$: Sea 
\begin{center}
\begin{tikzcd}
                                           & {} \arrow[d, no head] &                        \\
{} \arrow[ru, no head] \arrow[rr, no head] & {}                    & {} \arrow[lu, no head]
\end{tikzcd}
\end{center}
\textit{tableau} de $\Sigma$. Entonces 
\begin{center}
\begin{tikzcd}
                                           & {} \arrow[d, no head] &                        \\
{} \arrow[ru, no head] \arrow[rr, no head] & {} \arrow[d, no head] & {} \arrow[lu, no head] \\
                                           & \theta               &                       
\end{tikzcd}
\end{center}
Es decir, siempre podemos introducir cada axioma de igualdad $\theta$ a una rama.
\end{itemize}

El siguiente ejemplo muestra por qué, al aplicar la regla $\delta$, la constante auxiliar introducida en la rama debe ser nueva en ella.

\begin{example}
Consideremos el siguiente razonamiento:
\begin{center}
\syllog{Alguien mató a Trotsky} 
{Stalin pagó a alguien} 
{Stalin pagó a alguien que mató a Trotsky}
\end{center}

Lo formalizamos como:
\begin{center}
\syllog{$\varphi_1$: $\exists x \, M(x, Trotsky)$}
{$\varphi_2$: $\exists x \, P(Stalin, x)$}
{$\psi$: $\exists x \,  M(x, Trotsky) \land P(Stalin, x)$}
\end{center}

Es decir, tenemos el conjunto $\Sigma = \{\varphi_1, \varphi_2, \neg \psi \}$.

\begin{comment}
\begin{tikzcd}
{1.\neg\exists x M(x, Trotsky)\land P(Stalin, x)} \arrow[d, "hip(1)"']                                        &  &                                        \\
{2.  \exists x M(x, Trotsky)} \arrow[d, "hip(2)"']                                                            &  &                                        \\
{3.  \exists x P(Stalin, x)} \arrow[d, "{\delta, 2}"']                                                        &  &                                        \\
{4. M(Mercader, Trotsky)} \arrow[d, "{\delta, 3}"']                                                           &  &                                        \\
{5. P(Stalin, Mercader)} \arrow[d, "{\gamma, 1}"']                                                            &  &                                        \\
{6. \neg P(Stalin, Mercader) \land M(Mercader, Trotsky)} \arrow[dd, "{\beta, 6}"'] \arrow[rrdd, "{\beta, 6}"] &  &                                        \\
                                                                                                              &  &                                        \\
{7. \neg P(Stalin, Mercader) \#5, 7}                                                                          &  & {8. \neg M(Mercader, Trotsky) \#4, 8 }
\end{tikzcd}
\end{comment}
\begin{center}
\includegraphics[scale = 0.36]{figures/tableau3.png}
\end{center}

En el punto 4 hemos aplicado correctamente una regla $\delta$ introduciendo la constante auxiliar $Mercader$, y en el 5 hemos vuelto a introducirla por la misma regla, es decir, hemos introducido una constante auxiliar no nueva en la rama. Esto nos ha llevado al absurdo de que la deducción original era válida.  
\end{example}

\begin{example}
Un ejemplo sencillo. Veamos si es válida la siguiente deducción:

\begin{center}
\syllog{Algunos niños son buenos} 
{Todo lo bueno se come} 
{Algunos niños se comen}
\end{center}
Que formalizamos como:
\begin{center}
\syllog{$\varphi_1$: $\exists x \, (ni(x)\land bu(x))$}
{$\varphi_2$: $\forall x \, (bu(x)\to co(x))$}
{$\psi$: $\exists x \, (ni(x)\land co(x))$}
\end{center}

Es decir, en este caso, $\Sigma = \{\varphi_1, \varphi_2, \neg \psi \}$. Veamos un tableau cerrado de $\Sigma$:

\begin{comment}
\begin{tikzcd}
1.\exists x (ni(x)\land bu(x)) \arrow[d]                                          &                                                                       \\
2.  \forall x (bu(x)\to co(x)) \arrow[d]                                          &                                                                       \\
3.  \neg\exists x (ni(x)\land co(x)) \arrow[d, "{\delta, 1}"']                    &                                                                       \\
4. ni(Pepe)\land bu(Pepe) \arrow[d, "{\alpha, 4}"']                               & \text{(Donde $Pepe\in C_A$)}                                         \\
5. ni(Pepe) \arrow[d]                                                             &                                                                       \\
6. bu(Pepe) \arrow[d, "{\gamma,2,pepe/x}"]                                        &                                                                       \\
7.bu(Pepe)\to co(Pepe) \arrow[rd, "{\beta,7}"] \arrow[d, "{\beta,7}"]             &  \\
9.co(Pepe) \arrow[d, "{\gamma,3,pepe/x}"]                                         & {\neg bu(Pepe)\#6,8}                                                  \\
10.\neg(ni(pepe)\lor co(Pepe)) \arrow[d, "{\beta, 10}"] \arrow[rd, "{\beta, 10}"] &                                                                       \\
{12.\neg co(Pepe)\#9,12}                                                          & {11.\neg ni(Pepe)\#5,11}                                             
\end{tikzcd}
\end{comment}

\begin{center}
\includegraphics[scale = 0.44]{figures/tableau4.png}
\end{center}
\end{example}


\subsection{Corrección}

Tal y como hicimos en el método de los \textit{tableaux} para lógica proposicional, dados $\Phi \subseteq FORM_S$ y $\varphi \in FORM_S$, escribimos $\Phi \vdash_{tb} \varphi$ cuando existe un \textit{tableau} cerrado para $\Phi \cup \{\neg \varphi\}$.

Recordemos del capítulo anterior que decimos del método de los \textit{tableaux} que tiene \textit{corrección} si $\Phi \vdash_{tb} \varphi$ implica $\Phi \vDash \varphi$, y decimos que tiene \textit{completitud} si $\Phi \vDash \varphi$ implica $\Phi \vdash_{tb} \varphi$.\\
Vamos a comprobar que el método de los \textit{tableaux} de primer orden tiene ambas propiedades, empezando por la corrección.

Comencemos con el siguiente:

\begin{lema}\label{eq}
Para todo $\theta \in EQ_S$, $\vDash \theta$. 
\end{lema}
\begin{proof} \mbox{}
\begin{itemize}
        \item[(RF)] $\forall x \, x \doteq x$ es tautología ya que dada una interpretación $\mathfrak{I}$, se cumple $\mathfrak{I}[a/x] \vDash x \doteq x$ para todo $a \in A$, ya que obviamente $a=a$.
        \item[(IM)] $\forall x \, \forall y \, x \doteq y \rightarrow y \doteq x$ es tautología ya que, dada una interpretación $\mathfrak{I}$, se cumple $\mathfrak{I}[a/x][b/y] \vDash x \doteq y \rightarrow y \doteq x$ para todo $a \in A$, ya que si $a=b$, $\mathfrak{I}[a/x][b/y]$ verifica $x \doteq y$ y $y \doteq x$, por tanto verifica $x \doteq y \rightarrow y \doteq x$. Si $x\neq y$, $\mathfrak{I}[a/x][b/y]$ no verifican $x \doteq y$ ni $y \doteq x$, por tanto de nuevo verifica $x \doteq y \rightarrow y \doteq x$.
        \item[(TR)] $\forall x \, \forall t \, \forall z \, x \doteq y \land y \doteq z \rightarrow x \doteq z$ es una tautología. Este caso se demuestra de forma similar a los anteriores, comprobando que $\mathfrak{I}[a/x][b/y][c/z]$ siempre verifica $x \doteq y \land y \doteq z \rightarrow x \doteq z$. En este caso habría 8 casos, pero se puede hacer dividiendo en los casos $a\neq b$, $a=b\neq c$, $a=b=c$.
        \item[(ST_{1})] Sea $f|_n \in Fn_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \rightarrow f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n)$$ es una tautología. Se omite la demostración.
        \begin{comment}
        Este caso se demuestra por inducción en $n$.
        \begin{itemize}
            \item Caso base: Para cualquier constante (función 0-aria) $a$, cualquier interpretación verifica $a\doteq a$.
            \item Caso inductivo: Supongamos que cualquier función $n-1$-aria lo cumple. Sea f una función $n$-aria y sea una interpretación $\mathfrak{I}$. Entonces, $\mathfrak{I}$ verifica la función que buscamos si y solo si para todo $a\in A$, $\mathfrak{I}[a/x_1]$ verifica $$\forall x_2, \dots, \forall x_n \, \forall y_2, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \rightarrow f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
            Esta fórmula es equivalente a:
            $$\forall x_2, \dots, \forall x_n \, \forall y_2, \dots, \forall y_n \, \neg (x_1\doteq y_1)\lor(\bigvee\limits_{i = 1}^{n} \neg (x_i \doteq y_i)) \lor f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
            Como ninguna variable aparece libre, por la ley (9) de equivalencia lógica esto equivale a:
            $$\neg (x_1\doteq y_1)\lor\forall x_2, \dots, \forall x_n \, \forall y_2, \dots, \forall y_n \, (\bigvee\limits_{i = 1}^{n} \neg (x_i \doteq y_i)) \lor f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
        \end{itemize}
        \end{comment}
        \item[(ST_{2})] Sea $p|_n \in Pd_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \land  p(x_1, \dots, x_n) \rightarrow p(y_1, \dots, y_n)$$ es una tautología. Se omite la demostración.
\end{itemize}
\end{proof}

El siguiente resultado es fundamental, nos permite extender una rama satisfactible del \textit{tableaux} a otra que también lo es:

\begin{prop}\label{aaa}
Sea $S$ signatura. Sean $\Phi \subseteq FORM_S$ y $\mathfrak{I}$ $S$-interpretación tales que $\mathfrak{I} \vDash \Phi$. Entonces existe una $S$-interpretación $\mathfrak{I}'$ tal que $\mathfrak{I} \sim_{\varphi} \mathfrak{I}'$ para toda $\varphi \in \Phi$ de modo que:
\begin{enumerate}
    \item Sea $\sigma \in \Phi$ fórmula simplificable. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\sigma_1 \}$, con $\sigma \sim \sigma_1$ la simplificación de $\sigma$.
    \item Sea $\alpha \in \Phi$ una $\alpha$-fórmula. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\alpha_1, \alpha_2 \}$, con $\alpha \sim \alpha_1 \land \alpha_2$ la descomposición de $\alpha$.
    \item Sea $\beta \in \Phi$ una $\beta$-fórmula. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\beta_1\}$ o $\mathfrak{I}' \vDash \Phi \cup \{\beta_2\}$, con $\beta \sim \beta_1 \lor \beta_2$ la descomposición de $\beta$.
    \item Sean $\gamma \in \Phi$ $\gamma$-fórmula, $t \in TERM_S$. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\gamma(t)\}$.
    \item Sean $\delta \in \Phi$ $\delta$-fórmula, $c \in C_A$ constante auxiliar nueva en $\Phi$. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\delta(c)\}$.
    \item Para cada $\theta \in EQ_S$, $\mathfrak{I}' \vDash \Phi \cup \{ \theta\}$.
\end{enumerate}
\end{prop}
\begin{proof} \mbox{}

(1), (2) y (3) son análogos a los de lógica proposicional. Basta hacer que $\mathfrak{I} = \mathfrak{I}'$ y el hecho de que:$$\sigma \sim \sigma_1, \quad \alpha \sim \alpha_1 \land \alpha_2, \quad \beta \sim \beta_1 \lor \beta_2.$$ \\

Veamos (4). Sea $\gamma \in \Phi$ y supongamos, sin pérdida de generalidad, que $\gamma$ es de la forma $\forall x \, \varphi$ (si fuese de la forma $\neg \exists x \, \varphi$, usamos que esto es equivalente a $\forall x \, \neg \varphi$ y hacemos $\psi := \neg \varphi$). Tomemos $\mathfrak{I}' = \mathfrak{I}$.

\noindent Consideremos el conjunto soporte de la interpretación $\mathfrak{I}$, $A$. Sea $t \in TERM_S$, y sea $a := t^{\mathfrak{I}} \in A$. Dado que $\forall x \, \varphi \in \Phi$, por hipótesis, $\mathfrak{I} \vDash \forall x \, \varphi$, y por tanto, $\mathfrak{I}[b/x] \vDash \varphi$ para todo $b \in A$, en especial, $\mathfrak{I}[a/x] \vDash \varphi$. Por el Lema de Sustitución, $\mathfrak{I} \vDash \varphi[t/x]$, y notando que $\varphi[t/x] = \gamma(t)$, obtenemos el resultado. \\

Veamos (5). Sea $\delta \in \Phi$ y supongamos que $\delta = \exists x \, \varphi$, para $\varphi \in FORM_S$ (en caso de que $\delta$ fuese de la forma $\neg \forall x \, \varphi$, entonces sería equivalente a $\exists x \, \neg \varphi$ y, haciendo que $\psi := \neg \varphi$, habríamos terminado). Sea $c \in C_A$ constante auxiliar nueva en $\Phi$.

\noindent Consideremos de nuevo el conjunto soporte de $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$, $A$. Como $\exists x \, \varphi \in \Phi$, por hipótesis, $\mathfrak{I} \vDash \exists x \, \varphi$, luego existe $a \in A$ tal que $\mathfrak{I}[a/x] \vDash \varphi$. Ahora definimos $\mathfrak{A}'$ como $\mathfrak{A}$ excepto que $c^{\mathfrak{A}'} = a$. Definamos $\mathfrak{I}' := \langle \mathfrak{A}', \sigma \rangle$. 

\noindent Al ser $c$ constante nueva para $\Phi$, es decir, para cada elemento de $\Phi$, tenemos que $\mathfrak{I} \sim_{\psi} \mathfrak{I}'$, para cada $\psi \in \Phi$, por tanto se cumple $\mathfrak{I} \vDash \psi$ para toda $\psi\in\Phi$. Por el Lema de Sustitución, 
$$(\varphi[c/x])^{\mathfrak{I}'} = \varphi^{\mathfrak{I}'[c^{\mathfrak{I}'}/x]} = \varphi^{\mathfrak{I}'[a/x]}.$$
Y dado que $\mathfrak{I}'[a/x] \sim_{\varphi} \mathfrak{I}[a/x]$ por ser $c$ nueva, aplicando una vez más el Lema de Sustitución, 
$$\varphi^{\mathfrak{I}'[a/x]} = \varphi^{\mathfrak{I}[a/x]} = V.$$
Lo que nos da el resultado. \\

Finalmente, (6) se deduce de \ref{eq}. 
\end{proof}

Del siguiente resultado se deducirá como corolario la corrección del método de los \textit{tableaux} de primer orden:

\begin{theorem}\label{bbb}
Sea $S$ signatura. Sea $\Phi \subseteq FORM_S$ conjunto de fórmulas satisfactible y $T$ un tableau abierto finito para $\Phi$. Entonces existe una rama abierta de $T$, $r$, tal que $\Gamma_r$ es satisfactible.
\end{theorem}
\begin{proof}
Demostremos que existe una $S$-interpretación $\mathfrak{I}$ y una tal rama $r$ de modo que $\mathfrak{I} \vDash \Phi$ y $\mathfrak{I} \vDash \Gamma_r$. 

Al ser $T$ finito, se ha construido en un número finito de reglas $R_{ini}, R_1,  \dots, R_{n}$, dando lugar la sucesión de \textit{tableaux} $T_0, T_1, \dots, T_n = T$. Por tanto, procedemos por inducción sobre $n$. \\

Si $n=0$, entonces $T_0$ es un \textit{tableaux} inicial, es decir, tiene la forma 
\begin{tikzcd}
\varphi_1 \arrow[d, no head]          \\
\varphi_2 \arrow[dd, no head, dotted] \\ 
                                      \\
\varphi_k                            
\end{tikzcd}.
Entonces $r$ es la única rama disponible, y $\Gamma_r = \{ \varphi_1, \dots, \varphi_k\} \subseteq \Phi$, por lo que, dado que $\Phi$ es satisfactible, $\Gamma_r$ lo es. Por tanto, hemos encontrado una $S$-interpretación que verifica lo deseado. \\

Sea $n>0$ y supongamos que el resultado es cierto para el \textit{tableau} $T_{n-1}$ y veamos que lo es para $T_n$. Al aplicar la regla $R_n$ a $T_{n-1}$, extendemos una rama $r$. Además, por hipótesis de inducción, hay una rama $r'$ tal que $\Gamma_{r'}$ es satisfactible. \\

Si $r \neq r'$ entonces $r'$ es rama de $T_n$ y, como hemos dicho, verifica que $\Gamma_{r'}$ es satisfactible, con lo que obtenemos el resultado. \\

Si $r = r'$, debemos distinguir los siguientes casos, dependiendo de qué tipo de regla es $R_n$:
\begin{enumerate}
    \item $R_n$ es una regla inicial, de tipo $\sigma$, $\alpha$ o $\beta$. La demostración es análoga a la que vimos en lógica proposicional.
    \item $R_n$ es una regla $\delta$. Sea $\Gamma_{r}^{k}$ el conjunto de fórmulas de la rama $r$ en el árbol $k$-ésimo. Entonces existe $\delta \in \Gamma_{r}^{n-1}$ tal que $\Gamma_{r}^{n} = \Gamma_{r}^{n-1} \cup \{\delta(c)\}$, con $c \in C_A$ nueva en $r$. Por hipótesis de inducción, existe una $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \Phi$ y $\mathfrak{I} \vDash \Gamma_{r}^{n-1}$.
    
    Por \ref{aaa}, existe $\mathfrak{I}'$ tal que $\mathfrak{I}' \vDash \Gamma_{r}^{n-1} \cup \{\delta(c)\}$, es decir, tal que $\mathfrak{I}' \vDash \Gamma_{r}^{n}$. Al ser $c$ nueva en $r$, $c \notin voc(\psi)$, para cada $\psi \in \Phi$, por tanto como en la prueba de \ref{aaa} vimos que $\mathfrak{I}'$ solo difiere de $\mathfrak{I}$ en $c$, $\mathfrak{I}' \sim_{\psi} \mathfrak{I}$, y por tanto $\mathfrak{I}' \vDash \psi$, es decir, $\mathfrak{I}' \vDash \Phi$.
    
    \item $R_n$ es una regla $\gamma$. Existe $\gamma \in \Gamma_{r}^{n-1}$ tal que $\Gamma_{r}^{n} = \Gamma_{r}^{n-1} \cup \{\gamma(t)\}$, siendo $t \in TERM_S$. Por hipótesis, existe una $S$-interpretación $\mathfrak{I}$ con $\mathfrak{I} \vDash \Phi$ y $\mathfrak{I} \vDash \Gamma_{r}^{n-1}$. 
    
    Por la prueba de \ref{aaa}, la misma $\mathfrak{I}$ cumple $\mathfrak{I} \vDash \Gamma_{r}^{n-1} \cup \{\gamma(t)\}$, por tanto $\mathfrak{I} \vDash \Gamma_{r}^n$.
    
    \item $R_n$ es una regla $\theta$, con $\theta \in EQ_S$. Entonces, $\Gamma_{r}^{n} = \Gamma_{r}^{n-1} \cup \{\theta\}$. Por hipótesis de inducción, existe una $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \Phi$ y, $\mathfrak{I} \vDash \Gamma_{r}^{n-1}$. Por tanto, $\mathfrak{I} \vDash \Gamma_{r}^n$.
\end{enumerate}
\end{proof}

\begin{cor}\label{ccc}
Sea $S$ signatura. Si $\Phi \subseteq FORM_S$ y $\Phi$ tiene un \textit{tableau} cerrado, entonces $\Phi$ es insatisfactible. 
\end{cor}
\begin{proof}
Basta notar que este enunciado es la forma contrapositiva de \ref{bbb}.
\end{proof}

Finalmente, obtenemos el resultado al que hemos dedicado esta subsección:

\begin{cor}(Corrección)
Sean $S$ signatura, $\Phi \subseteq FORM_S$, $\varphi \in FORM_S$. Entonces, si $\Phi \vdash_{tb} \varphi$, entonces $\Phi \vDash \varphi$.
\end{cor}
\begin{proof}
Si $\Phi \vdash_{tb} \varphi$, entonces $\Phi \cup \{\neg \varphi \}$ tiene un \textit{tableau} cerrado y, por \ref{ccc}, $\Phi \cup \{\neg \varphi \}$ es insatisfactible. Por el resultado análogo a \ref{insat} para lógica de primer orden, esto implica que $\Phi \vDash \varphi$.
\end{proof}


\subsection{Completitud}

El estudio de la completitud va a ser más complicado que en lógica proposicional. Para poder estudiarla, vamos a necesitar introducir una serie de nociones fundamentales de teoría de grafos: 

\begin{defs}\mbox{}
\begin{enumerate}[label=\bold{\arabic*})]
    \item Un \textit{grafo no dirigido} es un par ordenado $T = \langle N, E \rangle$, donde $N$ es el conjunto de \textit{nodos} y $E$ es el conjunto de \textit{aristas}, que son pares sin ordenar de nodos.
    \item Un camino es una sucesión de $(\geq1)$ aristas $(a_1,\dots,a_n)$ de forma que el segundo vértice de $a_i$ es el primero de $a_{i+1}$ para $i=1,\dots,n$. Llamamos a $n$ \textit{longitud del camino}. 
    \item Decimos que el camino es simple si cada vértice del camino solo aparece hasta dos veces, una al final de una arista y otra al principio de la siguiente. Decimos que un camino es un ciclo si es simple y el primer vértice de la primera arista es el segundo vértice de la última arista.
    \item Decimos que un grafo es \textit{acíclico} si no tiene ciclos. Decimos que un grafo es \textit{conexo} si para cada par de nodos hay un camino entre ellos.
    \item Un \textit{árbol (libre)} es un grafo no dirigido conexo y acíclico. Equivalentemente, es un grafo tal que entre cada par de sus nodos hay un solo camino simple que los une.
    \item Sea $G = \langle V, E\rangle$ grafo no dirigido. Se llama \textit{grado} de $v \in V$, $deg(v)$, al número de elementos de $E$ que inciden sobre él.
    \item Se llama \textit{profundidad} del árbol (libre) $T = \langle N, E \rangle$ a $|N|$.
\end{enumerate}
\end{defs}


Se tienen las siguientes propiedades:

\begin{prop}
Sea $T = \langle N, E \rangle$ un grafo:
\begin{enumerate}
    \item Si $T$ es un árbol y le quitamos un elemento de $E$, $T$ deja de ser conexo.
    \item Si $T$ tiene finitos nodos, $T$ es un árbol si y solo si $|E| = |N| - 1$.
\end{enumerate}
\end{prop}
\begin{proof}
Se omite la demostración.
\end{proof}

\begin{defs}\mbox{}
\begin{enumerate}
    \item Un árbol $T = \langle N, E \rangle$ se llama \textit{árbol con raíz} si se selecciona un elemento especial de $N$, llamado \textit{raíz} de $T$.
    \item Sea $T = \langle N, E \rangle$ árbol con raíz $n_0$. Se llama \textit{altura} de $n \in N$, $h(n)$, a la longitud del único camino simple que une $n_0$ con $n$.
    \item Sea $T = \langle N, E \rangle$ árbol de raíz $n_0$. Se dice que $n_1\in N$ es \textit{hijo de} $n$ si hay una arista que conecta $n$ y $n_1$ y $h(n_1)=h(n)+1$. Se dice que $n_1$ y $n_2$ son \textit{hermanos} si son hijos del mismo nodo.
    \item Sea $T = \langle N, E \rangle$ árbol de raíz $n_0$. Llamamos \textit{rama} finita a un camino simple desde $n_0$ que no está contenido en ningún otro camino simple desde $n_0$. Una rama infinita será una sucesión de aristas $a_1,a_2,\dots$ tal que el primer vértice de $a_{n+1}$ es el segundo de $a_n$ para todo $n$, que parte desde $n_0$ y en que no se repiten vértices.
\end{enumerate}
\end{defs}

De ahora en adelante consideraremos árboles con una raíz determinada.

\begin{definition}
Sean $T_1 := \langle N_1, E_1 \rangle$, $T_2 :=  \langle N_2, E_2 \rangle$ dos árboles con la misma raíz. Decimos que $T_1$ \textit{está incluido en} $T_2$, $T_1 \leq T_2$, si:
\begin{itemize}
    \item $N_1 \subseteq N_2$.
    \item $E_1 \subseteq E_2$.
\end{itemize}
\end{definition}

\begin{definition}
Sean $T_0, \dots, T_k, \dots$ árboles tales que $T_0 \leq \dots \leq T_k \leq \dots$. Definimos:
$$\lim_{n \in \mathbb{N}} T_n := \langle N, E \rangle$$
siendo $N := \bigcup_{n\in \mathbb{N}} N_{n}$ y $E := \bigcup_{n\in \mathbb{N}} E_{n}$ y con la misma raíz que la de T_0.
\end{definition}

\begin{prop}
Sea $T_0 \leq \dots \leq T_k \leq \dots$ sucesión de árboles. Sea $T := \lim_{n \in \mathbb{N}} T_n$. Entonces:
\begin{enumerate}
    \item $T_i \leq T$, para todo $i \in \mathbb{N}$.
    \item $T$ es un árbol.
\end{enumerate}
\end{prop}
\begin{proof}\mbox{}
\begin{enumerate}
    \item Se sigue de las definiciones anteriores.
    \item Comencemos demostrando que $T = \langle T, N\rangle$ es conexo. Sean $n_1, n_2 \in N$. Como $N := \bigcup_{n\in \mathbb{N}} N_{n}$ y $N_i \subseteq N_j$, para todo $i \leq j$, existe $k \in \mathbb{N}$ tal que $n_1, n_2 \in N_k$. Al ser $T_k = \langle N_k, E_k\rangle$ conexo, existe un camino en $T_k$ que une $n_1$ y $n_2$. Al ser $E_k \subseteq E$ por definición, también es un camino en $T$, lo que nos da la conexión de $T$. \\
    
    Supongamos que existen dos nodos $n_1, n_2 \in N$ tales que existen dos caminos distintos $e_1, \dots, e_l$ y $f_1, \dots, f_k$ que los conectan. Es claro, razonando igual que antes, que existe $i \in \mathbb{N}$ tal que $n_1, n_2 \in N_i$ y $e_1, \dots, e_l, f_1, \dots, f_k \in E_i$ y, al ser $T_i = \langle N_i, E_i\rangle$ árbol, $e_1, \dots, e_l$ y $f_1, \dots, f_k$ son iguales, lo que implica que $T$ sea acíclico.
\end{enumerate}
\end{proof}

Nótese que nuestros \textit{tableaux} son árboles con raíz. Además, se cumplirá que las ramas cerradas serán siempre finitas.


Necesitamos el siguiente resultado técnico de la teoría de grafos:

\begin{theorem}(Lema de König para árboles)\label{konig}
\mbox{}
Sea $T$ un árbol con raíz con infinitos nodos tal que cada nodo tiene finitos hijos. Entonces $T$ tiene una rama infinita.
\end{theorem}
\begin{proof}
Se omite la demostración.
\end{proof}


\begin{comment}
\begin{theorem}(Lema de König)\label{konig}
Sea $G$ grafo que verifica lo siguiente:
\begin{enumerate}
    \item $G$ es conexo.
    \item $G$ es \textit{localmente finito}, es decir, cada nodo es vecino de finitos vértices.
    \item $G$ es \textit{infinito}, es decir, su conjunto de nodos es infinito.
\end{enumerate}
Entonces $G$ contiene un camino simple infinito.

En especial, cada árbol infinito contiene o un nodo de grado infinito o un camino simple infinito.
\end{theorem}
\begin{proof}
Se omite la demostración.
\end{proof}
\end{comment}


\begin{prop}
Si $T$ es tableau cerrado, es finito.
\end{prop}
\begin{comment}
\begin{proof}
Observemos que, en todo \textit{tableau}, el número máximo de hijos de cada nodo es dos: los que se pueden obtener por la aplicación de una regla $\beta$.
Al ser $T$ cerrado, en cada rama suya $r$ hay dos nodos $n_1, n_2$ que son contradictorios. Definimos:
$$h_r := max\{h(n_1), h(n_2)\}$$
$$h := max\{h_r \, | \, r \text{ rama de } T\}$$

Si $h$ fuese infinito, el árbol tendría ramas $r$ con $h_r$ arbitraria. Como cada nodo tiene a lo sumo dos hijos, por \ref{konig} debe tener una camino simple infinito, esto es, una rama infinita. Esta rama infinita no puede estar cerrada, ya que las ramas cerradas tienen siempre profundidad finita.

Por tanto, $h$ es finito y, del hecho de que cada nodo tiene a lo sumo dos hijos deducimos que tiene que ser finito.
\end{proof}
\end{comment}
\begin{proof}
Usaremos reducción al absurdo. Sea $T$ un \textit{tableaux} infinito cerrado. Observemos que, en todo \textit{tableau}, el número máximo de hijos de cada nodo es dos: los que se pueden obtener por la aplicación de una regla $\beta$. Por tanto, por $\ref{konig}$ el \textit{tableau} contiene una rama infinita. Esto contradice el hecho de que todas las ramas cerradas son finitas.
\end{proof}