\chapter{Lógica de primer orden}

\section{Introducción}

En el anterior capítulo, construimos con éxito un lenguaje formal que nos permitía traducir frases informales del español a expresiones formales, además de formalizar los conceptos de implicación y equivalencia lógica. Sin embargo, se puede reprochar que la lógica proposicional es demasiado \textit{simple} en el sentido siguiente: $\\$

Consideremos el silogismo: 

\begin{center}
\syllog{Todo hombre es mortal}
{Sócrates es un hombre}
{Sócrates es mortal}
\end{center}

En este caso, podríamos pensar que la consecuencia lógica se trata de una del tipo $p \land (p \rightarrow q) \rightarrow q$. Pero, por otro lado, parece evidente que depende de elementos más básicos que los símbolos de proposición. Sería, entonces, más conveniente una formalización del tipo:

\begin{center}
\syllog{\textit{Para todo} $x$, si $x$ \textit{es hombre} entonces \textit{es mortal}}
{\textit{Sócrates es hombre}}
{\textit{Sócrates es mortal}}
\end{center}

Hemos empleado los términos `hombre', `mortal' y `para todo' en un sentido puramente formal. Como ocurría con las proposiciones, existen múltiples frases y expresiones informales distintas que corresponden al silogismo que acabamos de exponer.$\\$

A continuación vamos a definir, igual que en lógica proposicional, el alfabeto que usaremos para construir fórmulas en los lenguajes de primer orden. Pero además, en este caso, habrá múltiples lenguajes de primer orden, y cada uno tendrá unos ciertos elementos que lo caractericen, que resumimos en el concepto de `signatura':


\begin{comment}
En general, los componentes en los que se pueden reducir las proposiciones son de tres tipos: \textit{constantes}, como `Sócrates' en el ejemplo anterior; \textit{predicados}, como `hombre' y `mortal' en el silogismo anterior y \textit{funciones}, como la función `sucesor de $n$' en los números naturales. De forma similar a como hicimos con los símbolos de proposición, definimos una serie de símbolos para referirnos a las anteriores clases de elementos. Esto nos lleva a la siguiente
\end{comment}

\begin{definition}\label{sig}
Una \textit{signatura} $S$ es una tupla $\langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ donde:
\begin{itemize}
    \item $Ct_{S}$ es el conjunto de símbolos de constante.
    \item $Fn_{S}$ es el conjunto de símbolos de función con determinada aridad\footnote{Por ahora, nos referimos por \textit{aridad} de un símbolo de función o de predicado como el número de argumentos que admite. Más adelante especificaremos lo que significa esta idea.}.
    \item $Pd_{S}$ es el conjunto de símbolos de predicado con determinada aridad.
\end{itemize} 
Dado un símbolo $\Gamma$ de función o predicado, denotamos por $\Gamma|_{n}$ que es $n$-ario.
\end{definition}


\begin{example}\label{nat}
La signatura $Nat := \langle \{0\}, \{+|_2, s|_1\}, \{<|_2\}\rangle$ para los números naturales. Es decir:
\begin{itemize}
    \item Hay un símbolo de constante, $0$.
    \item Los símbolos de función serán el símbolo de función binaria $+$, que llamaremos `suma', y el símbolo de función 1-aria, $s$, que llamaremos `sucesor'.
    \item Tenemos un símbolo de predicado 2-ario, $<$.
\end{itemize}
A veces en la signatura $Nat$ incluiremos un otro símbolo de función 2-aria, $*$, que llamaremos `producto'.
\end{example}

\begin{definition}
Dada la signatura $S$, definimos el alfabeto asociado como:
$$A_{S} := Ct_S \cup Fn_S \cup Pd_S \cup Var \cup \{\neg, \land, \lor, \rightarrow, \leftrightarrow, \top, \bot \} \cup \{(, )\} \cup \{\exists, \forall\} \cup \{ \doteq \},$$
donde:
\begin{itemize}
    \item $Ct_S,Fn_S,Pd_S$ vienen dados por \ref{sig}.
    \item $Var$ son los símbolos de variable: \{$x,y,z,x_1,\dots\}$.
    \item $\neg, \land, \lor, \rightarrow, \leftrightarrow, \top, \bot,(,)$ son los símbolos de conectiva y los paréntesis, al igual que en lógica proposicional.
    \item $\forall$ (para todo) y $\exists$ (existe) son los \textit{cuantificadores lógicos}. Llamamos a $\forall$ \textit{cuantificador universal} y a $\exists$ \textit{cuantificador existencial}.
    \item $\doteq$, el símbolo de igualdad. Usamos $\doteq$ en vez de $=$ para distinguirlo de la igualdad de fórmulas. Por ejemplo, si escribimos $\varphi = t \doteq s$ queremos decir que $\varphi$ es igual a $t \doteq s$.
\end{itemize}

\end{definition}

Como ocurría con las proposiciones, nos interesa distinguir las expresiones del alfabeto anterior que están bien formadas. Para ello, primero necesitaremos definir los \textit{términos}, que podemos interpretar como las expresiones que usaremos para nombrar objetos, y después las \textit{fórmulas}, expresiones que usaremos para denotar afirmaciones sobre los objetos.

\begin{definition}\label{term}
Dada la signatura $S$, el \textit{conjunto de términos} de $S$, $TERM_S$, es el menor subconjunto de $A_{S}^*$ que verifica:\footnote{Recordemos que $A_{S}^*$ es el cierre de Kleene de $A_{S}$, como definimos en \ref{klee}.}
\begin{enumerate}
    \item $Ct_S\subseteq TERM_S$.
    \item $Var\subseteq TERM_S$.
    \item Si $f|_{n} \in Fn_S$ y $t_1, .., t_n \in TERM_S$, entonces $f(t_1, ..., t_n) \in TERM_S$. 
\end{enumerate}
\end{definition}

Si $f$ es una función 2-aria, a veces usaremos la notación tradicional $xfy$ en vez de $f(x,y)$. Por ejemplo, en $Nat$ diremos $x+y$ en vez de $+(x,y)$.

\begin{example}
Siguiendo con la signatura $Nat$, algunos ejemplos de elementos de $TERM_{NAT}$ serían  $0, s(s(0)), x, y, z,+(s(s(0)), s(0))$ y $s(+(x,s(s(s(0)))))$.
\end{example}

La siguiente proposición nos da una definición constructiva de $TERM_S$: 
\begin{prop}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos los conjuntos:
$$T_{S}^{0} := Ct_S \cup Var$$
$$T_{S}^{n+1} := T_{S}^{n} \cup \bigcup\limits_{k \in \mathbb{N}} \{f(t_1, \dots, t_k) \, \, | \, \, t_1, \dots, t_k \in T_{S}^{n}, \, f|_{k} \in Fn_S\}$$
Entonces $\bigcup\limits_{i \in \mathbb{N}} T_{S}^{i} = TERM_S$.
\end{prop}
\begin{proof}
La demostración es análoga a la de \ref{ind}.
\end{proof}

Ahora podemos construir fórmulas a partir de estos elementos básicos que ya hemos definido. Comenzamos por 

\begin{definition}
Dada la signatura $S$, el \textit{conjunto de fórmulas atómicas} de $S$, $FORMAT_S$, es el menor subconjunto de $A_{S}^*$ que verifica:
\begin{enumerate}
    \item Si $t_1, t_2 \in TERM_S$, $t_1 \doteq t_2 \in FORMAT_S$.
    \item Si $R|_{n} \in Pd_S$ y $t_1, \dots, t_n \in TERM_S$, $R(t_1, \dots, t_n) \in FORMAT_S$.
    \item $\top, \bot \in FORMAT_S$.
\end{enumerate}
\end{definition}

Si $R$ es un predicado 2-ario, a veces usaremos la notación tradicional $xRy$ en vez de $R(x,y)$. Por ejemplo, en $Nat$ diremos $x<y$ en vez de $<(x,y)$.

\begin{definition}\label{form}
Dada la signatura $S$, el \textit{conjunto de fórmulas} de $S$, $FORM_S$, es el menor subconjunto de $A_{S}^*$ que verifica:
\begin{enumerate}
    \item $FORMAT_S \subseteq FORM_S$.
    \item Si $\varphi_1, \varphi_2 \in FORM_S$, $(\neg \varphi_1), (\varphi_1 \square \varphi_2) \in FORM_S$.
    \item Si $x \in Var$ y $\varphi \in FORM_S$, $(Qx \, \varphi) \in FORM_S$, siendo $Q\in\{\forall,\exists\}$
\end{enumerate}
\end{definition}

A partir de ahora, usaremos para mayor brevedad el símbolo $Q$ como intercambiable por $\forall$ o $\exists$ a no ser que se indique lo contrario.$\\$

Damos una definición constructiva de $FORM_S$:

\begin{prop}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos los conjuntos:
$$F_{S}^{0} := FORMAT_S$$
$$F_{S}^{n+1} := F_{S}^{n} \cup \{ (\neg \varphi) \, | \, \varphi \in F_{S}^{n}\} \cup \{ (\varphi \square \psi) \, | \, \varphi, \psi \in F_{S}^{n}\} \cup \{(Qx \, \varphi) \, | \, x \in Var, \, \varphi \in F_{S}^{n}\}$$
Entonces $\bigcup\limits_{i \in \mathbb{N}} F_{S}^{i} = FORM_S$.
\end{prop}
\begin{proof}
De nuevo, la demostración es análoga a la de \ref{ind}.
\end{proof}

\begin{comment}
Respecto a la omisión de paréntesis, todo se hará de forma similar a lógica proposicional, aunque tenemos que añadir que conectivas y cuantificadores se aplicarán en este orden: $\neg, \land, \lor, \to, \leftrightarrow, \forall, \exists$.
\end{comment}

\section{Inducción estructural y recursión}

Tal y como ocurría con la lógica proposicional, la recursión y la inducción estructural son las dos principales herramientas empleadas en las definiciones y demostraciones de la lógica de primer orden. Sin embargo, ahora tenemos que tratar separadamente los conjuntos $TERM_S$ y $FORM_S$ asociados a cierta signatura $S$. $\\$

Comenzamos con los teoremas de inducción estructural y recursión para $TERM_S$, dada una signatura $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$:

\begin{prop}(Inducción estructural)
Sean $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ una signatura y $P$ una propiedad. Si se cumple que:
\begin{enumerate}
    \item $P$ es válida para todo elemento de $T_{S}^{0}$.
    \item Sea $f|_k \in Fn_S$. Si $P$ es válida para todo elemento de $T_{S}^{n}$, entonces es válida para $f(t_1, \dots t_k)$, con $t_1, \dots, t_k \in T_{S}^{n}$.
\end{enumerate}
Entonces $P$ es válida para todo elemento de $TERM_S$.
\end{prop}
\begin{proof}
Si la propiedad $P$ cumple 1, 2 y 3, entonces el conjunto de términos que cumplen $P$ cumple las tres propiedades de la definición \ref{term}, por tanto contiene a $TERM_S$.
\end{proof}



 \begin{prop} El esquema de definición recursiva da como resultado una única función, es decir, dadas:
\begin{enumerate}
    \item $F_0: Ct_S \cup Var \rightarrow A$.
    \item $F_f: A^{k} \rightarrow A$, para cada función $f|_{k} \in Fn_S$.
\end{enumerate}
existe una única función $F: TERM_S \rightarrow A$ tal que:
\begin{enumerate}
    \item $F(t)=F_0(t)$, para todo $t\in Ct_S \cup Var$.
    \item $F(f(t_1,\dots,t_k))=F_f(F(t_1),\dots,F(t_k))$, para cada $f|_{k} \in Fn_S$ y $t_1,\dots,t_k\in TERM_S$.
\end{enumerate}
\begin{proof}
Se omite la demostración.
\end{proof}
\end{prop}


\begin{example}
Una función que nos será de utilidad será $var$, que nos lleva cada elemento de $TERM_S$ al conjunto de variables que aparecen en él. La definimos recursivamente como:
\begin{enumerate}
    \item Caso base: $var_{0}: Ct_S \cup Var \rightarrow \mathcal{P} (Var)$, dada por $var_{0}(c) = \emptyset$ si $c \in Ct_S$ y $var(x) = \{x\}$ si $x \in Var$.
    \item Caso recursivo: Dado $f|_{k} \in Fn_S$, $var_{f}: (\mathcal{P} (Var))^{k} \rightarrow \mathcal{P} (Var)$, dada por $var_{f}(f(t_1, \dots t_k)) = \bigcup\limits_{i = 1}^{k} var(t_i)$.
\end{enumerate}
\end{example}


Ahora enunciamos los teoremas de inducción estructural y recursión para $FORM_S$, dada una signatura $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$:

\begin{prop}(Inducción estructural)
Sean $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ una signatura y $P$ una propiedad. Si se cumple que:
\begin{enumerate}
    \item $P$ es válida para todo elemento de $FORMAT_S$.
    \item Si $\varphi_1, \varphi_2 \in FORM_S$ y se cumplen $P(\varphi_1),P(\varphi_2)$, entonces tenemos $P((\neg \varphi_1))$ y  $P((\varphi_1 \square \varphi_2))$.
    \item Si $x \in Var$ y $\varphi \in FORM_S$, y se cumple $P(\varphi)$, entonces tenemos $P((Q x \varphi))$.
\end{enumerate}
Entonces $P$ es válida para todo elemento de $FORM_S$.
\end{prop}
\begin{proof}
Si la propiedad $P$ cumple 1, 2 y 3, entonces el conjunto de términos que cumplen $P$ cumple las tres propiedades de la definición \ref{form}, por tanto contiene a $FORM_S$.
\end{proof}

 \begin{prop} El esquema de definición recursiva da como resultado una única función, es decir, dadas:
\begin{enumerate}
    \item $F_{AT}: FORMAT_S \rightarrow A$.
    \item $F_{\neg}: A \rightarrow A$.
    \item $F_{\square}: A \times A \rightarrow A$.
    \item $F_Q:Var\times A\rightarrow A$.
\end{enumerate}
existe una única función $F: FORM_S \rightarrow A$ tal que:
\begin{enumerate}
    \item $F(\varphi) = F_{AT}(\varphi)$, para toda $\varphi \in FORMAT_S$.
    \item $F((\neg \varphi)) = F_{\neg}(F(\varphi))$.
    \item $F((\varphi_1 \square \varphi_2)) = F_{\square}(F(\varphi_1), F(\varphi_2))$.
    \item $F((Qx\,\varphi))=F_Q(x,F(\varphi))$.
\end{enumerate}
\begin{proof}
     Se omite la demostración.
\end{proof}
\end{prop}


\begin{example}
Extendamos la función $var$ al conjunto $FORM_S$. Por comodidad, omitimos las funciones auxiliares:
\begin{enumerate}
    \item Caso base:
        \begin{itemize}
            \item $var(\top) = var(\bot) = \emptyset.$
            \item Sean $p|_k \in Pd_S$, $t_1, \dots t_n \in TERM_S$. Entonces $var(p(t_1, \dots t_n)) = \bigcup\limits_{i=1}^{k} var(t_i).$
            \item Sean $t, s \in TERM_S$. Entonces $var(t \doteq s) = var(t) \cup var(s)$.
        \end{itemize} 
    \item Caso recursivo:
        \begin{itemize}
            \item $var((\neg \varphi)) = var(\varphi)$.
            \item $var((\varphi \square \psi)) = var(\varphi) \cup var(\psi)$.
            \item $var((Qx \, \varphi)) = \{x\} \cup var(\varphi)$.
        \end{itemize}
\end{enumerate}
\end{example}




\section{Eliminación de paréntesis}
Al igual que en lógica proposicional, nos serán útiles unas reglas de omisión de paréntesis:
\begin{enumerate}
    \item Los paréntesis externos pueden omitirse. Esto no da lugar a ambigüedad.
    \item Conectivas y cuantificadores se aplicarán en este orden: $\neg, \land, \lor, \to, \leftrightarrow, \forall, \exists$.
    \item Cuando hay varias conectivas del mismo tipo seguidas, se asocia siempre por la izquierda.
\end{enumerate}
Un par de ejemplos de aplicación de estas reglas en fórmulas con cuantificadores:$\\[8pt]$
\begin{equation*}
\begin{array}{ccc}
     \forall x \, \varphi\to\psi  & \text{es} & (\forall x \, (\varphi\to\psi))\\
     \exists x \, \varphi \land \forall y \psi & \text{es} & 
     (\exists x \, (\varphi \land (\forall y \psi)))\\
\end{array}
\end{equation*}






\section{Variables libres y ligadas}
Consideremos las siguientes fórmulas de primer orden:
\begin{itemize}
    \item $\forall x\;x\doteq3$
    \item $x\doteq3$
\end{itemize}
La primera fórmula se puede traducir informalmente como `para todo $x$, $x$ es igual a 3'. Intuitivamente, podemos decir que el cuantificador $\forall$ está afectando al significado de $x$. Sin embargo, en la segunda fórmula, $x$ no aparece afectada por ningún cuantificador. En general, diremos que una variable es \textit{ligada} en una fórmula $\varphi$ si siempre aparece afectada por un cuantificador, como en el primer ejemplo, y diremos que es una variable \textit{libre} en $\varphi$ si aparece alguna vez sin estar afectada por un cuantificador. Formalicemos estos conceptos:


\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos recursivamente la función $lib: FORM_S \rightarrow \mathcal{P}(Var)$, que nos lleva cada fórmula al conjunto de sus variables libres:
\begin{enumerate}
    \item Caso base: Sea $\varphi \in FORMAT_S$. Entonces, $lib(\varphi) = var(\varphi)$.
    \item Caso recursivo: 
        \begin{itemize}
            \item $lib(\neg \varphi) = lib(\varphi)$.
            \item $lib(\varphi \square \psi) = lib(\varphi) \cup lib(\psi)$.
            \item $lib(Qx \, \varphi) = lib(\varphi) \setminus \{x\}$.
        \end{itemize}
\end{enumerate}
\end{definition}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos el \textit{conjunto de sentencias}, $SENT_S$, como el formado por aquellas $\varphi \in FORM_S$ tales que $lib(\varphi) = \emptyset$.
\end{definition}


\section{Álgebras e interpretaciones}
Hasta ahora hemos venido considerando cuestiones sintácticas sobre las fórmulas. Lo que queremos ahora es abordar su semántica, esto es, su comportamiento cuando les damos una interpretación determinada. Comenzamos definiendo la estructura de la que tomamos el significado de los símbolos de una signatura:

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ una signatura. Una \textit{S-álgebra} o \textit{S-estructura} es una tupla 
$$\mathfrak{A} := \langle A, \{ c^{\mathfrak{A}} \, | \, c \in Ct_S\}, \{f^{\mathfrak{A}} \, | \, f \in Fn_S\}, \{p^{\mathfrak{A}} \, | \, p \in Pd_S\}\rangle$$
De modo que:
\begin{itemize}
    \item $A$, el \textit{conjunto soporte}, verifica que $A \neq \emptyset$.
    \item Si $c \in Ct_S$, $c^{\mathfrak{A}} \in A$.
    \item Si $f|_k \in Fn_S$, $f^{\mathfrak{A}}: A^{k} \rightarrow A$.
    \item Si $p|_k \in Pd_S$, $p^{\mathfrak{A}}: A^{k} \rightarrow Bool$.
\end{itemize}
\end{definition}
$\\$
Por convenio, un símbolo $f$ de función 0-aria tendrá asociada una función $f^{\mathfrak{A}}: \{\emptyset\} \rightarrow A$. Es decir, será una función desde el conjunto de un elemento $\{\emptyset\}$ en $A$. Está claro que estas funciones pueden identificarse con elementos de $A$, identificando $f$ con $f(\emptyset)$. De modo que las funciones 0-arias van a llevar a cabo esencialmente la misma función que las constantes, y de hecho, aunque aquí usaremos constantes, toda la lógica de primer orden se puede desarrollar sin constantes usando funciones 0-arias.$\\$

De igual forma, un símbolo $p$ de predicado 0-ario tendrá asociada una función $p^{\mathfrak{A}}: \{\emptyset\} \rightarrow Bool$. Es decir, igual que con las funciones 0-arias, podemos asociar a cada predicado 0-ario un valor de $Bool$, $V$ o $F$. En esto se asemejarán a los símbolos de proposición de lógica proposicional, a los cuales asignábamos (mediante las asignaciones de verdad) un valor de $Bool$.

\begin{example}\label{anat}
Consideremos la signatura $Nat := \langle \{0\}, \{+|_2,*|_2, s|_1\}, \{<|_2\}\rangle$ que presentamos previamente. La forma natural (aunque no la única) de asignar significados a estos símbolos sería la $S$-álgebra:
$$\mathfrak{A}_{Nat} := \langle \mathbb{N}, \{ 0^{\mathfrak{A}_{Nat}}\}, \{+^{\mathfrak{A}_{Nat}},*^{\mathfrak{A}_{Nat}},s^{\mathfrak{A}_{Nat}}\}, \{<^{\mathfrak{A}_{Nat}}\}\rangle \text{, donde:}$$
\begin{itemize}
    \item $\mathbb{N}$ es el conjunto de los números naturales: $\{0,1,2,\dots\}$.
    \item $0^{\mathfrak{A}_{Nat}}$ será el número natural 0.
    \item $+^{\mathfrak{A}_{Nat}}$ será la función suma en los naturales, $+:\mathbb{N}^2\to\mathbb{N};(m,n)\mapsto m+n$. $\\$
    $*^{\mathfrak{A}_{Nat}}$ será la función producto en los naturales, $*:\mathbb{N}^2\to\mathbb{N};(m,n)\mapsto m*n$.$\\$
    $s^{\mathfrak{A}_{Nat}}$ será la función sucesor en los naturales, $s:\mathbb{N}\to\mathbb{N};n\mapsto n+1$.
    \item $<^{\mathfrak{A}_{Nat}}:\mathbb{N}^2\to Bool$ será la función que cumpla $<^{\mathfrak{A}_{Nat}}(m,n)=V$ si $m<n$, y $<^{\mathfrak{A}_{Nat}}(m,n)=F$ en caso contrario. Es decir, $<^{\mathfrak{A}_{Nat}}(m,n)$ será verdadero si y solo si $m<n$.
\end{itemize}
Es importante distinguir los símbolos de sus objetos asociados, ya que en algunos casos, como 0, suma y producto en este ejemplo, representamos igual ambas cosas. En el siguiente ejemplo habrá una clara distinción entre los símbolos y sus objetos asociados.
\end{example}


\begin{example}Vamos a ver otro ejemplo de álgebra para la signatura $Nat$.
Sea $\mathfrak{A} = \langle \{\bigtriangleup, \bigcirc \}, \{0^{\mathfrak{A}}\}, \{+^{\mathfrak{A}}, *^{\mathfrak{A}}, s^{\mathfrak{A}}\}, \{<^{\mathfrak{A}}\}\rangle$ tal que:
\begin{itemize}
    \item $0^{\mathfrak{A}} = \bigtriangleup$.
    \item $s^{\mathfrak{A}}: \{\bigtriangleup, \bigcirc \} \rightarrow \{\bigtriangleup, \bigcirc\}$, $x \mapsto \bigtriangleup$.
    \item $*^{\mathfrak{A}}, +^{\mathfrak{A}}: \{\bigtriangleup, \bigcirc \}^{2} \rightarrow \{\bigtriangleup, \bigcirc\}$, $(x, y) \mapsto \bigcirc$.
    \item $<^{\mathfrak{A}}: \{\bigtriangleup, \bigcirc \}^{2} \rightarrow Bool$, $(x, y) \mapsto V$.
\end{itemize}
Como veremos en interpretaciones, la expresión $$*(+(s(0), s(0)), s(s(s(0))))$$ en $\mathfrak{A}$ se refiere a $\bigcirc$ ya que, desarrollando, esa expresión corresponde a:
\begin{align*}
&*^{\mathfrak{A}}(+^{\mathfrak{A}}(s^{\mathfrak{A}}(0^{\mathfrak{A}}), s^{\mathfrak{A}}(0^{\mathfrak{A}})), s^{\mathfrak{A}}(s^{\mathfrak{A}}(s^{\mathfrak{A}}(0^{\mathfrak{A}}))))\\
&=*^{\mathfrak{A}}(+^{\mathfrak{A}}(s^{\mathfrak{A}}(\bigtriangleup), s^{\mathfrak{A}}(\bigtriangleup)), s^{\mathfrak{A}}(s^{\mathfrak{A}}(s^{\mathfrak{A}}(\bigtriangleup))))\\
&=*^{\mathfrak{A}}(+^{\mathfrak{A}}(\bigtriangleup, \bigtriangleup), s^{\mathfrak{A}}(s^{\mathfrak{A}}(\bigtriangleup)))\\
&=*^{\mathfrak{A}}(\bigcirc, s^{\mathfrak{A}}(\bigtriangleup))\\
&=*^{\mathfrak{A}}(\bigcirc, \bigtriangleup)\\
&=\bigcirc
\end{align*}


, mientras que en $\mathfrak{A}_{Nat}$ podemos ver de forma similar que la expresión se refiere a $6$.$\\$
Sin embargo, si intentamos ver a qué se refiere el término $+(s(x), s(0))$, tiene una variable que todavía no sabemos como interpretar. Informalmente, las variables suelen referirse a objetos que no hemos determinado. En nuestra segunda álgebra, $x$ podría referirse a $\bigtriangleup$ o a $\bigcirc$. En ambos casos, $+(s(x), s(0))$ se refiere a $\bigcirc$ en $\mathfrak{A}$. Sin embargo, en $\mathfrak{A}_{Nat}$, el valor que tome la expresión dependerá del valor que tome la $x$.
\end{example}

Lo anterior muestra que es necesario definir una función especial para dotar de significado a las variables:

\begin{definition}
Sea $S$ signatura. Una \textit{S-interpretación} es una tupla $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$ con:
\begin{itemize}
    \item $\mathfrak{A}$ es \textit{S-álgebra} de soporte $A$.
    \item $\sigma : Var \rightarrow A$.
\end{itemize}
\end{definition}

\begin{example}
Así, en el ejemplo anterior, tomando una $Nat$-interpretación $\sigma: Var \rightarrow \mathbb{N}$, podemos interpretar $+(s(x), s(0))$: si por ejemplo $\sigma(x) = 7$, estamos `asignando' a la variable $x$ el valor 7, por tanto a la expresión total le asignaríamos el valor:
\begin{align*}
&+^{\mathfrak{A}_{Nat}}(s^{\mathfrak{A}_{Nat}}(\sigma(x)), s^{\mathfrak{A}_{Nat}}(0^{\mathfrak{A}_{Nat}}))\\
&=+^{\mathfrak{A}_{Nat}}(s^{\mathfrak{A}_{Nat}}(7), s^{\mathfrak{A}_{Nat}}(0))\\
&=+^{\mathfrak{A}_{Nat}}(8,1)\\
&=9
\end{align*}
\end{example}

Ahora extendemos este concepto a términos, como ya hemos hecho intuitivamente en los dos últimos ejemplos:

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura, $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$ $S$-interpretación. Definimos recursivamente la \textit{interpretación de los términos} $t \in TERM_S$, $t^{\mathfrak{I}}$, como:
\begin{itemize}
    \item Caso base:
        \begin{itemize}
            \item Si $c \in Ct_S$, $c^{\mathfrak{I}} = c^{\mathfrak{A}}$.
            \item Si $x \in Var$, $x^{\mathfrak{I}} = \sigma(x)$.
        \end{itemize}
    \item Caso recursivo:
        \begin{itemize}
           \item Si $f|_k \in Fn_S$, $t_1, \dots, t_k \in TERM_S$, $f(t_1, \dots, t_k)^{\mathfrak{I}} = f^{\mathfrak{A}}(t_{1}^{\mathfrak{I}}, \dots, t_{k}^{\mathfrak{I}})$.
        \end{itemize}
\end{itemize}
\end{definition}

Antes de pasar a la interpretación de fórmulas, conviene establecer la siguiente notación: dada la $S$-interpretación $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$, por el símbolo $\mathfrak{I}[a/x]$ designamos la $S$-interpretación determinada por $\langle \mathfrak{A}, \sigma[a/x]\rangle$.\footnote{Recordemos que denotamos respectivamente por $f[b/a](x)$ a $f(x)$, si $x \neq a$, y a $b$, si $x = a$.}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$, $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$ $S$-interpretación, con $A$ conjunto soporte.  Definimos recursivamente la \textit{interpretación de las fórmulas} $\varphi \in FORM_S$, $\varphi^{\mathfrak{I}}$, como:
\begin{itemize}
    \item Caso base:
        \begin{itemize}
            \item Si $\varphi = \top$, $\varphi^{\mathfrak{I}} = V$.
            \item Si $\varphi = \bot$, $\varphi^{\mathfrak{I}} = F$.
            \item Si $\varphi = t \doteq s$, con $t, s \in TERM_S$; entonces $\varphi^{\mathfrak{I}} = V$ si $t^{\mathfrak{I}} = s^{\mathfrak{I}}$ y $\varphi^{\mathfrak{I}} = F$ en otro caso.
            \item Si $\varphi = p(t_1, \dots, t_k)$, con $t_1, \dots, t_k \in TERM_S$, $p|_k \in Pd_S$; entonces $\varphi^{\mathfrak{I}} = V$ si $p^{\mathfrak{A}}(t_{1}^{\mathfrak{I}}, \dots, t_{k}^{\mathfrak{I}}) = V$ y $\varphi^{\mathfrak{I}} = F$ en otro caso. 
        \end{itemize}
    \item Caso recursivo:
        \begin{itemize}
            \item Si $\varphi = \neg \varphi_1$,  $\varphi^{\mathfrak{I}} = v_{\neg}(\varphi_{1}^{\mathfrak{I}})$.
            \item Si $\varphi = \varphi_1 \square \varphi_2$,  $\varphi^{\mathfrak{I}} = v_{\square}(\varphi_{1}^{\mathfrak{I}}, \varphi_{2}^{\mathfrak{I}})$.
            \item Si $\varphi = \forall x \, \varphi_1$, con $x \in Var$; entonces $\varphi^{\mathfrak{I}} = V$, si para todo $a \in A$, $\varphi_1^{\mathfrak{I}[a/x]} = V$; y $\varphi^{\mathfrak{I}} = F$ en otro caso.
            \item Si $\varphi = \exists x \, \varphi_1$, con $x \in Var$; entonces $\varphi^{\mathfrak{I}} = V$, si existe $a \in A$ tal que $\varphi_1^{\mathfrak{I}[a/x]} = V$; y $\varphi^{\mathfrak{I}} = F$ en otro caso.
        \end{itemize}
\end{itemize}
\end{definition}

Describamos el concepto de \textit{consecuencia lógica} para lógica de primer orden: 

\begin{definition}
Sea $S$ signatura. Sean $\Phi \subseteq FORM_S$, $\varphi \in FORM_S$, $\mathfrak{I}$ $S$-interpretación. Decimos que $\mathfrak{I}$ \textit{satisface} $\varphi$, $\mathfrak{I} \vDash \varphi$, si $\varphi^{\mathfrak{I}} = V$. 
Análogamemente, $\mathcal{\A}$ \textit{satisface} $\Phi$, $\mathfrak{I} \vDash \Phi$, si $\psi^{\mathfrak{I}} = V$, para cada $\psi \in \Phi$.
\end{definition}

\begin{definition}
Sea $S$ signatura. Dados $\Phi \subseteq FORM_S$ y $\varphi \in FORM_S$, decimos que $\varphi$ es \textit{consecuencia lógica} de $\Phi$, $\Phi\vDash\varphi$, si toda $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I}\vDash \Phi$ verifica $\mathfrak{I} \vDash \varphi$.
\end{definition}

Está claro que $\emptyset\vDash\varphi$ es equivalente a que toda interpretación verifica $\varphi$. En estos casos, podemos escribir $\vDash\varphi$ en vez de $\emptyset\vDash\varphi$.

\begin{definition}
Sea $S$ signatura. $\Phi \subseteq FORM_S$ se dice \textit{satisfactible} si existe una $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \Phi$. $\Phi$ se dice \textit{insatisfactible} si no existe tal $S$-interpretación $\mathfrak{I}$.
\end{definition}
$\\$
Fijada una signatura $S$, podemos clasificar cada fórmula $\varphi$ como:
\begin{itemize}
    \item \textit{Satisfactible}, si existe alguna $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \varphi$. 
    \begin{itemize}
        \item \textit{Tautología}, si $\mathfrak{I} \vDash \varphi$ para toda $S$-interpretación $\mathfrak{I}$, es decir, $\vDash\varphi$
        \item \textit{Contingencia}, si es satisfactible pero no tautología.
    \end{itemize}
    \item \textit{Contradicción}, si no es satisfactible. 
\end{itemize}

$\\$
Veamos algunos ejemplos:

\begin{example}
La fórmula $\varphi=\exists x \, x \doteq x$ siempre es una tautología.
En esta afirmación juega un papel importante que el conjunto soporte, $A$, no es vacío. Por tanto dada una signatura $S$ y una $S$-interpretación $\mathfrak{I}$, existe un elemento $a\in A$. De modo que llamando $\varphi_1=x \doteq x$, tenemos que $\varphi_1^{\mathfrak{I}[a/x]} = V$, ya que se cumple que $a=a$. Como hay un elemento $a\in A$ tal que $\varphi_1^{\mathfrak{I}[a/x]} = V$, tenemos que $\varphi^{\mathfrak{I}} = V$. De hecho, como esto sucede para todo elemento $a\in A$, también será una tautología la fórmula $\forall x \, x \doteq x$.
\end{example}

\begin{example}\label{complejo}
Consideremos la signatura $S:= \langle \emptyset, \emptyset, \{ R|_2\}\rangle$ y las fórmulas 
$$\varphi := \exists x \, \forall y \, R(x, y)$$
$$\psi := \forall y \, \exists x \, R(x, y)$$
Veamos que $\varphi \vDash \psi$. Para ello, vamos a ver qué significan $\varphi$ y $\psi$ en términos del conjunto soporte.

Sea $\mathfrak{I}$ $S$-interpretación de soporte $A$ tal que $\mathfrak{I} \vDash \varphi$. Entonces, existe un $a \in A$ tal que $\mathfrak{I}[a/x] \vDash \forall y \, R(x, y)$. Por tanto, para todo $b \in A$ se cumple que $\mathfrak{I}[a/x][b/y] \vDash R(x, y)$. 

Es decir, $\mathfrak{I} \vDash \varphi$ significa que existe un elemento $a\in A$ que está relacionado con todos los elementos del conjunto soporte $A$ mediante la relación $R$.$\\$

Ahora, sea $\mathfrak{I}$ $S$-interpretación de soporte $A$ tal que $\mathfrak{I} \vDash \psi$. Entonces, para todo $c \in A$, $\mathfrak{I}[c/y]\vDash \exists x \, R(x, y)$. De la misma forma, existe $d \in A$ tal que $\mathfrak{I}[c/y][d/x] \vDash R(x, y)$. 

Es decir, $\mathfrak{I} \vDash \psi$ significa que para todo elemento $c\in A$ existe algún elemento $d$ del conjunto soporte $A$ tal que $d$ está relacionado con $c$.$\\$

Claramente, si tenemos el primer caso tenemos el segundo, porque para todo elemento $c\in A$, $a$ está relacionado con $c$, por tanto existe algún elemento relacionado con $c$. Por tanto, $\varphi \vDash \psi$.$\\[5pt]$

Veamos que la implicación recíproca, $\psi \vDash \varphi$, no es cierta en general. 

Para ello damos el siguiente contraejemplo: sea el $S$-álgebra $\mathfrak{A} := \langle A, \emptyset, \{R^{\mathfrak{A}} \}\rangle$, con $A :=  \{1, 2, 3 \}$ y $R^{\mathfrak{A}}: A^{2} \rightarrow Bool$ dada por $(1, 2), (2, 3), (3, 1) \mapsto V$, $(x, y) \mapsto F$ en otro caso\footnote{En ocasiones es más cómoda la notación conjuntista, es decir, en vez de dar $R^\mathfrak{A}$ como una función $R^{\mathfrak{A}}:A^n\to Bool$, podemos darla como el subconjunto $\{a\in\mathfrak{A}^n\, | \, R^{\mathfrak{A}}(a)=V\}$. Por ejemplo, en este caso, $R^{\mathfrak{A}}$ sería el conjunto $\{(1, 2), (2, 3), (3, 1)\}$}.$\\$

Sea $\mathcal{G}=\langle\mathfrak{A},\sigma \rangle$ una $S$-interpretación. Evidentemente, para todo $a \in A$ existe $b \in A$ tal que $\mathcal{G}[a/y][b/x] \vDash R(x, y)$: si $a = 1$, $b = 3$; si $a = 2$, $b = 1$; si $a= 3$, $b = 2$. Por otro lado, es imposible que exista $c \in A$ tal que, para todo $d \in A$, $\mathfrak{I}[c/x][d/y] \vDash R(x, y)$, ya que ningún elemento está relacionado con todos. Por tanto $\mathcal{G}$ satisface $\psi$ pero no satisface $\varphi$.
\end{example}

\begin{example}
$\varphi_{=\infty} := (\exists z \, \forall x \, \neg f(x) \doteq z) \land (\forall x \, \forall y \, f(x) \doteq f(y) \rightarrow x \doteq y)$ es una contingencia. Nótese que nos dice que $f$ es (símbolo de) una función inyectiva y no sobreyectiva. En concreto, esto implica que el cardinal del conjunto soporte de cualquier $S$-álgebra inducida por una $S$-interpretación $\mathfrak{I}$ que satisface $\varphi_{=\infty}$ tiene que ser infinito. Esto se debe a que el símbolo de función $f$ tiene asociada una función $f^\mathfrak{A}:A\to A$ que es inyectiva y no sobreyectiva, lo cual no puede pasar si $A$ es finito.
\end{example}

\begin{example}
$\varphi_{=2} := (\exists x \, \exists y \, \neg x \doteq y) \land \forall z \, (z \doteq y \lor z \doteq x)$ es una contingencia. Nos dice, en concreto, que el cardinal del conjunto soporte de cualquier $S$-álgebra inducida por una $S$-interpretación tiene que ser igual a 2.
\end{example}


\subsection{Axiomas de Peano}
Recordemos la signatura $Nat$ definida en \ref{nat}. Este lenguaje fue introducido por Peano para describir los números naturales usando los símbolos de suma, producto, sucesor y menor o igual. Para describir los naturales podrían considerarse estos axiomas:
\begin{enumerate}
    \item $\forall x \; \neg s(x)\doteq 0$
    \item $\forall x \, \forall y \; s(x)\doteq s(y)\to x\doteq y$
    \item $\forall x \; x+0\doteq x$
    \item $\forall x \, \forall y \; x+s(y)\doteq s(x+y)$
    \item $\forall x \; x*0\doteq 0$
    \item $\forall x \, \forall y \; x*s(y)\doteq (x*y)+x$
    \item $\forall x \, \forall y \; (x<y \leftrightarrow \exists z \; x+s(z)\doteq y)$
\end{enumerate}
Llamamos $\Phi_N$ al conjunto de las anteriores sentencias.
Es fácil comprobar que en la $Nat$-álgebra $\mathfrak{A}_{Nat}$, introducida en \ref{anat}, cualquier interpretación satisface los axiomas de Peano. Sin embargo, también hay otras estructuras con esta propiedad. De hecho, como veremos en \ref{infnocat}, cualquier conjunto de sentencias que se cumplan en los naturales también se cumplirán en alguna estructura de conjunto soporte no numerable.

\begin{comment}
como la siguiente:
$$\mathcal{N}_2=\{\{0,1\}\times \mathbb{N},\{0^{\mathcal{N}_2}\},\{+^{\mathcal{N}_2},*^{\mathcal{N}_2},s^{\mathcal{N}_2}\},\{<^{\mathcal{N}_2}\}\}$$
siendo:
\begin{itemize}
    \item $0^{\mathcal{N}_2}=(0,0)$.
    \item $\begin{array}{clcl}
         +^{\mathcal{N}_2}:&(\{0,1\}\times \mathbb{N})\times(\{0,1\}\times \mathbb{N})&\to& \{0,1\}\times\mathbb{N};\\
         & ((x,m),(y,n))&\mapsto& (max(x,y),m+n)
    \end{array}.$
    \item $\begin{array}{clcl}
         *^{\mathcal{N}_2}:&(\{0,1\}\times \mathbb{N})\times(\{0,1\}\times \mathbb{N})&\to& \{0,1\}\times\mathbb{N};\\
         & ((x,m),(y,n))&\mapsto& (max(x*y,x),m*n)
    \end{array}.$
    \item $s^{\mathcal{N}_2}:\{0,1\}\times\mathbb{N}\to \{0,1\}\times\mathbb{N}; (x,m)\mapsto (x,m+1)$
    \item $<^{\mathcal{N}_2}((x,m),(y,n))=V$ si y solo si $x\leq y$ y $m<n$.
\end{itemize}

Donde hemos usado las operaciones $+,*$ habituales de los naturales, y $max(x,y)$ es 0 si $x,y$ son 0 y 1 si no.
\end{comment}




\section{Sustitución}

El ejemplo \ref{complejo} muestra que la determinación de la consecuencia lógica en particular y de la satisfactibilidad en general es una tarea costosa. Motivados por este hecho, investigamos relaciones sintácticas que nos permitan trabajar más cómodamente. Comenzamos por el concepto de \textit{sustitución}, que ya estuvo presente a lo largo del anterior capítulo. 

De ahora en adelante, denotamos vectores de elementos de un determinado conjunto con una raya horizontal sobre una letra. Normalmente empleamos la misma letra para referirnos a los elementos de tal vector. Por ejemplo, dada la signatura $S$ y el conjunto soporte de cierta $S$-álgebra, $A$, designamos $\bar{a} := (a_1, \dots, a_n)$ con $a_i \in A$, para todo $i =1, \dots, n$.\\

Comenzamos definiendo la sustitución para términos:

\begin{definition}
Sea $S$ signatura. Sean $t \in TERM_S$, $\bar{x} := (x_1, \dots, x_n)$ vector de $Var$ y $\bar{s} := (s_1, \dots, s_n)$ vector de $TERM_S$. Definimos la \textit{sustitución de} $\bar{x}$ \textit{por} \bar{s} \textit{en t} como:
\begin{itemize}
    \item Si $t \in Ct_S$, $t[\bar{s}/\bar{x}] = t$.
    \item Si $t \in Var$, $t[\bar{s}/\bar{x}] = s_i$ si $t = x_i$, para cierto $i$, y $t[\bar{s}/\bar{x}] = t$ si $t \neq x_i$, para todo $i$.
    \item $f(t_1, \dots t_n)[\bar{s}/\bar{x}] = f(t_1[\bar{s}/\bar{x}], \dots, t_n[\bar{s}/\bar{x}]).$
\end{itemize}
\end{definition}

Pasamos a la sustitución para fórmulas:
\begin{definition}
Sea $S$ signatura. Sean $\varphi \in FORM_S$, $\bar{x} := (x_1, \dots, x_n)$ vector de $Var$ y $\bar{s} := (s_1, \dots, s_n)$ vector de $TERM_S$. Definimos la \textit{sustitución de} $\bar{x}$ \textit{por} \bar{s} \textit{en $\varphi$} como:
\begin{itemize}
    \item Caso base:
    \begin{itemize}
        \item $\top[\bar{s}/\bar{x}]=\top$.
        \item $\bot[\bar{s}/\bar{x}]=\bot$.
        \item $(t_1\doteq t_2)[\bar{s}/\bar{x}]=(t_1[\bar{s}/\bar{x}]\doteq t_2[\bar{s}/\bar{x}])$.
        \item Si $p|_k\in Pd_S$ y $t_1,\dots,t_k\in TERM_S$, $p(t_1,\dots,t_k)[\bar{s}/\bar{x}]=p(t_1[\bar{s}/\bar{x}],\dots,t_k[\bar{s}/\bar{x}])$.
    \end{itemize}
    \item Caso recursivo:
    \begin{itemize}
        \item $(\neg\varphi)[\bar{s}/\bar{x}]=(\neg\varphi[\bar{s}/\bar{x}])$.
        \item $(\varphi_1\square\varphi_2)[\bar{s}/\bar{x}]=(\varphi_1[\bar{s}/\bar{x}]\square\varphi_2[\bar{s}/\bar{x}])$.
        \item $(Qx\;\varphi)[\bar{s}/\bar{x}]$ se define por casos:
        \begin{itemize}
            \item $Qx\;\varphi[\bar{s}/\bar{x}]$, si $x\notin\bar{x}$ y $x\notin\bigcup_{i=1}^nvar(s_i)$.
            \item $Qx\;\varphi[(s_1,\dots,s_{i-1},s_{i+1},\dots,s_n)/(x_1,\dots,x_{i-1},x_{i+1}\dots,x_n)]$, si $x=x_i\in\bar{x}$ y $x\notin\bigcup_{i=1}^nvar(s_i)$.
            \item $Qz\;\varphi[z/x][\bar{s}/\bar{x}]$ si $x\in\bigcup_{i=1}^nvar(s_i)$, siendo z una variable nueva, es decir, que no está en $\bar{x}$, $\bigcup_{i=1}^nvar(s_i)$ o $\varphi$.
        \end{itemize}
    \end{itemize}
\end{itemize}
\end{definition}

Si queremos sustituir un solo elemento, no un vector con varios, podemos omitir la raya horizontal sobre la letra (aunque también puede interpretarse como un vector de un elemento).\\

En ocasiones haremos uso de la siguiente notación:
$$f(t_1, \dots t_n)[\bar{s}/\bar{x}] = f(t_1, \dots t_n)[s_1/x_1, \dots, s_n/x_n].$$


\begin{example}
Si llamamos $a:= h(x)$ y $b:= f(x, y)$, entonces $$f(x, y)[h(x)/x, f(x, y)/y] = f(h(x), f(x, y)).$$
\end{example}


\begin{note}

Si no nombramos adecuadamente a las variables que estamos manipulando podemos llegar a tener una \textit{colisión}, es decir, que mediante una sustitución una variable pase de estar libre a estar ligada. 
 
Por ejemplo, sean $\varphi := \forall z \, p(x, z)$ y $t := f(z)$. Entonces la sustitución 
$$\varphi[t/x] = \forall z \, p(f(z), z)$$ 
daría lugar a una colisión porque la variable $z$ está libre en $t$, pero ligada al sustituirla en $\varphi$ por $x$. Por razones técnicas, esto no nos va a ser conveniente, es por eso que en estos casos cambiamos $t=f(z)$ por $f(y)$, obteniendo
$$\varphi[t/x] = \forall z \, p(f(y), z),$$
de modo que ya no tenemos el problema anterior.
\end{note}


\section{Lema de coincidencia}

Más adelante nos será útil el estudiar las relaciones entre diferentes interpretaciones y signaturas. Para ello nos será útil el lema de coincidencia, además de para demostrar el lema de sustitución de la próxima sección.

Comencemos con la siguiente

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos recursivamente el \textit{vocabulario para términos}, $voc$, como:
\begin{itemize}
    \item Caso base: 
        \begin{itemize}
            \item $voc(c) = \{c\}$, para todo $c \in Ct_S$.
            \item $voc(x) = \emptyset$, para todo $x \in Var$.
        \end{itemize}
    \item Caso recursivo: $voc(f(t_1, \dots, t_k)) = \{ f\} \cup \bigcup \limits_{i = 1}^{k} voc(t_i)$, con $f|_k \in Fn_S$, $t_1 \dots t_k \in TERM_S$.
\end{itemize}
\end{definition}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Definimos recursivamente el \textit{vocabulario para fórmulas}, $voc$, como:
\begin{itemize}
    \item Caso base:
        \begin{itemize}
            \item $voc(p(t_1, \dots, t_k)) = \{ p\} \cup \bigcup \limits_{i = 1}^{k} voc(t_i)$, con $p|_k \in Pd_S$, $t_1 \dots t_k \in TERM_S$.
            \item $voc(t \doteq s) = voc(t) \cup voc(s)$, con $t, s\in TERM_S$.
            \item $voc(\top) = voc(\bot) = \emptyset$.
        \end{itemize}
    \item Caso recursivo:
        \begin{itemize}
            \item $voc(\neg \varphi) = voc(\varphi)$, con $\varphi \in FORM_S$.
            \item $voc(\varphi \square \psi) = voc(\varphi) \cup voc(\psi)$, con $\varphi, \psi \in FORM_S$.
            \item $voc(Qx \, \varphi) = voc(\varphi)$, con $\varphi \in FORM_S$ y $x \in Var$.
        \end{itemize}
\end{itemize}
\end{definition}

Es decir, el vocabulario de una expresión, sea término o fórmula, es el conjunto de elementos de la signatura (símbolos de constante, función y predicado) que aparecen en ella.\\

Ahora consideramos:

\begin{definition}
Sean $S_1 = \langle Ct_{S_1}, Fn_{S_1}, Pd_{S_1}\rangle$, $S_2 = \langle Ct_{S_2}, Fn_{S_2}, Pd_{S_2}\rangle$ signaturas. Definimos la \textit{signatura unión} y la \textit{signatura intersección} respectivamente como:
$$S_1 \cup S_2 := \langle Ct_{S_1} \cup Ct_{S_2}, Fn_{S_1} \cup Fn_{S_2}, Pd_{S_1} \cup Pd_{S_2} \rangle, $$
$$S_1 \cap S_2 := \langle Ct_{S_1} \cap Ct_{S_2}, Fn_{S_1} \cap Fn_{S_2}, Pd_{S_1} \cap Pd_{S_2} \rangle. $$
\end{definition}

Ya que podemos obtener nuevas signaturas a partir de otras, es decir, nuevos conjuntos de símbolos, nos interesa estudiar qué ocurre con las interpretaciones, es decir, con los significados de los símbolos. Esto motiva la noción de \textit{coincidencia}:

\begin{definition}
Sean $S_1, S_2$ signaturas, $\mathfrak{I}_{1} = \langle \mathfrak{A}_1, \sigma_1 \rangle$ una $S_1$-interpretación y $\mathfrak{I}_{2} = \langle \mathfrak{A}_2, \sigma_2 \rangle$ una $S_2$-interpretación con el mismo conjunto soporte. Consideremos $S := S_1 \cap S_2$, $t \in TERM_S$. Decimos que $\mathfrak{I}_{1}$ \textit{y} $\mathfrak{I}_{2}$ \textit{coinciden en} $t$, $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, si:
\begin{enumerate}
    \item $c^{\mathfrak{I}_{1}} = c^{\mathfrak{I}_{2}}$, para todo $c \in voc(t)$, $c \in Ct_S$.
    \item $x^{\mathfrak{I}_{1}} = x^{\mathfrak{I}_{2}}$, para todo $x \in var(t)$.
    \item $f^{\mathfrak{A}_{1}} = f^{\mathfrak{A}_{2}}$, para todo $f \in voc(t)$, $f \in Fn_S$.
\end{enumerate}
\end{definition}

\begin{definition}
Sean $S_1, S_2$ signaturas, $\mathfrak{I}_{1} = \langle \mathfrak{A}_1, \sigma_1 \rangle$ una $S_1$-interpretación y $\mathfrak{I}_{2} = \langle \mathfrak{A}_2, \sigma_2 \rangle$ una $S_2$-interpretación con el mismo conjunto soporte. Consideremos $S := S_1 \cap S_2$, $ \varphi \in FORM_S$. Decimos que $\mathfrak{I}_{1}$ \textit{y} $\mathfrak{I}_{2}$ \textit{coinciden en} $\varphi$, $\mathfrak{I}_{1} \sim_{\varphi} \mathfrak{I}_{2}$, si:
\begin{enumerate}
    \item $c^{\mathfrak{I}_{1}} = c^{\mathfrak{I}_{2}}$, para todo $c \in voc(\varphi)$, $c \in Cts_S$.
    \item $\sigma_1(x) = \sigma_2(x)$, para todo $x \in lib(\varphi)$.
    \item $f^{\mathfrak{A}_{1}} = f^{\mathfrak{A}_{2}}$, para todo $f \in voc(\varphi)$, $f \in Fn_S$.
    \item $p^{\mathfrak{A}_{1}} = p^{\mathfrak{A}_{2}}$, para todo $p \in voc(\varphi)$, $p \in Pd_S$.
\end{enumerate}
\end{definition}

Ya estamos en disposición de enunciar el resultado que da nombre a esta sección:
\begin{theorem}(Lema de coincidencia)\label{coinc}
Sean $S_1, S_2$ signaturas, $\mathfrak{I}_{1} = \langle \mathfrak{A}_1, \sigma_1 \rangle$ una $S_1$-interpretación y $\mathfrak{I}_{2} = \langle \mathfrak{A}_2, \sigma_2 \rangle$ una $S_2$-interpretación con el mismo conjunto soporte. Consideremos $S := S_1 \cap S_2$.
\begin{enumerate}
    \item Si $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, con $t \in TERM_S$, entonces  $t^{\mathfrak{I}_{1}} = t^{\mathfrak{I}_{2}}$.
    \item Si $\mathfrak{I}_{1} \sim_{\varphi} \mathfrak{I}_{2}$, con $\varphi \in FORM_S$, entonces  $\varphi^{\mathfrak{I}_{1}} = \varphi^{\mathfrak{I}_{2}}$.
\end{enumerate}
\end{theorem}

Es decir, la primera parte nos dice que el significado de un término bajo una interpretación solo depende de los significados de las constantes, variables y funciones que aparecen en ella. La segunda nos dice algo parecido para fórmulas, solo que además nos dice que el significado de una fórmula \textbf{no} depende del significado de sus variables ligadas, solo importan las libres.
\begin{proof}\mbox{}
\begin{enumerate}
    \item Inducción estructural.
    Caso base:
    \begin{itemize}
        \item Si $t=p$ con $p\in Ct_S$, entonces $p\in voc(t)$, por tanto como $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, tenemos que $p^{\mathfrak{I}_1}=p^{\mathfrak{I}_2}$.
        \item Si $t=x$ con $x\in var$, entonces $x\in var(t)$, por tanto como $\mathfrak{I}_{1} \sim_{t} \mathfrak{I}_{2}$, se cumple $x^{\mathfrak{I}_1}=x^{\mathfrak{I}_2}$.
    \end{itemize} 
    Caso inductivo: $t=f(t_1,\dots,t_n)$, para $t_1,\dots,t_n\in TERM_S.$ Como $voc(t_i)\subseteq voc(t)$ y $var(t_i)\subseteq var(t)$, se cumple que $\mathfrak{I}_{1} \sim_{t_i} \mathfrak{I}_{2}, i=1,\dots,n$.\\
    Por tanto por inducción tenemos $t_i^{\mathfrak{I}_1}=t_i^{\mathfrak{I}_2}$, de modo que:
    $$f(t_1,\dots,t_n)^{\mathfrak{I}_1}=f^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1},\dots,t_n^{\mathfrak{I}_1})=f^{\mathfrak{A}_2}(t_2^{\mathfrak{I}_2},\dots,t_n^{\mathfrak{I}_2})=f(t_1,\dots,t_n)^{\mathfrak{I}_2},$$
    Donde hemos usado que $f\in voc(t)$, por tanto $f^{\mathfrak{A}_1}=f^{\mathfrak{A}_2}$.
    \item De nuevo, inducción estructural.
    Caso base:
    \begin{itemize}
        \item $\varphi$ es $\top$ o $\bot$. Caso obvio.
        \item $\varphi=t_1\doteq t_2$. En este caso, $voc(t_i)\subseteq voc(\varphi)$ y $var(t_i)\subseteq var(\varphi)$. De modo que $\mathfrak{I}_{1} \sim_{t_i} \mathfrak{I}_{2}, i=1,2$, y por el apartado anterior se cumple que $t_i^{\mathfrak{I}_{1}} = t_i^{\mathfrak{I}_{2}},i=1,2$. Por tanto $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $t_1^{\mathfrak{I}_{1}} = t_2^{\mathfrak{I}_{1}}$ si y solo si $t_1^{\mathfrak{I}_{2}} = t_2^{\mathfrak{I}_{2}}$ si y solo si $\varphi^{\mathfrak{I}_2}$.
        \item $\varphi=p(t_1,\dots,t_k)$. En este caso,igual que en el anterior tenemos $t_i^{\mathfrak{I}_1}=t_i^{\mathfrak{I}_2}$. Además, $p\in voc(\varphi)$, por tanto $p^{\mathfrak{A}_1}=p^{\mathfrak{A}_2}$. De modo que $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $p^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1},\dots,t_n^{\mathfrak{I}_1})=V$ si y solo si $p^{\mathfrak{A}_2}(t_1^{\mathfrak{I}_2},\dots,t_n^{\mathfrak{I}_2})=V$ si y solo si $\varphi^{\mathfrak{I}_2}$ es $V$.
    \end{itemize}
    Caso inductivo:
    \begin{itemize}
        \item $\varphi=\neg\varphi_1$. Entonces $voc(\varphi)=voc(\varphi_1)$ y $lib(\varphi)=lib(\varphi_1)$. Por tanto, $\mathfrak{I}_{1} \sim_{\varphi_1} \mathfrak{I}_{2}$, y por hipótesis de inducción, $\varphi_1^{\mathfrak{I}_1}=\varphi_1^{\mathfrak{I}_2}$. De modo que
        $\varphi^{\mathfrak{I}_1}=v_\neg(\varphi_1^{\mathfrak{I}_1})=v_\neg(\varphi_1^{\mathfrak{I}_2})=\varphi^{\mathfrak{I}_2}$.
        
        \item Si $\varphi=\varphi_1\square\varphi_2$. Igual que en el caso anterior, tenemos que $\varphi_i^{\mathfrak{I}_1}=\varphi_i^{\mathfrak{I}_2},i=1,2$. De modo que:
        $\varphi^{\mathfrak{I}_1}=v_\square(\varphi_1^{\mathfrak{I}_1},\varphi_2^{\mathfrak{I}_1})=v_\square(\varphi_1^{\mathfrak{I}_2},\varphi_2^{\mathfrak{I}_2})=\varphi^{\mathfrak{I}_2}$.
        
        \item $\varphi=\exists x \varphi_1$. Como $\mathfrak{I}_{1} \sim_{\varphi} \mathfrak{I}_{2}$, y tenemos $voc(\varphi)=voc(\varphi_1)$, $lib(\varphi)=lib(\varphi_1)\setminus \{x\}$, sabemos que $\mathfrak{I}_1[a/x]\sim_{\varphi_1}\mathfrak{I}_2[a/x]$, ya que la única diferencia de interpretaciones de $\mathfrak{I}_1$ y $\mathfrak{I}_2$ en $\varphi_1$ que no se da en $\varphi$ es en la variable $x$, y $\mathfrak{I}_1[a/x]$ y $\mathfrak{I}_2[a/x]$ coinciden en la variable $x$. Ahora,
        $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si existe $a\in A$ tal que $\varphi_1^{\mathfrak{I}_1[a/x]} = V$. Pero esto equivale a que exista $a\in A$ tal que $\varphi_1^{\mathfrak{I}_2[a/x]} = V$, es decir, a que $\varphi^{\mathfrak{I}_2}$ sea $V$.
        
        \item $\varphi=\forall x \varphi_1$. Igual que en el caso anterior, sabemos que $\mathfrak{I}_1[a/x]\sim_{\varphi_1}\mathfrak{I}_2[a/x]$. Ahora,
        $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si para todo $a\in A$ se cumple $\varphi_1^{\mathfrak{I}_1[a/x]} = V$. Pero esto equivale a que para todo $a\in A$ se cumpla $\varphi_1^{\mathfrak{I}_2[a/x]} = V$, lo cual equivale a que $\varphi^{\mathfrak{I}_2}$ sea $V$.
    \end{itemize}
\end{enumerate}
\end{proof}

\begin{example}
Sean $t \in TERM_S$, $\varphi \in FORM_S$ tales que existen $x_1, \dots, x_n \in Var$ de modo que $var(t) \subseteq \{x_1, \dots, x_n\}$ y $lib(\varphi) \subseteq \{x_1, \dots, x_n\}$. El Lema de Coincidencia nos dice que el significado que tome cada variable que no pertenezca a $\{x_1, \dots, x_n \}$ no afectará a los significados de $t$ y $\varphi$.\\
Es decir, dada una interpretación $\mathfrak{I}=\langle \mathfrak{A}, \sigma \rangle$, $\varphi^\mathfrak{I}$ solo depende de $\mathfrak{A}$ y de $\sigma(x_1),\dots,\sigma(x_n)$.
\end{example}

\begin{example}
En el ejemplo anterior, si $\varphi$ es una fórmula cerrada, $lib(\varphi) = \emptyset$ y entonces podemos tomar $n=0$. Es decir, el significado de $\varphi$ depende solo de el álgebra, no de la interpretación.
\end{example}


\section{Isomorfía}

Seguimos nuestro estudio de las relaciones entre signaturas e interpretaciones. Introducimos a continuación un concepto empleado constantemente en matemáticas. En nuestro caso, captura la idea de una aplicación que `preserva el significado' entre dos álgebras de la misma signatura:

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sean $\mathfrak{A}_1$ y $\mathfrak{A}_2$ $S$-álgebras de conjuntos soporte respectivos $A_1$ y $A_2$. Una aplicación $h: A_1 \rightarrow A_2$ es \textit{isomorfismo de S-álgebras} si:
\begin{itemize}
    \item $h$ es biyectiva.
    \item $h(c^{\mathfrak{A}_1}) = c^{\mathfrak{A}_2}$, para todo $c \in Ct_S$.
    \item $h(f^{\mathfrak{A}_1}(a_1, \dots, a_n)) = f^{\mathfrak{A}_2}(h(a_1), \dots, h(a_n))$, con $f|_n \in Fn_S$, $a_1, \dots, a_n \in A_1$.
    \item $p^{\mathfrak{A}_1}(a_1, \dots, a_n) = p^{\mathfrak{A}_2}(h(a_1), \dots, h(a_n))$, con $p|_n \in Pn_S$, $a_1, \dots, a_n \in A_1$.
\end{itemize}
Si existe un isomorfismo entre $\mathfrak{A}_1$ y $\mathfrak{A}_2$, decimos que son \textit{isomorfas} y lo denotamos por $\mathfrak{A}_1 \approx \mathfrak{A}_2$.
\end{definition}

\begin{definition}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sean $\mathfrak{I}_1 = \langle \mathfrak{A}_1, \sigma_1 \rangle$ y $\mathfrak{I}_2 = \langle \mathfrak{A}_2, \sigma_2 \rangle$ $S$-intepretaciones. Una aplicación $h$ es \textit{isomorfismo de S-interpretaciones} si:
\begin{itemize}
    \item $h$ es isomorfismo entre las $S$-álgebras $\mathfrak{A}_1$ y $\mathfrak{A}_2$.
    \item $h(\sigma_1(x)) = \sigma_2(x)$, para todo $x \in Var$.
\end{itemize}
Cuando existe un isomorfismo entre $\mathfrak{I}_1$ y $\mathfrak{I}_2$, decimos que son \textit{isomorfas} y lo simbolizamos por $\mathfrak{I}_1 \approx \mathfrak{I}_2$.
\end{definition}

\begin{example}
Consideremos la signatura característica de los grupos, $S := \langle \{e\}, \{*|_2\}, \emptyset \rangle$. Sean los grupos $(\mathbb{Z}_2, +)$ y $(A, \cdot)$ dado por $A = \{a, b\}$ con:
\begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|c|}
    \hline 
    $\cdot$ & $a$ & $b$ \\ \hline
    $a$ & $a$ & $b$\\ \hline
    $b$ & $b$ & $a$\\ \hline
    \end{tabular}
    \end{center}
    \end{table}
\end{example}
Entonces tenemos dos $S$-álgebras:
$$\mathfrak{A}_1 = \langle \mathbb{Z}_2, \{ 0,1\}, \{ +\}, \emptyset \rangle$$
$$\mathfrak{A}_2 = \langle A, \{a,b\}, \{\cdot \}, \emptyset \rangle$$
Entonces, la aplicación $h: \mathbb{Z}_2 \rightarrow A$ dada por $h(0) = a$ y $h(1) = b$ es un isomorfismo, es decir, $h:\mathfrak{A}_1 \approx \mathfrak{A}_2$. 

Este lema técnico nos permitirá probar el siguiente teorema:

\begin{lema}\label{sustiso}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sean $\mathfrak{I}_1 = \langle \mathfrak{A}_1, \sigma_1 \rangle$ y $\mathfrak{I}_2 = \langle \mathfrak{A}_2, \sigma_2 \rangle$ $S$-interpretaciones de conjuntos soporte $A_1,A_2$ tales que existe $h: \mathfrak{I}_1 \approx \mathfrak{I}_2$. Sea $a\in A_1$.\\
Entonces, $\mathfrak{I}_1[a/x]\approx\mathfrak{I}_2[h(a)/x]$. De hecho, la misma función $h:A_1\to A_2$ es isomorfismo entre $\mathfrak{I}_1[a/x]$ y $\mathfrak{I}_2[h(a)/x]$.
\end{lema}
\begin{proof}
Está claro que se cumple $h(\sigma_1(y)) = \sigma_2(y)$ para todas las variables excepto x, ya que si $y\in Var\setminus \{x\}$, $h(\sigma_1[a/x](y))=h(\sigma_1(y))=\sigma_2(y)=\sigma_2[h(a)/x](y)$.\\
Respecto a la variable $x$, $h(\sigma_1[a/x](x))=h(a)=\sigma_2[h(a)/x](x)$.\\
Queda entonces comprobar que $h$ es isomorfismo entre las álgebras de $\mathfrak{I}_1$ y $\mathfrak{I}_2$. Pero esto es directo, ya que estas álgebras son $\mathfrak{A}_1$ y $\mathfrak{A}_2$.
\end{proof}

El siguiente resultado muestra que los isomorfismos entre $S$-interpretaciones se extienden a las fórmulas y los términos de tal signatura $S$.

\begin{theorem}(Lema de Isomorfía)\label{isomorf}
Sea $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura. Sea $h$ isomorfismo entre las $S$-interpretaciones $\mathfrak{I}_1$ y $\mathfrak{I}_2$. Entonces:
\begin{enumerate}
    \item Para todo $t \in TERM_S$, $h(t^{\mathfrak{I}_1}) = t^{\mathfrak{I}_2}$.
    \item Para toda $\varphi \in FORM_S$, $\varphi^{\mathfrak{I}_1} = \varphi^{\mathfrak{I}_2}$, y por tanto $\mathfrak{I}_1 \vDash \varphi$ si y solo si $\mathfrak{I}_2 \vDash \varphi$.
\end{enumerate}
\end{theorem}
\begin{proof} \mbox{}
\begin{enumerate}
    \item Por inducción estructural sobre $t \in TERM_S$:
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                \item Si $t = c$, con $c \in Ct_S$, entonces $h(t^{\mathfrak{I}_1}) = h(c^{\mathfrak{I}_1}) = c^{\mathfrak{I}_2} = t^{\mathfrak{I}_2}$.
                \item Si $t = x$, con $x \in Var$, entonces $h(t^{\mathfrak{I}_1}) = h(x^{\mathfrak{I}_1}) = h(\sigma_1(x)) = \sigma_2(x) = x^{\mathfrak{I}_2} = t^{\mathfrak{I}_2}$.
                 \end{itemize}
            \item Caso recursivo: Si $t = f(t_1, \dots, t_n)$, con $f|_n \in Fn_S$ y $t_1, \dots, t_n \in TERM_S$ cumplen el enunciado, entonces: 
            
            $h(f(t_1, \dots, t_n)^{\mathfrak{I}_1}) = h(f^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1}, \dots, t_n^{\mathfrak{I}_1})) = f^{\mathfrak{A}_2}(h(t_1^{\mathfrak{I}_1}), \dots, h(t_n^{\mathfrak{I}_1})) =  f^{\mathfrak{A}_2}(t_1^{\mathfrak{I}_2}, \dots, t_n^{\mathfrak{I}_2}) = f(t_1, \dots, t_n)^{\mathfrak{I}_2}$
        \end{itemize}
    \item Por inducción estructural sobre $\varphi \in FORM_S$:
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                    \item Si $\varphi = \top$, entonces $\varphi^{\mathfrak{I}_1} = \top^{\mathfrak{I}_1} = V = \top^{\mathfrak{I}_2} = \varphi^{\mathfrak{I}_2}$ y análogo con $\bot$.
                    \item Si $\varphi = t \doteq s$ para $t, s \in TERM_S$, entonces $\mathfrak{I}_1 \vDash \varphi$ si y solo si $t^{\mathfrak{I}_1} = s^{\mathfrak{I}_1}$ si y solo si (por ser $h$ inyectiva) $h(t^{\mathfrak{I}_1}) = h(s^{\mathfrak{I}_1})$ si y solo si $t^{\mathfrak{I}_2} = s^{\mathfrak{I}_2}$ si y solo si  $\mathfrak{I}_1 \vDash \varphi$.
                    \item Si $\varphi = p(t_1, \dots, t_n)$, con $p|_n \in Pd_S$ y $t_1, \dots, t_n \in TERM_S$ cumplen el enunciado, entonces $p(t_1, \dots, t_n)^{\mathfrak{I}_1} = V$, si y solo si $p^{\mathfrak{A}_1}(t_1^{\mathfrak{I}_1}, \dots, t_n^{\mathfrak{I}_1}) = V$ si y solo si  $p^{\mathfrak{A}_2}(h(t_1^{\mathfrak{I}_1}), \dots, h(t_n^{\mathfrak{I}_1})) = V$ si y solo si  $p^{\mathfrak{A}_2}(t_1^{\mathfrak{I}_2}, \dots, t_n^{\mathfrak{I}_2}) = V$
                \end{itemize}
            \item Caso recursivo:
                \begin{itemize}
                    \item $\varphi=\neg\varphi_1$. Entonces, $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $v_\neg(\varphi_1^{\mathfrak{I}_1})$ es $V$ si y solo si $v_\neg(\varphi_1^{\mathfrak{I}_2})$ es $V$ si y solo si 
                    $\varphi^{\mathfrak{I}_2}$ es $V$.
                    \item $\varphi=\varphi_1\square\varphi_2$. Entonces, 
                    $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si $v_\square(\varphi_1^{\mathfrak{I}_1},\varphi_2^{\mathfrak{I}_1})$ es $V$ si y solo si $v_\square(\varphi_1^{\mathfrak{I}_2},\varphi_1^{\mathfrak{I}_2})$ es $V$ si y solo si 
                    $\varphi^{\mathfrak{I}_2}$ es $V$.
                    \item $\varphi=\exists x \, \varphi_1$. Entonces, $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si existe $a$ que cumple $\varphi_1^{\mathfrak{I}_1[a/x]}=V$. Como por hipótesis inductiva el enunciado se cumple para $\varphi_1$, usando el lema \ref{sustiso} tenemos que $\varphi_1^{\mathfrak{I}_1[a/x]}=V$ equivale a $\varphi_1^{\mathfrak{I}_2[a/x]}=V$. Y que exista $a$ que cumpla esto es equivalente a que $\varphi^{\mathfrak{I}_2}$ sea $V$, como queríamos.
                    \item $\varphi=\forall x \, \varphi_1$. Entonces, $\varphi^{\mathfrak{I}_1}$ es $V$ si y solo si para todo $a$ se cumple $\varphi_1^{\mathfrak{I}_1[a/x]}=V$. Como por hipótesis inductiva el enunciado se cumple para $\varphi_1$, usando el lema \ref{sustiso} tenemos que $\varphi_1^{\mathfrak{I}_1[a/x]}=V$ equivale a $\varphi_1^{\mathfrak{I}_2[a/x]}=V$. Y que esto se cumpla para todo $a$ es equivalente a que $\varphi^{\mathfrak{I}_2}$ sea $V$, como queríamos.
                    
                \end{itemize}
        \end{itemize}
\end{enumerate}
\end{proof}

\section{Lema de sustitución}

Proseguimos nuestro estudio de la sustitución. A continuación obtenemos el resultado análogo al que ya demostramos en lógica proposicional.

\begin{theorem}(Lema de sustitución)\label{sustprim}
Sean $S = \langle Ct_{S}, Fn_{S}, Pd_{S}\rangle$ signatura, $\mathfrak{I}$ $S$-interpretación de conjunto soporte $A$. Sean $\bar{x} := (x_1, \dots, x_n)$ y $\bar{t} := (t_1, \dots, t_n)$ vectores de $Var$ y $TERM_S$, respectivamente. Denotemos $\bar{t}^{\mathfrak{I}} := (t_1^{\mathfrak{I}}, \dots, t_n^{\mathfrak{I}})$ y $\mathcal{J} := \mathfrak{I}[\bar{t}^{\mathfrak{I}}/\bar{x}]$.
Entonces:
\begin{enumerate}
    \item Si $s \in TERM_S$, $(s[\bar{t}/\bar{x}])^{\mathfrak{I}} = s^{\mathcal{J}}$.
    \item Si $\varphi \in FORM_S$, $(\varphi[\bar{t}/\bar{x}])^{\mathfrak{I}} = \varphi^{\mathcal{J}}$, es decir, $\mathfrak{I} \vDash \varphi[\bar{t}/\bar{x}]$ si y solo si $\mathcal{J} \vDash \varphi$.
\end{enumerate}
\end{theorem}
\begin{proof}\mbox{}
\begin{enumerate} 
    \item Por inducción estructural.
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                    \item Si $s = c$, con $c \in Ct_S$, entonces $s=s[\bar{t}/\bar{x}]=c$, y se cumple $c^{\mathfrak{I}}=c^{\mathcal{J}}$, ya que $\mathfrak{I}$ y $\mathcal{J}$ tienen la misma álgebra.
                    \item Sea $s = x$, con $x \in Var$. Si $x$ no está en $\bar{x}$, entonces $x[\bar{t}/\bar{x}]=x$, y como $x^{\mathfrak{I}}=x^{\mathcal{J}}$, tenemos el resultado. Si $x = x_i$, con $x_i$ el elemento $i$-ésimo de $\bar{x}$, $(x[\bar{t}/\bar{x}])^{\mathfrak{I}} = t_i^{\mathfrak{I}} = x^{\mathfrak{I}[\bar{t}/\bar{x}]} = x^{\mathcal{J}}$.
                \end{itemize}
            \item Caso recursivo: Sea $s = f(r_1, \dots, r_k)$, con $f|_k \in Fn_S$ y $r_1, \dots, r_k \in TERM_S$. Entonces, $(f(r_1, \dots, r_k)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (f(r_1[\bar{t}/\bar{x}], \dots, r_k[\bar{t}/\bar{x}]))^{\mathfrak{I}} = f^{\mathfrak{A}}((r_1[\bar{t}/\bar{x}])^{\mathfrak{I}}, \dots, (r_k[\bar{t}/\bar{x}])^{\mathfrak{I}})$ y aplicando la hipótesis de inducción, lo anterior es igual $f^{\mathfrak{A}}(r_1^{\mathcal{J}}, \dots, r_k^{\mathcal{J}}) = f(r_1, \dots, r_k)^{\mathcal{J}}.$
        \end{itemize}
    \item Por inducción estructural.
        \begin{itemize}
            \item Caso base:
                \begin{itemize}
                    \item Si $\varphi = \top$, $(\varphi[\bar{t}/\bar{x}])^{\mathfrak{I}} = V = \varphi^{\mathcal{J}}$. Análogo con $\bot$.
                    \item Si $\varphi = r \doteq s$, con $r, s \in TERM_S$. Entonces $((r \doteq s)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (r[\bar{t}/\bar{x}] \doteq s[\bar{t}/\bar{x}])^{\mathfrak{I}}$, que es cierto si y solo si $r[\bar{t}/\bar{x}])^{\mathfrak{I}} = s[\bar{t}/\bar{x}]^{\mathfrak{I}}$ si y solo si, por hipótesis de inducción, $r^{\mathcal{J}} = s^{\mathcal{J}}$, es decir, si y solo si $\mathcal{J} \vDash r \doteq s$.
                    \item Si $\varphi = p(r_1, \dots, r_k)$, con $p|_k \in Pd_S$, $r_1, \dots r_k \in TERM_S$, entonces $(p(r_1, \dots, r_k)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (p(r_1[\bar{t}/\bar{x}], \dots, r_k[\bar{t}/\bar{x}]))^{\mathfrak{I}}$ es igual a  $p^{\mathfrak{A}}((r_1[\bar{t}/\bar{x}])^{\mathfrak{I}}, \dots, (r_k[\bar{t}/\bar{x}])^{\mathfrak{I}})$, que por hipótesis de inducción es igual a $p^{\mathcal{A}}(r_1^{\mathcal{J}}, \dots, r_k^{\mathcal{J}}) = p(r_1, \dots, r_k)^{\mathcal{J}}$.
                \end{itemize}
            \item Caso inductivo:
                    \begin{itemize}
                        \item Si $\varphi = \neg \psi$, entonces $((\neg \psi)[\bar{t}/\bar{x}])^{\mathfrak{I}} = (\neg \psi[\bar{t}/\bar{x}])^{\mathfrak{I}} = v_{\neg}((\psi[\bar{t}/\bar{x}])^{\mathfrak{I}})$, que por hipótesis de inducción es $v_{\neg}(\psi^{\mathcal{J}}) = (\neg \psi)^{\mathcal{J}}$.
                        \item Si $\varphi = \psi \square \chi$, entonces $((\psi \square \chi)[\bar{t}/\bar{x}])^{\mathfrak{I}} = ((\psi[\bar{t}/\bar{x}]) \square (\chi[\bar{t}/\bar{x}]))^{\mathfrak{I}} = v_{\square}((\psi[\bar{t}/\bar{x}])^{\mathfrak{I}}, (\chi[\bar{t}/\bar{x}])^{\mathfrak{I}})$, que por hipótesis de inducción es $v_{\square}(\psi^{\mathcal{J}}, \chi^{\mathcal{J}}) = (\psi \square \chi)^{\mathcal{J}}$.
                        \item Veamos el caso $\forall x \, \varphi$. Supongamos que $x$ no es ninguno de los elementos del vector $\bar{x}$, ya que si esto fuera cierto y $x$ correspondiera a la variable $i$-ésima de $\bar{x}$, $x_i$, por cómo hemos definido sustitución tendríamos que 
                        $$(\forall x\;\varphi)[\bar{t}/\bar{x}]=(\forall x\;\varphi)[(t_1,\dots t_{i-1},t_{i+1},\dots,t_n)/(x_1,\dots x_{i-1},x_{i+1},\dots,x_n)],$$
                        es decir, nuestra sustitución es igual a otra sustitución en que $x\notin\bar{x}$.
    
    Tenemos entonces dos casos, $x \in var(t_i)$ para algún $i=1,\dots,n$ o no. El primero resulta ser más complicado y nos limitamos a hacer ese:\\
    Supongamos $x \in var(t_i)$ para cierto $1 \leq i \leq n$, con $t_i$ el $i$-ésimo elemento de $\bar{t}$. Entonces, introduciendo la variable nueva $z$, 
    $$(\forall x \, \varphi)[\bar{t}/\bar{x}] = \forall z \, \varphi[z/x][\bar{t}/\bar{x}]$$
    Entonces, $\mathfrak{I} \vDash \forall z \, \varphi[z/x][\bar{t}/\bar{x}]$ es equivalente a que para todo $a \in A$, $\mathfrak{I}[a/z] \vDash \varphi[z/x][\bar{t}/\bar{x}]$. Aplicando la hipótesis de inducción a $\mathfrak{I}[a/z]$ y a $\varphi$, lo anterior equivale a que para todo $a \in A$,
    $$(\mathfrak{I}[a/z])[\bar{t}^{\mathfrak{I}[a/z]}/\bar{x}] \vDash \varphi[z/x]$$
    Nótese que, al ser $z$ variable nueva, $z \notin var(t_i)$, para todo $1 \leq i \leq n$ y por \ref{coinc}, $t_i^{\mathfrak{I}[a/z]} = t_i^{\mathfrak{I}}$. Lo anterior es entonces equivalente a que para todo $a \in A$:
    $$(\mathfrak{I}[a/z])[\bar{t}^{\mathfrak{I}}/\bar{x}] \vDash \varphi[z/x]$$
    Por ser $z$ nueva, se sigue también que es distinta de todo elemento de $\bar{x}$. De modo que
    $(\mathfrak{I}[a/z])[\bar{t}^{\mathfrak{I}}/\bar{x}] = \mathfrak{I}[\bar{t}^{\mathfrak{I}}/\bar{x}][a/z] = \mathcal{J}[a/z]$, y entonces lo anterior es cierto si y solo si para todo $a \in A$, 
    $$\mathcal{J}[a/z] \vDash \varphi[z/x]$$
    De nuevo, por hipótesis de inducción sobre $\mathcal{J}[a/z]$ y $\varphi$, lo anterior se da si y solo si, para todo $a \in A$,
    $$\mathcal{J}[a/z][z^{\mathcal{J}[a/z]}/x] \vDash \varphi$$
    esto es, usando que $z^{\mathcal{J}[a/z]} = a$, 
    $$(\mathcal{J}[a/z])[a/x] \vDash \varphi$$
    Por ser $z$ variable nueva, $\mathcal{J}[a/z] \sim_{\varphi} \mathcal{J}$ y empleando \ref{coinc}, $\varphi^{\mathcal{J}[a/z]} = \varphi^{\mathcal{J}}$. Finalmente, lo anterior es equivalente a que para todo $a \in A$,
    $$\mathcal{J}[a/x] \vDash \varphi$$
    es decir, $\mathcal{J} \vDash \forall x \, \varphi$.
    El caso $\exists x \, \varphi$ es análogo.
                    \end{itemize}
        \end{itemize}
    
\end{enumerate}
\end{proof}


\section{Equivalencia lógica}

Algunos de los ejemplos precedentes muestran que operar con interpretaciones no es tarea cómoda. Por ello, debemos investigar relaciones entre los signos, que nos faciliten un futuro estudio de su semántica. De nuevo, la noción principal para este propósito es la de \textit{equivalencia lógica}:

\begin{definition}
Sea $S$ signatura, $\varphi, \psi \in FORM_S$. $\varphi$ y $\psi$ son \textit{lógicamente equivalentes}, $\varphi \sim \psi$, si para toda $S$-intepretación $\mathfrak{I}$, $\varphi^{\mathfrak{I}} = \psi^{\mathfrak{I}}$, es decir, $\mathfrak{I} \vDash \varphi$ si y solo si $\mathfrak{I} \vDash \psi$\footnote{No es difícil demostrar que $\sim$ es reflexiva, simétrica y transitiva, es decir, es relación de equivalencia sobre $FORM_S$.}.
\end{definition}



\begin{prop}\label{fund}
Sea $S$ signatura, $\varphi, \psi \in FORM_S$. Entonces son equivalentes:
\begin{enumerate}
    \item $\varphi \sim \psi$.
    \item $\vDash \varphi \leftrightarrow \psi$.
    \item $\varphi \vDash \psi$ y $\psi \vDash \varphi$.
\end{enumerate}
\end{prop}
\begin{proof}$\\$
\be
(1)$\implies$(2): Si $\varphi \sim \psi$, $\varphi^{\mathfrak{I}} = \psi^{\mathfrak{I}}$ para toda $S$-interpretación $\mathfrak{I}$, por tanto toda interpretación $\mathfrak{I}$ cumple $\mathfrak{I} \vDash \varphi\leftrightarrow \psi$, como queríamos.\\

\noindent (2)$\implies$(3):  Si $\vDash \varphi \leftrightarrow \psi$, toda interpretación $\mathfrak{I}$ solo puede satisfacer $\varphi$ y $\psi$ o no satisfacer $\varphi$ ni $\psi$. Por tanto, si una interpretación satisface $\varphi$, satisface $\psi$ y viceversa.  \\


\noindent (3)$\implies$(1): Si $\varphi \vDash \psi$ y $\psi \vDash \varphi$, entonces una interpretación satisface $\psi$ si satisface $\varphi$ y viceversa, por tanto satisface $\psi$ si y solo si satisface $\varphi$.
\end{proof}

Evidentemente, las leyes de equivalencia del cálculo proposicional siguen siendo válidas en lógica de primer orden. Además, introducimos nuevas leyes en las que aparezcen cuantificadores:

\begin{theorem}(Leyes de equivalencia lógica con cuantificadores)\mbox{}
\begin{enumerate}
    \item $Q x \, \varphi \sim Q u \, \varphi[u/x]$, siendo $u$ variable nueva.
    \item Si $\varphi \sim \psi$, entonces $Qx \, \varphi \sim Qx \, \psi$.
    \item $\neg \forall x \, \varphi \sim \exists x \, \neg \varphi,  \quad \neg \exists x \, \varphi \sim \forall x \, \neg \varphi$.
    \item $\forall x \, \varphi \sim \neg \exists x \, \neg \varphi, \quad \exists x \, \varphi \sim \neg \forall x \neg \varphi$.
    \item Si $x \neq y$, entonces $Qx \, Qy \, \varphi \sim Qy \, Qx \, \varphi$.
    \item $\forall x \, (\varphi \land \psi) \sim (\forall x \, \varphi) \land (\forall x\, \psi), \quad \exists x \, (\varphi \lor \psi) \sim (\exists x \, \varphi) \lor (\exists x\, \psi)$.
    \item Si $x \notin lib(\psi)$, $Qx \, \psi \sim \psi$.
    \item Si $x \notin lib(\psi)$, $(\forall x \, \varphi) \land \psi \sim \forall x \, (\varphi \land \psi), \quad  (\exists x \, \varphi) \lor \psi \sim \exists x \, (\varphi \lor \psi)$.
    \item Si $x \notin lib(\psi)$, $\forall x \, (\varphi \lor \psi) \sim (\forall x \, \varphi) \lor (\forall x \, \psi), \quad \exists x \, (\varphi \land \psi) \sim (\exists x \, \varphi) \land (\exists x \, \psi)$.
    \item Si $x \notin lib(\psi)$, $(\forall x \, \varphi) \rightarrow \psi \sim \exists x \, (\varphi \rightarrow  \psi), \quad (\exists x \, \varphi) \rightarrow \psi \sim \forall x (\varphi \rightarrow  \psi)$.
\end{enumerate}
\end{theorem}
\begin{proof} \mbox{}
\begin{enumerate}
    \item Demostremos el caso $\forall$, el $\exists$ se hace de forma análoga.
    Sea $\mathfrak{I}$ $S$-interpretación de conjunto soporte $A$. $\mathfrak{I} \vDash \forall u\;\varphi[u/x]$ es por definición equivalente a que, para todo $a \in A$, 
    $$\mathfrak{I}[a/u] \vDash \varphi[u/x].$$ 
    Como $u^{\mathfrak{I}[a/u]} = a$, aplicando el lema de sustitución \ref{sustprim} lo anterior es cierto si y solo si, para todo $a \in A$, 
    $$(\mathfrak{I}[a/u])[a/x]\vDash \varphi$$
    Al ser $u$ variable nueva, $(\mathfrak{I}[a/u])[a/x] \sim_{\varphi} \mathfrak{I}[a/x]$ y \ref{coinc} nos dice que lo anterior equivale a que, para todo $a \in A$, 
    $$\mathfrak{I}[a/x] \vDash \varphi,$$
    que es la definición de $\mathfrak{I} \vDash \forall x \, \varphi$.
    \item Sea $\mathfrak{I}$ $S$-interpretación tal que $\mathfrak{I} \vDash \exists x \, \varphi$, es decir, tal que existe $a \in A$ con $\mathfrak{I}[a/x] \vDash \varphi$, y al ser $\varphi \sim \psi$, lo anterior se da si y solo si existe $a \in A$ con $\mathfrak{I}[a/x] \vDash \psi$, es decir, la definición de $\mathfrak{I} \vDash \exists x \, \psi$. El caso $\forall$ es análogo.
    \item Sea $\mathfrak{I}$ $S$-interpretación tal que $\mathfrak{I} \vDash \neg \forall x \, \varphi$, es decir, $\mathfrak{I} \nvDash \forall x \, \varphi$. Equivalentemente, existe $a \in A$ tal que $\mathfrak{I}[a/x] \vDash \neg \varphi$, que es la definición de $\mathfrak{I} \vDash \exists x \, \neg \varphi$. El caso $\exists$ es análogo.
    \item $\varphi \sim \neg \neg \varphi$ luego, aplicando (2), $\forall x \, \varphi \sim \forall x \, \neg \neg \varphi$ y, por (3), $\forall x \, \neg \neg \varphi \sim \neg \exists x \, \neg \varphi$. El caso $\exists$ es análogo.
    \item $\mathfrak{I}\vDash \exists x\;\exists y\;\varphi$ si y solo si existe $a\in A$ tal que $\mathfrak{I}[a/x]\vDash\exists y\;\varphi$ si y solo si existen $a,b\in A$ tal que $\mathfrak{I}[a/x][b/y]\vDash\varphi$. Como $x\neq y$, $\mathfrak{I}[a/x][b/y]=\mathfrak{I}[b/y][a/x]$, por tanto lo anterior equivale a que existan $a,b\in A$ tales que $\mathfrak{I}[b/y][a/x]\vDash\varphi$. Igual que antes, vemos que esto es equivalente a que $\mathfrak{I}\vDash \exists y\;\exists x\;\varphi$. El caso $\forall$ es análogo.
    
    \item Sea $\mathfrak{I}$ $S$-interpretación tal que $\mathfrak{I} \vDash (\forall x \, \varphi) \land (\forall x \, \psi)$. Esto, por \ref{fund}, es equivalente a que $\mathfrak{I} \vDash \forall x \, \varphi $ y $\mathfrak{I} \vDash \forall x \, \psi$. Entonces, en el primer caso tenemos que, para todo $a \in A$, $\mathfrak{I}[a/x] \vDash \varphi$ y en el segundo que, para todo $b \in A$, $\mathfrak{I}[b/x] \vDash \psi$. De esta forma, lo anterior es equivalente a que, para todo $c \in A$, $\mathfrak{I}[c/x] \vDash \varphi$ y $\mathfrak{I}[c/x] \vDash \psi$, es decir, $\mathfrak{I}[c/x] \vDash \varphi \land \psi$, es decir, $\mathfrak{I} \vDash \varphi \land \psi$.\\
    El otro caso se puede probar a partir del primero, ya que:
    \begin{multline*}
        \exists x \, (\varphi \lor \psi) \sim \neg\neg(\exists x \, (\varphi \lor \psi))\sim\neg(\forall x\,\neg(\varphi\lor\psi))\sim\neg(\forall x\,(\neg\varphi\land\neg\psi))\sim \\ \sim\neg((\forall x\,\neg\varphi)\land(\forall x\neg\psi))\sim\neg(\forall x\,\neg\varphi)\lor\neg(\forall x\neg\psi)\sim(\exists x\,\neg\neg\varphi)\lor(\exists x\,\neg\neg\psi)\sim\exists x\varphi\lor\exists x\psi,
    \end{multline*}
    donde hemos usado las leyes de equivalencia de lógica proposicional, el primer apartado de este ejercicio y la regla (4) para negar cuantificadores.
    \item En este caso, solo es necesario notar que $\mathfrak{I}[a/x] \sim_{\psi} \mathfrak{I}$ y aplicar el Lema de Coincidencia, \ref{coinc}.
    \item Es una consecuencia directa de los apartados 6 y 7.
    \item Comencemos con el caso $\forall$.\\ 
    Queremos demostrar que $\mathfrak{I}\vDash\forall x\,\varphi\lor\psi$ si y solo si $\mathfrak{I}\vDash\forall x\,\varphi\lor\forall x\psi$\\
    $\implies$) Si $\mathfrak{I}\vDash\forall x\,\varphi\lor\psi$, para todo $a\in A$ se cumple $\mathfrak{I}[a/x]\vDash\varphi\lor\psi$. Dividimos en casos:
    \begin{itemize}
        \item $\mathfrak{I}\vDash\forall x\,\varphi$. En este caso, es obvio que se cumple $\mathfrak{I}\vDash\forall x\,\varphi\lor\forall x\psi$.
        \item En caso contrario, existe $a\in A$ tal que $\mathfrak{I}[a/x]\nvDash\varphi$. Entonces para ese $a$ tiene que cumplirse $\mathfrak{I}[a/x]\vDash\psi$. Pero entonces por la regla (7), $\mathfrak{I}[a/x]\vDash\forall x\psi$, por tanto $\mathfrak{I}\vDash\forall x\,\varphi\lor\forall x\psi$.
    \end{itemize}
    $\Longleftarrow$) $\mathfrak{I}\vDash\forall x \psi\lor\forall x \psi$. Tenemos dos casos:
    \begin{itemize}
        \item $\mathfrak{I}\vDash\forall x \psi$, es decir, para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\psi$. Esto implica que para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\varphi\lor\psi$, es decir, $\mathfrak{I}\vDash\forall x (\varphi\lor\psi)$.
        \item $\mathfrak{I}\vDash\forall x \varphi$, es decir, para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\varphi$. Esto implica que para todo $a\in A$, $\mathfrak{I}[a/x]\vDash\varphi\lor\psi$, es decir, $\mathfrak{I}\vDash\forall x (\varphi\lor\psi)$.
    \end{itemize}
    Pasamos a la segunda parte. Esta se puede hacer de forma análoga a la anterior, aunque es más rápido deducirla de la anterior:
    \begin{multline*}
        \exists x\,(\varphi\land\psi)\sim\neg\neg\exists x(\varphi\land\psi)\sim\neg\forall x (\neg\varphi\lor\neg\psi)\sim\\\sim\neg((\forall x \neg \varphi)\lor(\forall x \neg\psi))\sim(\neg\forall x\neg\varphi)\land(\neg\forall x\neg\psi)\sim(\exists x\varphi)\land(\exists x\psi).
    \end{multline*}
    Hemos podido usar la parte anterior de la regla ya que $x\in lib(\psi)$ si y solo si $x\in lib(\neg\psi)$.
    \item Estas últimas reglas se pueden deducir de las anteriores:
    \begin{multline*}
        (\forall x\,\varphi)\to\psi\sim\neg(\forall x\,\varphi)\lor\psi\sim\\\sim(\exists x\,\neg\varphi)\lor\psi\sim\exists x\,(\neg\varphi\lor\psi)\sim\exists x\,\varphi\to\psi.
    \end{multline*}
    \begin{multline*}
        (\exists x\,\varphi)\to\psi\sim\neg(\exists x\,\varphi)\lor\psi\sim(\forall x\,\neg\varphi)\lor\psi\sim\\\sim(\forall x\,\neg\varphi)\lor(\forall x\,\psi)\sim\forall x (\neg\varphi\lor\psi)\sim\forall x(\varphi\to\psi).
    \end{multline*}
\end{enumerate}
\end{proof}

Las leyes de equivalencia como 6, 8, 9 o 10 permiten escribir los cuantificadores \textit{al principio} de las fórmulas. Esto nos lleva a la siguiente
\begin{definition}
Sea $S$ signatura. Se dice que $\varphi \in FORM_S$ \textit{está en forma prenexa} si se puede escribir como:
$Q_1 x_1 \,, \dots, Q_n x_n \, \psi$, con $x_i$ variable y $Q_i$ cuantificador, para cada $1 \leq i \leq n$, y $\psi$ libre de cuantificadores. $\psi$ recibe el nombre de \textit{núcleo}.
\end{definition}

Ahora bien, ¿toda fórmula tiene una fórmula equivalente en forma prenexa? Antes de dar una respuesta afirmativa a esta pregunta necesitamos el siguiente lema:
\begin{lema}\label{lemita2345}
Sea $S$ signatura. Sean $\varphi,\psi \in FORM_S$, $x \in lib(\psi)$, $u \in Var$ tal que $u$ una variable nueva. Entonces 
$$(Q x \, \varphi) \lor \psi \sim Q u \, (\varphi[u/x] \lor \psi).$$
\begin{proof}
Es consecuencia de las reglas de equivalencia:
$$(\forall x \, \varphi) \lor \psi \sim (\forall u \, \varphi[u/x]) \lor \psi \sim (\forall u \, \varphi[u/x]) \lor (\forall u\, \psi) \sim \forall u \, \varphi[u/x] \lor \psi$$
$$(\exists x \, \varphi) \lor \psi \sim (\exists u \, \varphi[u/x]) \lor \psi \sim (\exists u \, \varphi[u/x]) \lor (\exists u\, \psi) \sim \exists u \, \varphi[u/x] \lor \psi,$$
donde en el caso $\forall$ hemos usado que $u$ no aparece libre en $\psi$.
\end{proof}
\end{lema}

\begin{prop}
Sea $S$ signatura. Entonces, para cada $\varphi \in FORM_S$ existe $\psi \in FORM_S$ en forma prenexa tal que $\varphi \sim \psi$.
\end{prop}
\begin{proof}
La demostración se lleva a cabo por inducción estructural. Es rutinaria salvo por el paso inductivo en fórmulas, que demostramos para $\neg$ y $\lor$ \footnote{En realidad no hace falta demostrar el paso inductivo para más conectivas ya que el resto de conectivas pueden expresarse en términos de $\neg$ y $\lor$, como vimos en \ref{cosasfunccomp}}.$\\$

\noindent ($\neg$) Sea $\varphi=\neg \varphi_1$. Por hipótesis de inducción, existe $\psi \in FORM_S$ en forma prenexa tal que $\varphi_1 \sim \psi$, con $\psi = Q_1 x_1 \, \dots Q_n x_n \, \chi$. Entonces $\varphi\sim\neg \varphi_1 \sim \neg \psi \sim Q'_1 x_1 \, \dots Q'_n x_n \, \neg \chi$, donde $Q'_i = \forall$ si $Q_i = \exists$ y $Q'_i = \exists$ si $Q'_i = \forall$, para cada $1 \leq i \leq n$. $\\$

\noindent ($\lor$) Sea $\varphi=\varphi_1 \lor \varphi_2$. Por hipótesis de inducción, existen los respectivos núcleos $\chi_1$, $\chi_2$, tales que $\varphi_1 \sim Q^{1}_1 x_1 \, \dots Q^{1}_n x_n \, \chi_1$ y $\varphi_2 \sim Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2$. Consideremos los vectores de variables nuevas $\bar{u}= (u_1, \dots, u_n)$ y $\bar{v} = (v_1, \dots, v_m)$. Entonces, $\varphi_1 \sim Q^{1}_1 u_1 \, \dots Q^{1}_n u_n \, \chi_1[\bar{u}/\bar{x}]$ y $\varphi_2 \sim Q^{2}_1 v_1 \, \dots Q^{2}_m v_m \, \chi_2[\bar{v}/\bar{y}]$. Ahora, como $\bar{u}$ y $\bar{v}$ son variables nuevas, aplicando repetidamente el lema \ref{lemita2345}, obtenemos:

\begin{array}{ccl}
 \varphi_1 \lor \varphi_2 &\sim&Q^{1}_1 x_1(Q^1_2 x_2 \, \dots Q^{1}_n x_n \, \chi_1)\lor Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2 \\
     &\sim& Q^{1}_1u_1(Q^{1}_2 x_2 \, \dots Q^{1}_n x_n \, \chi_1[u_1/x_1]\lor Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2)\\
     &\vdots&\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n (\chi_1[\bar{u}/\bar{x}]\lor Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2)\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n (Q^{2}_1 y_1 \, \dots Q^{2}_m y_m \, \chi_2\lor\chi_1[\bar{u}/\bar{x}])\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n Q^2_1 v_1 (Q^{2}_2 y_2 \, \dots Q^{2}_m y_m \, \chi_2[v_1/y_1]\lor\chi_1[\bar{u}/\bar{x}])\\
     &\vdots&\\
     &\sim& Q^1_1 u_1\dots Q^1_n u_n Q^2_1 v_1\dots Q^2_m v_m(\chi_2[\bar{v}/\bar{y}]\lor \chi_1[\bar{u}/\bar{x}]),
\end{array}

y ya tenemos una forma prenexa.
\end{proof}


\section{Método de los \textit{tableaux}}

En esta sección desarrollaremos el método de los \textit{tableaux} para lógica de primer orden, análogo al que ya presentamos en el anterior capítulo. Por ello, remitimos toda motivación informal acerca de este procedimiento a lo que ya dijimos allí. Para aprender métodos de este tipo siempre son de ayuda los ejemplos, que hemos incluido al final de la siguiente subsección.

\subsection{Nociones básicas y ejemplos}

Como veremos, para aplicar una regla de construcción de \textit{tableaux} necesitaremos unas constantes especiales, llamadas \textit{auxiliares}. Por tanto, supondremos la existencia de un conjunto de estas constantes, $C_{A} = \{c_0,c_1, \dots \}$, en nuestra signatura.

Siempre que tengamos una fórmula existencial en un \textit{tableaux} podremos seleccionar un elemento del conjunto $C_A$ que la verifica. Más adelante veremos un ejemplo. 


Las fórmulas que pueden aparecer ahora en nuestros \textit{tableaux} obviamente incluyen a las que lo hacían en los del cálculo proposicional, pero se incorporan algunas nuevas. Es decir, además de las $\alpha$, $\beta$, $\sigma$-fórmulas, definimos:
\begin{itemize}
    \item $\gamma$-\textit{fórmulas} (también llamadas \textit{universales}):
    \begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|}
    \hline
    $\gamma$ & $\gamma(t)$ \\
    \hline \hline
    $\forall x \, \varphi$ & $\varphi[t/x]$ \\ \hline
    $\neg \exists x \, \varphi$ & $\neg \varphi[t/x]$\\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    Siendo $t \in TERM_S$.
    
    \item $\delta$-\textit{fórmulas} (también llamadas \textit{existenciales}):
    \begin{table}[H]
    \begin{center}
    \begin{tabular}{|c|c|}
    \hline
    $\delta$ & $\delta(c)$ \\
    \hline \hline
    $\exists x \, \varphi$ & $\varphi[c/x]$ \\ \hline
    $\neg \forall x \, \varphi$ & $\neg \varphi[c/x]$\\ \hline
    \end{tabular}
    \end{center}
    \end{table}
    Siendo $c \in C_A$.
    
    \item \textit{Axiomas de igualdad}, $EQ_S$:
    \begin{itemize}
        \item[(RF)] $\forall x \, x \doteq x$.
        \item[(IM)] $\forall x \, \forall y \, x \doteq y \rightarrow y \doteq x$.
        \item[(TR)] $\forall x \, \forall y \, \forall z \, x \doteq y \land y \doteq z \rightarrow x \doteq z$.
        \item[(ST_{1})] Sea $f|_n \in Fn_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \rightarrow f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
        \item[(ST_{2})] Sea $p|_n \in Pd_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \to  (p(x_1, \dots, x_n) \rightarrow p(y_1, \dots, y_n)).$$
    \end{itemize}
\end{itemize}
Los nombres de las reglas $RF,IM,TR$ se deben a que a estas propiedades se conocen como reflexiva, simétrica y transitiva. En el caso de las dos últimas se debe a que son reglas de sustitución.

Un resultado análogo al correspondiente de lógica proposicional es el siguiente:

\begin{prop}
Sean $S$ signatura, $\varphi \in FORM_S$. Entonces $\varphi$ verifica una de las siguientes condiciones:
\begin{enumerate}
    \item Es de la forma $\psi$, $\neg \psi$, $\bot$ o $\top$, con $\psi \in FORMAT_S$.
    \item Es $\sigma$-fórmula.
    \item Es $\alpha$-fórmula.
    \item Es $\beta$-fórmula.
    \item Es $\gamma$-fórmula.
    \item Es $\delta$-fórmula.
\end{enumerate}
\end{prop}

Esto asegura que nuestro método nos permitirá descomponer fórmulas arbitrarias en otras de la forma $\bot$, $\top$ $\psi$ o $\neg \psi$, con $\psi \in FORMAT_S$. \\\

Ahora describimos las reglas para la construcción de \textit{tableaux} asociados a un conjunto de fórmulas $\Sigma$:
\begin{itemize}
    \item Las reglas $R_{ini}, R_{hip}, R_{\sigma}, R_{\alpha}, R_{\beta}$.
    \item \textit{Regla} $\gamma$, $R_{\gamma}$: Sea 
    \begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \gamma \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head]                                           & {}
\end{tikzcd}
\end{center}
\textit{tableau} de $\Sigma$. Entonces 
\begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \gamma \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head] \arrow[d, no head]                        & {} \\
                      & \gamma(t)                                                        &   
\end{tikzcd}
\end{center}
es \textit{tableau} de $\Sigma$, donde $\gamma$ es $\gamma$-fórmula y $\gamma(t)$ su versión simplificada. $\\$
Es decir, siempre podemos añadir a una rama abierta una versión simplificada de cualquier $\gamma$-fórmula suya y seguimos teniendo un \textit{tableau} de $\Sigma$.

    \item \textit{Regla} $\delta$, $R_{\delta}$: Sea 
    \begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \delta \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head]                                           & {}
\end{tikzcd}
\end{center}
\textit{tableau} de $\Sigma$. Entonces 
\begin{center}
\begin{tikzcd}
                      & {} \arrow[d, no head] \arrow[ldd, no head] \arrow[rdd, no head] &    \\
                      & \delta \arrow[d, no head]                                       &    \\
{} \arrow[r, no head] & {} \arrow[r, no head] \arrow[d, no head]                        & {} \\
                      & \delta(c)                                                        &   
\end{tikzcd}
\end{center}
es \textit{tableau} de $\Sigma$, donde $\delta$ es $\delta$-fórmula y $\delta(c)$ su versión simplificada.$\\$
Es decir, siempre que tengamos una rama abierta que contenga una $\delta$-fórmula, $\delta$, la podemos extender con su versión simplificada $\delta(c)$, siendo $c \in C_A$ nueva en tal rama, y seguimos teniendo un \textit{tableau} de $\Sigma$.

    \item Dado un axioma de igualdad, $\theta \in EQ_S$, la \textit{regla} $\theta$: Sea 
\begin{center}
\begin{tikzcd}
                                           & {} \arrow[d, no head] &                        \\
{} \arrow[ru, no head] \arrow[rr, no head] & {}                    & {} \arrow[lu, no head]
\end{tikzcd}
\end{center}
\textit{tableau} de $\Sigma$. Entonces 
\begin{center}
\begin{tikzcd}
                                           & {} \arrow[d, no head] &                        \\
{} \arrow[ru, no head] \arrow[rr, no head] & {} \arrow[d, no head] & {} \arrow[lu, no head] \\
                                           & \theta               &                       
\end{tikzcd}
\end{center}
Es decir, siempre podemos introducir cada axioma de igualdad $\theta$ a una rama.
\end{itemize}

El siguiente ejemplo muestra por qué, al aplicar la regla $\delta$, la constante auxiliar introducida en la rama debe ser nueva en ella.

\begin{example}
Consideremos el siguiente razonamiento:
\begin{center}
\syllog{Alguien mató a Trotsky} 
{Stalin pagó a alguien} 
{Stalin pagó a alguien que mató a Trotsky}
\end{center}

Lo formalizamos como:
\begin{center}
\syllog{$\varphi_1$: $\exists x \, M(x, Trotsky)$}
{$\varphi_2$: $\exists x \, P(Stalin, x)$}
{$\psi$: $\exists x \,  M(x, Trotsky) \land P(Stalin, x)$}
\end{center}

Es decir, tenemos el conjunto $\Sigma = \{\varphi_1, \varphi_2, \neg \psi \}$.

\begin{comment}
\begin{tikzcd}
{1.\neg\exists x M(x, Trotsky)\land P(Stalin, x)} \arrow[d, "hip(1)"']                                        &  &                                        \\
{2.  \exists x M(x, Trotsky)} \arrow[d, "hip(2)"']                                                            &  &                                        \\
{3.  \exists x P(Stalin, x)} \arrow[d, "{\delta, 2}"']                                                        &  &                                        \\
{4. M(Mercader, Trotsky)} \arrow[d, "{\delta, 3}"']                                                           &  &                                        \\
{5. P(Stalin, Mercader)} \arrow[d, "{\gamma, 1}"']                                                            &  &                                        \\
{6. \neg P(Stalin, Mercader) \land M(Mercader, Trotsky)} \arrow[dd, "{\beta, 6}"'] \arrow[rrdd, "{\beta, 6}"] &  &                                        \\
                                                                                                              &  &                                        \\
{7. \neg P(Stalin, Mercader) \#5, 7}                                                                          &  & {8. \neg M(Mercader, Trotsky) \#4, 8 }
\end{tikzcd}
\end{comment}
\begin{center}
\includegraphics[scale = 0.36]{figures/tableau3.png}
\end{center}

En el punto 4 hemos aplicado correctamente una regla $\delta$ introduciendo la constante auxiliar $Mercader$, y en el 5 hemos vuelto a introducirla por la misma regla, es decir, hemos introducido una constante auxiliar no nueva en la rama. Esto nos ha llevado al absurdo de que la deducción original era válida.  
\end{example}

\begin{example}
Un ejemplo sencillo. Veamos si es válida la siguiente deducción:

\begin{center}
\syllog{Algunos niños son buenos} 
{Todo lo bueno se come} 
{Algunos niños se comen}
\end{center}
Que formalizamos como:
\begin{center}
\syllog{$\varphi_1$: $\exists x \, (ni(x)\land bu(x))$}
{$\varphi_2$: $\forall x \, (bu(x)\to co(x))$}
{$\psi$: $\exists x \, (ni(x)\land co(x))$}
\end{center}

Es decir, en este caso, $\Sigma = \{\varphi_1, \varphi_2, \neg \psi \}$. Veamos un tableau cerrado de $\Sigma$:

\begin{comment}
\begin{tikzcd}
1.\exists x (ni(x)\land bu(x)) \arrow[d]                                          &                                                                       \\
2.  \forall x (bu(x)\to co(x)) \arrow[d]                                          &                                                                       \\
3.  \neg\exists x (ni(x)\land co(x)) \arrow[d, "{\delta, 1}"']                    &                                                                       \\
4. ni(Pepe)\land bu(Pepe) \arrow[d, "{\alpha, 4}"']                               & \text{(Donde $Pepe\in C_A$)}                                         \\
5. ni(Pepe) \arrow[d]                                                             &                                                                       \\
6. bu(Pepe) \arrow[d, "{\gamma,2,pepe/x}"]                                        &                                                                       \\
7.bu(Pepe)\to co(Pepe) \arrow[rd, "{\beta,7}"] \arrow[d, "{\beta,7}"]             &  \\
9.co(Pepe) \arrow[d, "{\gamma,3,pepe/x}"]                                         & {\neg bu(Pepe)\#6,8}                                                  \\
10.\neg(ni(pepe)\land co(Pepe)) \arrow[d, "{\beta, 10}"] \arrow[rd, "{\beta, 10}"] &                                                                       \\
{12.\neg co(Pepe)\#9,12}                                                          & {11.\neg ni(Pepe)\#5,11}                                             
\end{tikzcd}
\end{comment}

\begin{center}
\includegraphics[scale = 0.44]{figures/tableau4.png}
\end{center}
\end{example}


\subsection{Corrección}

Tal y como hicimos en el método de los \textit{tableaux} para lógica proposicional, dados $\Phi \subseteq FORM_S$ y $\varphi \in FORM_S$, escribimos $\Phi \vdash_{tb} \varphi$ cuando existe un \textit{tableau} cerrado para $\Phi \cup \{\neg \varphi\}$.

Recordemos del capítulo anterior que decimos del método de los \textit{tableaux} que tiene \textit{corrección} si $\Phi \vdash_{tb} \varphi$ implica $\Phi \vDash \varphi$, y decimos que tiene \textit{completitud} si $\Phi \vDash \varphi$ implica $\Phi \vdash_{tb} \varphi$.\\
Vamos a comprobar que el método de los \textit{tableaux} de primer orden tiene ambas propiedades, empezando por la corrección.

Comencemos con el siguiente:

\begin{lema}\label{eq}
Para todo $\theta \in EQ_S$, $\vDash \theta$. 
\end{lema}
\begin{proof} \mbox{}
\begin{itemize}
        \item[(RF)] $\forall x \, x \doteq x$ es tautología ya que dada una interpretación $\mathfrak{I}$, se cumple $\mathfrak{I}[a/x] \vDash x \doteq x$ para todo $a \in A$, ya que obviamente $a=a$.
        \item[(IM)] $\forall x \, \forall y \, x \doteq y \rightarrow y \doteq x$ es tautología ya que, dada una interpretación $\mathfrak{I}$, se cumple $\mathfrak{I}[a/x][b/y] \vDash x \doteq y \rightarrow y \doteq x$ para todos $a,b \in A$, ya que si $a=b$, $\mathfrak{I}[a/x][b/y]$ verifica $x \doteq y$ y $y \doteq x$, por tanto verifica $x \doteq y \rightarrow y \doteq x$. Si $a\neq b$, $\mathfrak{I}[a/x][b/y]$ no verifican $x \doteq y$ ni $y \doteq x$, por tanto de nuevo verifica $x \doteq y \rightarrow y \doteq x$.
        \item[(TR)] $\forall x \, \forall t \, \forall z \, x \doteq y \land y \doteq z \rightarrow x \doteq z$ es una tautología. Este caso se demuestra de forma similar a los anteriores, comprobando que $\mathfrak{I}[a/x][b/y][c/z]$ siempre verifica $x \doteq y \land y \doteq z \rightarrow x \doteq z$. Se puede hacer como el apartado anterior dividiendo en los casos $a\neq b$, $a=b\neq c$, $a=b=c$.
        \item[(ST_{1})] Sea $f|_n \in Fn_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \rightarrow f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n)$$ es una tautología. Se omite la demostración.
        \begin{comment}
        Este caso se demuestra por inducción en $n$.
        \begin{itemize}
            \item Caso base: Para cualquier constante (función 0-aria) $a$, cualquier interpretación verifica $a\doteq a$.
            \item Caso inductivo: Supongamos que cualquier función $n-1$-aria lo cumple. Sea f una función $n$-aria y sea una interpretación $\mathfrak{I}$. Entonces, $\mathfrak{I}$ verifica la función que buscamos si y solo si para todo $a\in A$, $\mathfrak{I}[a/x_1]$ verifica $$\forall x_2, \dots, \forall x_n \, \forall y_2, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \rightarrow f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
            Esta fórmula es equivalente a:
            $$\forall x_2, \dots, \forall x_n \, \forall y_2, \dots, \forall y_n \, \neg (x_1\doteq y_1)\lor(\bigvee\limits_{i = 1}^{n} \neg (x_i \doteq y_i)) \lor f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
            Como ninguna variable aparece libre, por la ley (9) de equivalencia lógica esto equivale a:
            $$\neg (x_1\doteq y_1)\lor\forall x_2, \dots, \forall x_n \, \forall y_2, \dots, \forall y_n \, (\bigvee\limits_{i = 1}^{n} \neg (x_i \doteq y_i)) \lor f(x_1, \dots, x_n) \doteq f(y_1, \dots, y_n).$$
        \end{itemize}
        \end{comment}
        \item[(ST_{2})] Sea $p|_n \in Pd_S$. Entonces, $$\forall x_1, \dots, \forall x_n \, \forall y_1, \dots, \forall y_n \, \bigwedge\limits_{i = 1}^{n} x_i \doteq y_i \to  p(x_1, \dots, x_n) \rightarrow p(y_1, \dots, y_n)$$ es una tautología. Se omite la demostración.
\end{itemize}
\end{proof}

El siguiente resultado es fundamental, nos permite extender una rama satisfactible del \textit{tableaux} a otra que también lo es:

\begin{prop}\label{aaa}
Sea $S$ signatura. Sean $\Phi \subseteq FORM_S$ y $\mathfrak{I}$ $S$-interpretación tales que $\mathfrak{I} \vDash \Phi$. Entonces existe una $S$-interpretación $\mathfrak{I}'$ tal que $\mathfrak{I} \sim_{\varphi} \mathfrak{I}'$ para toda $\varphi \in \Phi$ de modo que:
\begin{enumerate}
    \item Sea $\sigma \in \Phi$ fórmula simplificable. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\sigma_1 \}$, con $\sigma \sim \sigma_1$ la simplificación de $\sigma$.
    \item Sea $\alpha \in \Phi$ una $\alpha$-fórmula. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\alpha_1, \alpha_2 \}$, con $\alpha \sim \alpha_1 \land \alpha_2$ la descomposición de $\alpha$.
    \item Sea $\beta \in \Phi$ una $\beta$-fórmula. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\beta_1\}$ o $\mathfrak{I}' \vDash \Phi \cup \{\beta_2\}$, con $\beta \sim \beta_1 \lor \beta_2$ la descomposición de $\beta$.
    \item Sean $\gamma \in \Phi$ $\gamma$-fórmula, $t \in TERM_S$. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\gamma(t)\}$.
    \item Sean $\delta \in \Phi$ $\delta$-fórmula, $c \in C_A$ constante auxiliar nueva en $\Phi$. Entonces $\mathfrak{I}' \vDash \Phi \cup \{\delta(c)\}$.
    \item Para cada $\theta \in EQ_S$, $\mathfrak{I}' \vDash \Phi \cup \{ \theta\}$.
\end{enumerate}
\end{prop}
\begin{proof} \mbox{}

(1), (2) y (3) son análogos a los de lógica proposicional. Basta hacer que $\mathfrak{I} = \mathfrak{I}'$ y el hecho de que:$$\sigma \sim \sigma_1, \quad \alpha \sim \alpha_1 \land \alpha_2, \quad \beta \sim \beta_1 \lor \beta_2.$$ \\

Veamos (4). Sea $\gamma \in \Phi$ y supongamos, sin pérdida de generalidad, que $\gamma$ es de la forma $\forall x \, \varphi$ (si fuese de la forma $\neg \exists x \, \varphi$, usamos que esto es equivalente a $\forall x \, \neg \varphi$ y hacemos $\psi := \neg \varphi$). Tomemos $\mathfrak{I}' = \mathfrak{I}$.

\noindent Consideremos el conjunto soporte de la interpretación $\mathfrak{I}$, $A$. Sea $t \in TERM_S$, y sea $a := t^{\mathfrak{I}} \in A$. Dado que $\forall x \, \varphi \in \Phi$, por hipótesis, $\mathfrak{I} \vDash \forall x \, \varphi$, y por tanto, $\mathfrak{I}[b/x] \vDash \varphi$ para todo $b \in A$, en especial, $\mathfrak{I}[a/x] \vDash \varphi$. Por el Lema de Sustitución, $\mathfrak{I} \vDash \varphi[t/x]$, y notando que $\varphi[t/x] = \gamma(t)$, obtenemos el resultado. \\

Veamos (5). Sea $\delta \in \Phi$ y supongamos que $\delta = \exists x \, \varphi$, para $\varphi \in FORM_S$ (en caso de que $\delta$ fuese de la forma $\neg \forall x \, \varphi$, entonces sería equivalente a $\exists x \, \neg \varphi$ y, haciendo que $\psi := \neg \varphi$, habríamos terminado). Sea $c \in C_A$ constante auxiliar nueva en $\Phi$.

\noindent Consideremos de nuevo el conjunto soporte de $\mathfrak{I} := \langle \mathfrak{A}, \sigma \rangle$, $A$. Como $\exists x \, \varphi \in \Phi$, por hipótesis, $\mathfrak{I} \vDash \exists x \, \varphi$, luego existe $a \in A$ tal que $\mathfrak{I}[a/x] \vDash \varphi$. Ahora definimos $\mathfrak{A}'$ como $\mathfrak{A}$ excepto que $c^{\mathfrak{A}'} = a$. Definamos $\mathfrak{I}' := \langle \mathfrak{A}', \sigma \rangle$. 

\noindent Al ser $c$ constante nueva para $\Phi$, es decir, para cada elemento de $\Phi$, tenemos que $\mathfrak{I} \sim_{\psi} \mathfrak{I}'$, para cada $\psi \in \Phi$, por tanto se cumple $\mathfrak{I} \vDash \psi$ para toda $\psi\in\Phi$. Por el Lema de Sustitución, 
$$(\varphi[c/x])^{\mathfrak{I}'} = \varphi^{\mathfrak{I}'[c^{\mathfrak{I}'}/x]} = \varphi^{\mathfrak{I}'[a/x]}.$$
Y dado que $\mathfrak{I}'[a/x] \sim_{\varphi} \mathfrak{I}[a/x]$ por ser $c$ nueva, aplicando una vez más el Lema de Sustitución, 
$$\varphi^{\mathfrak{I}'[a/x]} = \varphi^{\mathfrak{I}[a/x]} = V.$$
Lo que nos da el resultado. \\

Finalmente, (6) se deduce de \ref{eq}. 
\end{proof}

Del siguiente resultado se deducirá como corolario la corrección del método de los \textit{tableaux} de primer orden:

\begin{theorem}\label{bbb}
Sea $S$ signatura. Sea $\Phi \subseteq FORM_S$ conjunto de fórmulas satisfactible y $T$ un tableau finito para $\Phi$. Entonces $T$ es abierto y existe una rama abierta de $T$, $r$, tal que $\Gamma_r$ es satisfactible.
\end{theorem}
\begin{proof}
Demostremos que existe una $S$-interpretación $\mathfrak{I}$ y una tal rama $r$ de modo que $\mathfrak{I} \vDash \Phi$ y $\mathfrak{I} \vDash \Gamma_r$. 

Al ser $T$ finito, se ha construido en un número finito de reglas $R_{ini}, R_1,  \dots, R_{n}$, dando lugar la sucesión de \textit{tableaux} $T_0, T_1, \dots, T_n = T$. Por tanto, procedemos por inducción sobre $n$. \\

Si $n=0$, entonces $T_0$ es un \textit{tableau} inicial, es decir, tiene la forma 
\begin{tikzcd}
\varphi_1 \arrow[d, no head]          \\
\varphi_2 \arrow[dd, no head, dotted] \\ 
                                      \\
\varphi_k                            
\end{tikzcd}.
Entonces $r$ es la única rama disponible, y $\Gamma_r = \{ \varphi_1, \dots, \varphi_k\} \subseteq \Phi$, por lo que, dado que $\Phi$ es satisfactible, $\Gamma_r$ lo es. Por tanto, hemos encontrado una $S$-interpretación que verifica lo deseado. \\

Sea $n>0$ y supongamos que el resultado es cierto para el \textit{tableau} $T_{n-1}$ y veamos que lo es para $T_n$. Al aplicar la regla $R_n$ a $T_{n-1}$, extendemos una rama $r$. Además, por hipótesis de inducción, hay una rama $r'$ tal que $\Gamma_{r'}$ es satisfactible. \\

Si $r \neq r'$ entonces $r'$ es rama de $T_n$ y, como hemos dicho, verifica que $\Gamma_{r'}$ es satisfactible, con lo que obtenemos el resultado. \\

Si $r = r'$, debemos distinguir los siguientes casos, dependiendo de qué tipo de regla es $R_n$:
\begin{enumerate}
    \item $R_n$ es una regla inicial, de tipo $\sigma$, $\alpha$ o $\beta$. La demostración es análoga a la que vimos en lógica proposicional.
    \item $R_n$ es una regla $\delta$. Sea $\Gamma_{r}^{k}$ el conjunto de fórmulas de la rama $r$ en el árbol $k$-ésimo. Entonces existe $\delta \in \Gamma_{r}^{n-1}$ tal que $\Gamma_{r}^{n} = \Gamma_{r}^{n-1} \cup \{\delta(c)\}$, con $c \in C_A$ nueva en $r$. Por hipótesis de inducción, existe una $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \Phi$ y $\mathfrak{I} \vDash \Gamma_{r}^{n-1}$.
    
    Por \ref{aaa}, existe $\mathfrak{I}'$ tal que $\mathfrak{I}' \vDash \Gamma_{r}^{n-1} \cup \{\delta(c)\}$, es decir, tal que $\mathfrak{I}' \vDash \Gamma_{r}^{n}$. Al ser $c$ nueva en $r$, $c \notin voc(\psi)$, para cada $\psi \in \Phi$, por tanto como en la prueba de \ref{aaa} vimos que $\mathfrak{I}'$ solo difiere de $\mathfrak{I}$ en $c$, $\mathfrak{I}' \sim_{\psi} \mathfrak{I}$, y por tanto $\mathfrak{I}' \vDash \psi$, es decir, $\mathfrak{I}' \vDash \Phi$.
    
    \item $R_n$ es una regla $\gamma$. Existe $\gamma \in \Gamma_{r}^{n-1}$ tal que $\Gamma_{r}^{n} = \Gamma_{r}^{n-1} \cup \{\gamma(t)\}$, siendo $t \in TERM_S$. Por hipótesis, existe una $S$-interpretación $\mathfrak{I}$ con $\mathfrak{I} \vDash \Phi$ y $\mathfrak{I} \vDash \Gamma_{r}^{n-1}$. 
    
    Por la prueba de \ref{aaa}, la misma $\mathfrak{I}$ cumple $\mathfrak{I} \vDash \Gamma_{r}^{n-1} \cup \{\gamma(t)\}$, por tanto $\mathfrak{I} \vDash \Gamma_{r}^n$.
    
    \item $R_n$ es una regla $\theta$, con $\theta \in EQ_S$. Entonces, $\Gamma_{r}^{n} = \Gamma_{r}^{n-1} \cup \{\theta\}$. Por hipótesis de inducción, existe una $S$-interpretación $\mathfrak{I}$ tal que $\mathfrak{I} \vDash \Phi$ y, $\mathfrak{I} \vDash \Gamma_{r}^{n-1}$. Por tanto, $\mathfrak{I} \vDash \Gamma_{r}^n$.
\end{enumerate}
\end{proof}

\begin{cor}\label{ccc}
Sea $S$ signatura. Si $\Phi \subseteq FORM_S$ y $\Phi$ tiene un \textit{tableau} cerrado, entonces $\Phi$ es insatisfactible. 
\end{cor}
\begin{proof}
Basta notar que este enunciado es la forma contrapositiva de \ref{bbb}.
\end{proof}

Finalmente, obtenemos el resultado al que hemos dedicado esta subsección:

\begin{cor}(Corrección)
Sean $S$ signatura, $\Phi \subseteq FORM_S$, $\varphi \in FORM_S$. Entonces, si $\Phi \vdash_{tb} \varphi$, entonces $\Phi \vDash \varphi$.
\end{cor}
\begin{proof}
Si $\Phi \vdash_{tb} \varphi$, entonces $\Phi \cup \{\neg \varphi \}$ tiene un \textit{tableau} cerrado y, por \ref{ccc}, $\Phi \cup \{\neg \varphi \}$ es insatisfactible. Por el resultado análogo a \ref{\text{Insat}} para lógica de primer orden, esto implica que $\Phi \vDash \varphi$.
\end{proof}


\subsection{Completitud. Conceptos Básicos}

El estudio de la completitud va a ser más complicado que en lógica proposicional. Para poder estudiarla, vamos a necesitar introducir una serie de nociones fundamentales de teoría de grafos: 

\begin{defs}\mbox{}
\begin{enumerate}[label=\bold{\arabic*})]
    \item Un \textit{grafo no dirigido} es un par ordenado $T = \langle N, E \rangle$, donde $N$ es el conjunto de \textit{nodos} y $E$ es el conjunto de \textit{aristas}, que son pares sin ordenar de nodos distintos.
    \item Un camino es una sucesión de $(\geq1)$ aristas $(a_1,\dots,a_n)$ de forma que  $a_i$ comparte uno de sus vértices con $a_{i-1}$ y el otro con $a_{i+1}$ para $i=2,3,\dots,n-1$. Llamamos a $n$ \textit{longitud del camino}.
    \item Decimos que el camino es \textit{simple} si cada vértice del camino solo aparece hasta dos veces, una al final de una arista y otra al principio de la siguiente. Decimos que un camino es un \textit{ciclo} si es simple y el primer vértice de la primera arista es el segundo vértice de la última arista.
    \item Decimos que un grafo es \textit{acíclico} si no tiene ciclos. Decimos que un grafo es \textit{conexo} si para cada par de nodos hay un camino entre ellos.
    \item Un \textit{árbol (libre)} es un grafo no dirigido conexo y acíclico. Equivalentemente, es un grafo tal que entre cada par de sus nodos hay un solo camino simple que los une.
    \item Sea $G = \langle V, E\rangle$ grafo no dirigido. Se llama \textit{grado} de $v \in V$, $deg(v)$, al número de elementos de $E$ que inciden sobre él.
\end{enumerate}
\end{defs}


Se tienen las siguientes propiedades:

\begin{prop}
Sea $T = \langle N, E \rangle$ un grafo:
\begin{enumerate}
    \item Si $T$ es un árbol y le quitamos un elemento de $E$, $T$ deja de ser conexo.
    \item Si $T$ tiene finitos nodos, $T$ es un árbol si y solo si $|E| = |N| - 1$.
\end{enumerate}
\end{prop}
\begin{proof}
Se omite la demostración.
\end{proof}

\begin{defs}\mbox{}
\begin{enumerate}[label=\bold{\arabic*})]
    \item Un árbol $T = \langle N, E \rangle$ se llama \textit{árbol con raíz} si se selecciona un elemento especial de $N$, llamado \textit{raíz} de $T$.
    \item Sea $T = \langle N, E \rangle$ árbol con raíz $n_0$. Se llama \textit{altura} de $n \in N$, $h(n)$, a la longitud del único camino simple que une $n_0$ con $n$.
    \item Sea $T = \langle N, E \rangle$ árbol de raíz $n_0$. Se dice que $n_1\in N$ es \textit{hijo de} $n$ si hay una arista que conecta $n$ y $n_1$ y $h(n_1)=h(n)+1$. Se dice que $n_1$ y $n_2$ son \textit{hermanos} si son hijos del mismo nodo.
    \item Sea $T = \langle N, E \rangle$ árbol de raíz $n_0$. Llamamos \textit{rama finita} a un camino simple desde $n_0$ que no está contenido en ningún otro camino simple desde $n_0$. Una \textit{rama infinita} será una sucesión de aristas $a_1,a_2,\dots$ tal que $a_i$ comparte un vértice con $a_{i-1}$ y el otro con $a_{i+1}$ para $i\geq2$, que parte desde $n_0$ y en que no se repiten vértices (es decir, como un camino simple desde $n_0$ pero con infinitos vértices).
\end{enumerate}
\end{defs}

De ahora en adelante consideraremos árboles con una raíz determinada.

\begin{definition}
Sean $T_1 := \langle N_1, E_1 \rangle$, $T_2 :=  \langle N_2, E_2 \rangle$ dos árboles con la misma raíz. Decimos que $T_1$ \textit{está incluido en} $T_2$, $T_1 \leq T_2$, si:
\begin{itemize}
    \item $N_1 \subseteq N_2$.
    \item $E_1 \subseteq E_2$.
\end{itemize}
\end{definition}

\begin{definition}
Sean $T_0, \dots, T_k, \dots$ árboles tales que $T_0 \leq \dots \leq T_k \leq \dots$. Definimos:
$$\lim_{n \in \mathbb{N}} T_n := \langle N, E \rangle$$
siendo $N := \bigcup_{n\in \mathbb{N}} N_{n}$ y $E := \bigcup_{n\in \mathbb{N}} E_{n}$ y con la misma raíz que la de T_0.
\end{definition}

\begin{prop}
Sea $T_0 \leq \dots \leq T_k \leq \dots$ sucesión de árboles. Sea $T := \lim_{n \in \mathbb{N}} T_n$. Entonces:
\begin{enumerate}
    \item $T_i \leq T$, para todo $i \in \mathbb{N}$.
    \item $T$ es un árbol.
\end{enumerate}
\end{prop}
\begin{proof}\mbox{}
\begin{enumerate}
    \item Se sigue de las definiciones anteriores.
    \item Comencemos demostrando que $T = \langle T, N\rangle$ es conexo. Sean $n_1, n_2 \in N$. Como $N := \bigcup_{n\in \mathbb{N}} N_{n}$ y $N_i \subseteq N_j$, para todo $i \leq j$, existe $k \in \mathbb{N}$ tal que $n_1, n_2 \in N_k$. Al ser $T_k = \langle N_k, E_k\rangle$ conexo, existe un camino en $T_k$ que une $n_1$ y $n_2$. Al ser $E_k \subseteq E$ por definición, también es un camino en $T$, lo que nos da la conexión de $T$. \\
    
    Supongamos que existen dos nodos $n_1, n_2 \in N$ tales que existen dos caminos simples distintos $e_1, \dots, e_l$ y $f_1, \dots, f_k$ que los conectan. Es claro, razonando igual que antes, que existe $i \in \mathbb{N}$ tal que $n_1, n_2 \in N_i$ y $e_1, \dots, e_l, f_1, \dots, f_k \in E_i$ y, al ser $T_i = \langle N_i, E_i\rangle$ árbol, $e_1, \dots, e_l$ y $f_1, \dots, f_k$ son iguales, lo que implica que $T$ sea acíclico.
\end{enumerate}
\end{proof}

Nótese que nuestros \textit{tableaux} son árboles con raíz. Además, se cumplirá que las ramas cerradas serán siempre finitas, ya que una rama cerrada se forma cuando dos fórmulas en la rama están en contradicción y ya no hace falta seguir extendiendo la rama.


Necesitamos el siguiente resultado técnico de la teoría de grafos:

\begin{theorem}(Lema de König para árboles)\label{konig}
\mbox{}
Sea $T$ un árbol con raíz con infinitos nodos tal que cada nodo tiene finitos hijos. Entonces $T$ tiene una rama infinita.
\end{theorem}
\begin{proof}

Supongamos que tenemos una ordenación de los vértices, $(v_n)_{n\in\mathbb{N}}$. La raíz del árbol será $v_{i_0}$. Dados dos nodos $a$ y $b$ distintos, decimos que $b$ es descendiente de $a$ si el único camino simple $c_b$ desde $v_0$ hasta $b$ pasa por $a$. Como $b\neq a$, en $c_b$ tenemos un vértice siguiente a $a$, que por tanto es hijo de $a$. De modo que cualquier descendiente de un vértice es uno de sus hijos o descendiente de uno de sus hijos.\\[-7pt]

Entonces, $v_{i_0}$ tiene infinitos descendientes (todos los vértices salvo $v_0$). Estos infinitos descendientes contienen a los finitos hijos de $v_{i_0}$ y a sus descendientes. Por tanto alguno de sus hijos tiene que tener infinitos descendientes. Sea $v_{i_1}$ el menor de ellos. Como $v_{i_1}$ tiene infinitos descendientes, de la misma forma que antes escogemos el menor de sus hijos, $v_{i_2}$, que tiene infinitos descendientes.\\[-7pt]

De este modo creamos una sucesión de vértices $(v_{i_n})_{n\in\mathbb{N}}$. Como por definición $v_{i_n}$ tiene altura $n$, no se repiten vértices. Por tanto la sucesión de aristas $a_n$ que unen $v_{i_n}$ con $v_{i_{n+1}}$ forman una rama infinita.

\end{proof}


\begin{comment}
\begin{theorem}(Lema de König)\label{konig}
Sea $G$ grafo que verifica lo siguiente:
\begin{enumerate}
    \item $G$ es conexo.
    \item $G$ es \textit{localmente finito}, es decir, cada nodo es vecino de finitos vértices.
    \item $G$ es \textit{infinito}, es decir, su conjunto de nodos es infinito.
\end{enumerate}
Entonces $G$ contiene un camino simple infinito.

En especial, cada árbol infinito contiene o un nodo de grado infinito o un camino simple infinito.
\end{theorem}
\begin{proof}
Se omite la demostración.
\end{proof}
\end{comment}


\begin{prop} \label{cefi}
Si $T$ es tableau cerrado, es finito.
\end{prop}
\begin{comment}
\begin{proof}
Observemos que, en todo \textit{tableau}, el número máximo de hijos de cada nodo es dos: los que se pueden obtener por la aplicación de una regla $\beta$.
Al ser $T$ cerrado, en cada rama suya $r$ hay dos nodos $n_1, n_2$ que son contradictorios. Definimos:
$$h_r := max\{h(n_1), h(n_2)\}$$
$$h := max\{h_r \, | \, r \text{ rama de } T\}$$

Si $h$ fuese infinito, el árbol tendría ramas $r$ con $h_r$ arbitraria. Como cada nodo tiene a lo sumo dos hijos, por \ref{konig} debe tener una camino simple infinito, esto es, una rama infinita. Esta rama infinita no puede estar cerrada, ya que las ramas cerradas tienen siempre profundidad finita.

Por tanto, $h$ es finito y, del hecho de que cada nodo tiene a lo sumo dos hijos deducimos que tiene que ser finito.
\end{proof}
\end{comment}
\begin{proof}
Usaremos reducción al absurdo. Sea $T$ un \textit{tableaux} infinito cerrado. Observemos que, en todo \textit{tableau}, el número máximo de hijos de cada nodo es dos: los que se pueden obtener por la aplicación de una regla $\beta$. Por tanto, por el lema de König $\ref{konig}$ el \textit{tableau} contiene una rama infinita. Esto contradice el hecho de que todas las ramas cerradas son finitas.
\end{proof}

\subsection{Conjuntos de Hintikka para lógica de primer orden}\label{Hinti33}

Para continuar con el teorema de completitud, lo siguiente es definir
el análogo a los conjuntos de Hintikka que vimos en la lógica
proposicional, pero ahora para la lógica de primer orden.

Lo primero que necesitamos es el concepto de \emph{término adecuado}
para un conjunto de fórmulas $\Phi\subseteq FORM_S$


\begin{definition}
  Sea S una signatura, $t\in TERM_S$ y $\Phi\subseteq FORM_S$. Diremos que
  $t$ es \emph{adecuado} para $\Phi$ si se cumple:
  \begin{itemize}
  \item $voc(t)\subseteq voc(\Phi):=\bigcup\limits_{\varphi\in\Phi} voc(\varphi)$
  \item $var(t)\subseteq lib(\Phi):=\bigcup\limits_{\varphi\in\Phi} lib(\varphi)$
  \end{itemize}
\end{definition}
\\ \\
\noindent Puede darse el caso de que no encontremos ningún término adecuado para un conjunto de fórmulas. Por ejemplo consideremos el conjunto de fórmulas
\begin{displaymath}
  \Phi = \{\exists x\ (p(x)\to q(x))\}
\end{displaymath}
En este caso
$(voc(\Phi)\cap\mathit{Ct}_{S})\cup lib(\Phi)=\emptyset$, por tanto no podemos construir términos adecuados. En este caso, como en el método de los \textit{tableaux} nos serán necesarios términos adecuados para desarrollar el algoritmo, tomaremos como término adecuado cualquier constante auxiliar $c\in C_A$ nueva.

\begin{definition}[Conjunto de Hintikka]
  Sea $S$ una signatura,  $\Phi\in FORM_S$ y $T_{\Phi}:=\{t\ |\ t\in TERM_S\
  \mbox{adecuado para}\ \Phi\}$. Diremos que \(\Phi\) es de
  \emph{Hintikka}
  si verifica todas estas propiedades:
  \begin{itemize}
  \item \(\Phi\) es coherente:
    \begin{itemize}
    \item $\bot\not\in\Phi$
    \item no existe $\varphi\in\Phi$ tal que \(\neg\varphi\in\Phi\).
    \end{itemize}
  \item \(\Phi\) es \(\alpha\)-saturado: si \(\alpha\in\Phi\) es una
    \(\alpha\)-fórmula, \(\alpha_{1},\alpha_{2}\in\Phi\).
  \item \(\Phi\) es \(\beta\)-saturado: si \(\beta\in\Phi\) es una
    \(\beta\)-fórmula, \(\beta_{1}\in \Phi\) o \(\beta_{2}\in\Phi\).
  \item \(\Phi\) es \(\sigma\)-saturado: si \(\sigma\in\Phi\) es una
    \(\sigma\)-fórmula, \(\sigma_1\in \Phi\).
  \item \(\Phi\) es \(\gamma\)-saturado: si \(\gamma\in\Phi\) es una
    \(\gamma\)-fórmula y \(t\in T_{\Phi}\), entonces \(\gamma(t)\in \Phi\).
  \item \(\Phi\) es \(\delta\)-saturado: si \(\delta\in\Phi\) es una
    \(\delta\)-fórmula, entonces existe una constante auxiliar
    $c\in C_{A}$ tal que \(\delta(c)\in \Phi\).
  \item \(\Phi\) es \(\theta\)-saturado: si
    \(\theta\in\mathrm{EQ}_{S}\) es un axioma de igualdad, entonces
    \(\theta\in\Phi\).
  \end{itemize}
\end{definition}
 \\ \\ \\

Consideremos a continuación una signatura cualquiera $S$. Nuestra intención es demostrar que todo conjunto $\Phi\subseteq FORM_S$ de Hintikka es satisfactible. Es decir, tenemos que crear una interpretación, con una álgebra $\mathfrak{T}$ y una asignación de  variables $\sigma_\Phi$, que haga ciertas todas las fórmulas de $\Phi$. El primer paso  para ello  es encontrar un conjunto soporte para nuestra álgebra. \\
Una opción a considerar es el \textit{álgebra libre de términos}, una álgebra conocida que tiene como como conjunto soporte a $TERM_S$. Sin embargo, esta álgebra no es suficiente: Supongamos que tenemos la signatura de
la aritmética. Según esta signatura, los términos
\(s(0)+0\) y \(s(0)\) son distintos, pero representan el mismo elemento. Eso se traduce en que en nuesto álgebra necesitamos establecer una relación de
equivalencia de términos. Esa relación la denotaremos como
$\equiv_{\Phi}$, la idea es que $t\equiv_{\Phi} s$ si $\Phi\models
t\doteq s$.


\begin{definition}
  Dada $S$ una signatura, $\Phi\subseteq FORM_S$ y
  $s,t\in TERM_S$ definimos la equivalencia de términos como:
  
   $$ t\equiv_{\Phi}s\quad\text{si y solo si}\quad t\doteq s\in\Phi $$
 
\end{definition}
 
 
\begin{prop}
  Sea $S$ signatura, \(\Phi\subseteq FORM_S\). Si $\Phi$ es de Hintikka, entonces \(\equiv_{\Phi}\subseteq
  T_{\Phi}\times T_{\Phi}\) es relación de equivalencia.

\begin{proof} Probamos las propiedades reflexiva, simétrica y transitiva.
    \begin{enumerate}
        \item \textit{Propiedad reflexiva.} Dado $t\in T_\Phi$ hay que probar que $t\equiv_{\Phi} t$. Utilizaremos el axioma de reflexión (RF), que está en $\Phi$ por ser de $Hintikka$.
        \[
            \gamma := (\forall x\ x\doteq x) \in \Phi
        \]
        Es una $\gamma$-fórmula, luego por ser $\Phi$ de $Hintikka$, $\gamma(t) \in \Phi$, esto es:
        \[
            t\doteq t\ \in \Phi
        \]
        lo que equivale a que $t\equiv_{\Phi} t$, que es el resultado deseado.
        \item \textit{Propiedad simétrica.} Sean $t,s\in T_{\Phi}$ tales que \(t\equiv_{\Phi} s\), es decir,
    \(t\doteq s\in\Phi\). Al ser $\Phi$ de Hintikka contiene al axioma de simetría (IM):
    \[
         \gamma\ :=\ (\forall x \, \forall y \, x \doteq y \rightarrow y \doteq x)
    \]
    que es una $\gamma$-fórmula, por lo que $\gamma(t) \in \Phi$:
    \[
        \gamma(t)\ =\ (\forall y \, t \doteq y \rightarrow y \doteq t)
    \]
    que es de nuevo otra $\gamma$-fórmula. Se aplica nuevamente la misma regla para $s$ y se tiene que:
    \[
        \gamma(t)(s)\ =\ (t \doteq s \rightarrow s \doteq t) \in \Phi
    \]
    que es una $\beta$-fórmula, luego se cumple:
    \[
        \neg t \doteq s \in \Phi\ \ o\ \ s \doteq t \in \Phi
    \]
    Como se sabe ya que $t \doteq s \in \Phi$ no queda otra que $s \doteq t \in \Phi$, que equivale a que $s\equiv_{\Phi} t$, como queríamos probar.
    \item \textit{Propiedad transitiva.} Dados $t,s,r\in T_{\Phi}$ tal que $t\equiv_{\Phi} s$ y  $s\equiv_{\Phi} r$, hay que demostrar que $t\equiv_{\Phi} r$. El axioma de transitividad está en $\Phi$, luego:
    \[
        \gamma\ :=\ (\forall x\forall y \forall z\ x\doteq y \land y\doteq z \rightarrow x\doteq z) \in \Phi
    \]
    que es una $\gamma$-fórmula. Aplicando los cambios de las variables por los términos y atendiendo a que $\Phi$ es $\gamma$-saturado por ser de Hintikka se tiene:
    \[
        \gamma(t)(r)(s)\ =\ (t\doteq s \land s\doteq r \rightarrow t\doteq r) \in \Phi
    \] 
    que es una $\beta$-fórmula. Entonces:
    \[
        \neg(t\doteq s \land s\doteq r)\in \Phi\ \ o \ \ t\doteq r \in \Phi
    \]
    Veamos que la primera no se cumple: de ser así, y al ser una $\beta$-fórmula, se tendría que:
    \[
        \neg(t \doteq s)\in \Phi\ \ o\ \  \neg(s\doteq r)\in \Phi
    \]
    pero esto es imposible por la coherencia de $\Phi$, pues tanto $t \doteq s$ como $s\doteq r$ están en $\Phi$. Se deduce que necesariamente $t\doteq r \in \Phi$ y entonces $t\equiv_{\Phi} r$.
    \end{enumerate}
\end{proof}
\end{prop}

Dada una relación de equivalencia $\equiv_{\Phi}$ podemos crear de forma natural una partición del conjunto  considerando el conjunto cociente, es decir, el conjunto de clases de equivalencia inducido por $\equiv_{\Phi}$. Dado $t\in T_{\Phi}$, se tiene su clase de equivalencia:
\begin{displaymath}
  [t] := \{s\ |\ s\in T_{\Phi}, t\equiv_{\Phi}s\}
\end{displaymath}
y entonces el conjunto cociente es:
\begin{displaymath}
  T_{\Phi}/\equiv_{\Phi}\quad =\quad \{[t]\ |\ t\in T_{\Phi}\}
\end{displaymath}
El soporte del álgebra que vamos a construir es precisamente este conjunto cociente.

\noindent Ahora hay que definir el valor de las constantes,
las funciones y los símbolos de predicado en el conjunto cociente. 
\begin{itemize}
\item Si $c\in Ct_{S}$ definimos
  \begin{displaymath}
    c^{\mathfrak{T}_{\Phi}}=\left\{
      \begin{array}{ll}
        [c] & \mbox{si}\ c\in T_{\Phi}\\
        \mbox{arbitrario}\footnotemark & \mbox{si no}
      \end{array}
    \right.
  \end{displaymath}
  \footnotetext{Por el lema de coincidencia, para nuestros propósitos no importará el valor que
    tenga.}

\item Si $f|_{k}\in Fn_{S}$ y \(t_{1},\dots t_{k}\in T_{\Phi}\)
  \begin{displaymath}
    f^{\mathfrak{T}_{\Phi}}([t_{1}],\dots [t_{k}])=\left\{
      \begin{array}{ll}
        [f(t_{1},\dots t_{k})]& \mbox{si}\ f(t_{1},\dots t_{k})\in
                                 T_{\Phi}\\
        \mbox{arbitrario} & \mbox{si no}
      \end{array}
    \right.
  \end{displaymath}
\item Si $p|_{k}\in Pd_{S}$ y \(t_{1},\dots t_{k}\in T_{\Phi}\)
  \begin{displaymath}
    p^{\mathfrak{T}_{\Phi}}([t_{1}],\dots [t_{k}])=\left\{
      \begin{array}{ll}
        V & \mbox{si}\ p(t_{1},\dots t_{k})\in\Phi\\
        F & \mbox{si no}
      \end{array}
    \right.
  \end{displaymath}
\end{itemize}

Veamos a continuación que el valor de una clase está bien definido, es decir, no depende de los representantes escogidos:

\begin{prop}
  Sea $S$ una signatura, $\Phi\subseteq FORM_S$ un conjunto de fórmulas de
  Hintikka, $t_{1},\ldots t_{k},s_{1},\ldots,s_{k}\in T_{\Phi}$
  términos tales que $[t_{i}]=[s_{i}]$ para $1\leq i\leq k$.
  \begin{itemize}
  \item Si $f|_{k}\in voc(\Phi)$ entonces $[f(t_{1},\ldots t_{k})]=[f(s_{1},\ldots,s_{k})]$
  \item Si $p|_{k}\in voc(\Phi)$ entonces $p(t_{1},\ldots
    t_{k})\in\Phi$ si y solo si $p(s_{1},\ldots,s_{k})\in\Phi$
  \end{itemize}

  \begin{proof}
    En primer lugar veamos el caso de los símbolos de función.
    Puesto que
    \(\Phi\)
    es de Hintikka tenemos que el axioma de igualdad
    \begin{displaymath}
      \gamma_{0}=\forall x_{1}\dots\forall x_{k}\forall y_{1}\dots \forall
      y_{k}\
      x_{1}\doteq y_{1}\land\dots\land x_{k}\doteq y_{k}\to
      f(x_{1},\dots,x_{k})\doteq f(y_{1},\dots,y_{k})\in\Phi
    \end{displaymath}
  Definimos ahora las siguientes fórmulas, que estarán en $\Phi$ por ser $\Phi$ de Hintikka:
  \begin{displaymath}
    \begin{array}{l}
      \displaystyle\gamma_{1}=\gamma_{0}(t_{1}),\ \ \gamma_{2}=\gamma_{1}(t_{2}),\ \ 
      \dots\ \ \gamma_{k}=\gamma_{k-1}(t_{k})\\
      \gamma_{k+1}=\gamma_{k}(s_{1}),\  \gamma_{k+2}(s_{2}),\ 
      \displaystyle\dots\ \gamma_{2k}=\gamma_{2k-1}(s_{k})\\
      \gamma_{2k}\ =\ t_{1}\doteq s_{1}\land\dots\land t_{k}\doteq s_{k}\rightarrow
      f(t_{1},\dots, t_{k})\doteq f(s_{1},\dots, s_{k})
    \end{array}
  \end{displaymath}
  Resulta que \(\gamma_{2k}\) es una \(\beta\)-fórmula.
  Por tanto \(\neg(t_{1}\doteq s_{1}\y\dots t_{k}\doteq s_{k})
  \in\Phi\) o
  \(f(t_{1},\dots, t_{k})\doteq f(s_{1},\dots, s_{k})\in\Phi\).
  Hay 2 casos:
  \begin{itemize}
  \item
    \(\neg(t_{1}\doteq s_{1}\y\dots t_{k}\doteq s_{k})
    \in\Phi\). Esta es una \(\beta\)-fórmula.
    En este caso, aplicando la regla $\beta$ repetidamente llegamos a que alguna de las fórmulas $\neg (t_{i}\doteq
    s_{i})$ está en $\Phi$. Por otro lado,
    $[t_{i}]=[s_{i}]$ significa \(t_{i}\doteq s_{i}\in\Phi\). Esto  contradice que \(\Phi\) sea de Hintikka, al tener
    $\neg (t_{i}\doteq  s_{i}), t_{i}\doteq  s_{i}\in\Phi$, por tanto este caso no puede darse.
  \item \(f(t_{1},\dots, t_{k})\doteq f(s_{1},\dots,
    s_{k})\in\Phi\). Esta es la definición de
    \( f(t_{1},\dots, t_{k})\equiv_{\Phi} f(s_{1},\dots,
    s_{k}) \), por tanto \( [f(t_{1},\dots, t_{k})]=[f(s_{1},\dots,
    s_{k})] \).
  \end{itemize}

Pasamos ahora a los símbolos de predicado. Nos vale probar que si $p(t_{1},\ldots
    t_{k})\in\Phi$, entonces $p(s_{1},\ldots,s_{k})\in\Phi$. En efecto, la  implicación recíproca es consecuencia de la  implicación directa al intercambiar $t_1,\dots,t_k$ por $s_1,\dots,s_k$ respectivamente.

    Puesto que
    \(\Phi\)
    es de Hintikka contiene el axioma de igualdad
    \begin{displaymath}
      \gamma_{0}=\forall x_{1}\dots\forall x_{k}\forall y_{1}\dots \forall
      y_{k}\
      x_{1}\doteq y_{1}\land\dots\land x_{k}\doteq y_{k}\to(
      p(x_{1},\dots,x_{k})\to p(y_{1},\dots,y_{k})\in\Phi).
    \end{displaymath}
  De forma similar a la vista los símbolos de función, llegamos a que la siguiente fórmula está en $\Phi$:  
\[\gamma_{2k}\ =\ t_{1}\doteq s_{1}\land\dots\land t_{k}\doteq s_{k}\rightarrow
      (p(t_{1},\dots, t_{k})\to p(s_{1},\dots, s_{k}))\]
  Por tanto, \(\neg(t_{1}\doteq s_{1}\y\dots t_{k}\doteq s_{k})
  \in\Phi\) o
  \(p(t_{1},\dots, t_{k})\to p(s_{1},\dots, s_{k})\in\Phi\).
  Hay 2 casos. En el primer caso, igual que con los símbolos de función llegamos a  un absurdo.  En el segundo caso, tenemos que $p(t_{1},\dots, t_{k})\to p(s_{1},\dots,
    s_{k})\in\Phi$. Esto implica, que  o bien $\neg(p(t_{1},\dots, t_{k}))\in\Phi$ en cuyo caso $p(t_{1},\dots, t_{k})\notin\Phi$, o bien $p(s_{1},\dots,
    s_{k})\in\Phi$. En ambos casos se cumple la implicación que buscamos.
\end{proof}
\end{prop}

Ya podemos definir el álgebra que buscamos:
\begin{displaymath}
  \mathfrak{T}_\Phi \ :=\ \bigl\langle
  T_{\Phi}/\equiv_{\Phi},\{c^{\mathfrak{T}_{\Phi}}:=[c]\ |\ c\in Ct_{S}\},
  \{f^{\mathfrak{T}_{\Phi}}\ |\ f|_{k}\in Fn_{S}\},
  \{p^{\mathfrak{T}_{\Phi}}\ |\ p|_{k}\in Pd_{S}\}
  \bigr\rangle
\end{displaymath}

Además, consideremos la asignación de variables:
\begin{displaymath}
  \sigma_{\Phi} :=\left\{
    \begin{array}{ll}
      [x] & \mbox{si } x \in T_{\Phi}\\
      \mbox{arbitrario} & \mbox{si no}
    \end{array}
\end{displaymath}

Y tomamos la interpretación:
\begin{displaymath}
  \mathfrak{I}_{\Phi} := \langle \mathfrak{T}_{\Phi}, \sigma_{\Phi}\rangle
\end{displaymath}

Veamos que \(\mathfrak{I}_{\Phi}\models\Phi\). En primer
lugar tenemos la siguiente 
\begin{prop}\label{prop:terminos}
  Sea $S$ una signatura, $\Phi\subseteq FORM_S$ un conjunto de fórmulas de
  Hintikka y $t\in T_{\Phi}$. Entonces \(t^{\mathfrak{I}_{\Phi}}=[t]\).

  \begin{proof}
Se puede hacer por inducción sobre la longitud de los términos. Para longitud 1, es directo de la definición en constantes y variables. Supongamos que se cumple para palabras de longitud $\leq n$, siendo $n>1$.\\
Ahora, si $t$ es un término de longitud $n$, será de la forma $f(t_1,\dots,t_k)$, donde los $t_i$ tienen longitudes $<n$. Por tanto, por hipótesis de inducción, se cumple $t_i^{\mathfrak{I}_{\Phi}}=[t_i]$ para $i=1,\dots,k$, ya que $t_i\in T_{\Phi}$ para todo $i$. Por tanto:
\[t^{\mathfrak{I}_{\Phi}}=f^{\mathfrak{I}_{\Phi}}([t_1],\dots,[t_k])=[f(t_1,\dots,t_k)],\]
lo cual completa la inducción.
  \end{proof}
\end{prop}

Ahora tenemos que demostrar \(\mathfrak{I}_\Phi \models\varphi\) para cada
\(\varphi\in\Phi\). Para esto no basta con inducción estructural, sino que nos interesa extender la norma que vimos en lógica proposicional:

\begin{definition}
  Sea $S$ una signatura. Definimos la \textit{norma} de una fórmula como:
  $$\|\cdot\|:FORM_S \rightarrow \N$$ de forma recursiva como sigue:
  \begin{itemize}
  \item Caso base: \(\|\varphi\|=0\) si \(\varphi\) es atómica.

  \item Casos recursivos: \mbox{ }
    \begin{itemize}
    \item \(\|\neg\varphi\|=1+\|\varphi\|\)
    \item \(\|\varphi\land\psi\|=1+\|\varphi\|+\|\psi\|\)
    \item \(\|\varphi\lor\psi\|=1+\|\varphi\|+\|\psi\|\)
    \item \(\|\varphi\rightarrow\psi\|=2+\|\varphi\|+\|\psi\|\)
    \item \(\|\varphi\leftrightarrow\psi\|=5+ 2\|\varphi\|+2\|\psi\|\)
    \item \(\|\forall x\,\varphi\|=1+\|\varphi\|\)
    \item \(\|\exists x\,\varphi\|=1+\|\varphi\|\)
    \end{itemize}
  \end{itemize}
\end{definition}



Conviene hacer notar que:
\begin{itemize}
\item \(\|\varphi\rightarrow\psi\| = \|\neg\varphi\lor\psi\|\)
\item \(\|\varphi\leftrightarrow\psi\| = \|(\varphi\rightarrow\psi)\land(\psi\rightarrow\varphi)\|\)
\end{itemize}

Veamos los siguientes resultados auxiliares:
\begin{lema}\mbox{ }
  \begin{itemize}
  \item Si \(\alpha\) es una \(\alpha\)-fórmula,
    \(\|\alpha\|>\|\alpha_{1}\|\) y \(\|\alpha\|>\|\alpha_{2}\|\)
  
  \item Si \(\beta\) es una \(\beta\)-fórmula,
    \(\|\beta\|>\|\beta_{1}\|\) y \(\|\beta\|>\|\beta_{2}\|\)
  \item Si \(\sigma\) es una \(\sigma\)-fórmula,
    \(\|\sigma\|>\|\sigma_1\|\).
  \item Si \(\varphi\in FORM_S\) es una fórmula y $t\in TERM_S$ y  $x\in var$,
    \(\|\varphi[t/x]\|=\|\varphi\|\)
    \end{itemize}
  \begin{proof}
    Las tres primeras son fáciles de obtener por casos.
    La última se demuestra por una inducción estructural rutinaria en $\varphi$. Intuitivamente este lema quiere decir que la norma de una fórmula no depende de los términos involucrados.
  \end{proof}
  \end{lema}


\begin{lema}\label{le:casobase}
  Sea \(S\) una signatura, \(\Phi\subseteq FORM_S\) de Hintikka y \(\varphi\in FORMAT_S\). Entonces, si
  \(\varphi\in\Phi\) se cumple \(\mathfrak{I}_{\Phi}\models\varphi\). De hecho la implicación recíproca también se cumple excepto si $\varphi=\top$.
  \begin{proof}\mbox{}
      \begin{itemize}
      \item \(\varphi=\top\). Trivial
      \item \(\varphi\ =\ t\doteq s\). En este
        caso \(\varphi\in\Phi\) si y solo si \(t\equiv_{\Phi}s\), que es lo mismo
        que  \([t]=[s]\). Por la
        proposición~\ref{prop:terminos} esto equivale a 
        \(t^{\mathfrak{I}_{\Phi}}=s^{\mathfrak{I}_{\Phi}}\), que equivale a
        \(\mathfrak{I}_{\Phi}\models t\doteq s\).
      \item \(\varphi\ =\ p(t_{1},\dots, t_{k})\) para
        \(p|_{k}\in Pd_{S}\) y \(t_{1},\dots, t_{k}\in T_{\Phi}\).

        Por definición \(p(t_{1},\dots, t_{k})\in\Phi\) si y solo si
        $
          p^{\mathfrak{T}_{\Phi}}([t_{1}],\dots,[t_{k}]) = V
          $.
        Por tanto tenemos
        \begin{displaymath}
          p^{\mathfrak{T}_{\Phi}}([t_{1}],\dots,[t_{k}])=
          p^{\mathfrak{T}_{\Phi}}(t_{1}^{\mathfrak{I}_{\Phi}},\dots,t_{k}^{\mathfrak{I}_{\Phi}})=
          (p(t_{1},\dots, t_{k}))^{\mathfrak{I}_{\Phi}}
        \end{displaymath}
        Puesto que $(p(t_{1},\dots, t_{k}))^{\mathfrak{I}_{\Phi}}=V$
        es la definición de
        \(\mathfrak{I}_{\Phi}\models p(t_{1},\dots, t_{k})\in\Phi\), tenemos
        \(p(t_{1},\dots, t_{k})\in\Phi\) si y solo si
        \(\mathfrak{I}_{\Phi}\models p(t_{1},\dots, t_{k})\in\Phi\).
      \end{itemize}
  \end{proof}
\end{lema}


Ahora podemos demostrar el resultado que buscamos.
\begin{theorem}
  Sea \(S\) una signatura y \(\Phi\subseteq FORM_S\) un conjunto de
  fórmulas de Hintikka, entonces \(\mathfrak{I}_{\Phi}\models\Phi\).
  \begin{proof}
    Sea \(\varphi\in\Phi\), probaremos \(\mathfrak{I}_{\Phi}\models\varphi\)
    por inducción sobre \(\|\varphi\|\).
    \begin{description}
    \item[\(\|\varphi\|=0\)] Es una de las implicaciones
      del lema~\ref{le:casobase}.
    \item[\(\|\varphi\|>0\)]
      En ese caso tenemos varias opciones
      \begin{itemize}
      \item \(\varphi=\alpha\) es una \(\alpha\)-fórmula. Al ser
        \(\Phi\) un conjunto \(\alpha\)-saturado, tenemos
        \(\alpha_{1},\alpha_{2}\in\Phi\). Puesto que
        \(\|\alpha\|>\|\alpha_{1}\|\) y
        \(\|\alpha\|>\|\alpha_{2}\|\) podemos aplicar hipótesis de
        inducción y tenemos
        \(\mathfrak{I}_{\Phi}\models\alpha_{1}\) y
        \(\mathfrak{I}_{\Phi}\models\alpha_{2}\). Puesto que
        \(\varphi=\alpha\sim\alpha_{1}\land\alpha_{2}\) tenemos
        \(\mathfrak{I}_{\Phi}\models\varphi\).

      \item \(\varphi=\beta\) es una \(\beta\)-fórmula.
        En este caso, $\beta_1\in\Phi$ o $\beta_2\in\Phi$. Esto implica por hipótesis de inducción que \(\mathfrak{I}_{\Phi}\models\beta_{1}\) o
        \(\mathfrak{I}_{\Phi}\models\beta_{2}\). Como $\beta\sim\beta_1\lor\beta_2$, en ambos casos se cumple que \(\mathfrak{I}_{\Phi}\models\beta\).
      \item \(\varphi=\sigma\) es una \(\sigma\)-fórmula.
       Similar a las anteriores.

      \item \(\varphi=\gamma\) es una \(\gamma\)-fórmula.
        Hay 2 casos
        \begin{itemize}
        \item \(\varphi=\forall x\,\psi\). Al ser $\Phi$ saturado, tenemos que para todo término $t\in T_{\Phi}$ se verifica $\psi[t/x]\in\Phi$. Además, 
\[||\forall x\psi||=1+||\psi||>||\psi||=||\psi[t/x]||,\]
        por tanto por hipótesis de inducción, para todo $t\in T_\Phi$ se cumple $\mathfrak{I}_\Phi\vDash\psi[t/x]$. Esto equivale por el lema de sustitución a que $\mathfrak{I}_\Phi[t^{\mathfrak{I}_\Phi}/x]\vDash\psi$, es decir, $\mathfrak{I}_\Phi[[t]/x]\vDash\psi$.\\
        Como esto se cumple para cualquier elemento y cada clase de equivalencia $a\in T_{\Phi}/\equiv_{\Phi}$ contiene al menos un elemento, tenemos que para todo $a\in T_{\Phi}/\equiv_{\Phi}$ se cumple que $\mathfrak{I}_\Phi[a/x]\vDash\psi$. Esto es la definición de que $\mathfrak{I}\vDash\forall x\psi$, y hemos acabado.
        \item \(\varphi=\neg\exists x\,\psi\).
          Puesto que \(\Phi\) es saturado tenemos que para todo
          término
          \(t\in T_{\Phi}\) se verifica \(\neg\psi[t/x]\in\Phi\).
          Por otro lado
          \begin{displaymath}
            \|\neg\exists x\,\psi\| = 2+\|\psi\| =
            1+\|\neg\psi\| > \|\neg\psi\| = \|\neg\psi[t/x]\|,
          \end{displaymath}
        Por tanto podemos aplicar inducción a los términos $\neg\psi[t/x]$
        para $t\in T_{\Phi}$. Por lo que podemos decir que
        para cada \(t\in T_{\Phi}\) tenemos
        \(\mathfrak{I}_{\Phi}\models \neg\psi[t/x]\) y,
        aplicando el lema de sustitución, tenemos
        \(\mathfrak{I}_{\Phi}[t^{\mathfrak{I}_{\Phi}}/x]\models \neg\psi\).
        Puesto que \(t^{\mathfrak{I}_{\Phi}}=[t]\),
        
        tenemos que para cada \([t]\in T_{\Phi}/\equiv_{\Phi}\)
        se verifica
        \(\mathfrak{I}_{\Phi}[[t]/x]\models \neg\psi\). Puesto que cada
        elemento
        de $t\in T_{\Phi}$ está en una y solo una clase de
        equivalencia, podemos decir que para cada
        \(a\in T_{\Phi}/\equiv_{\Phi}\)
        se verifica
        \(\mathfrak{I}_{\Phi}[a/x]\models \neg\psi\), que es la definición
        de que $\mathfrak{I}_{\Phi}\models\forall x\,\neg\psi$.
        Puesto que $\forall x\,\neg\psi\sim\neg\exists x\,\psi$
        tenemos el resultado.
        \end{itemize}
      \item \(\varphi=\delta\) es una \(\delta\)-fórmula. 2 casos.
      \begin{itemize}
        \item $\varphi=\exists x\psi$. En este caso, al ser $\Phi$ saturado, existe una constante auxiliar $c\in C_A$ tal que $\psi[c/x]\in\Phi$. Además, tenemos que 
\[||\exists x\psi||=1+||\psi||>||\psi||=||\psi[c/x]||,\]
        por tanto por hipótesis de inducción, se cumple que $\mathfrak{I}_\Phi\vDash\psi[c/x]$. Por el lema de sustitución, tenemos que $\mathfrak{I}_\Phi[c^{\mathfrak{I}_\Phi}/x]\vDash\psi$. Es decir, existe un elemento $a$ del conjunto soporte tal que $\mathfrak{I}_\Phi[a/x]\vDash\psi$. Esto es la definición de $\mathfrak{I}_\Phi\vDash\exists x\psi$,y hemos acabado.
        \item $\varphi=\neg\forall x\psi$. Caso similar al anterior.
      \end{itemize}
        

      \end{itemize}
    \end{description}
  \end{proof}
\end{theorem}


\subsection{\textit{Tableau} canónico. Teorema de compacidad}

Volvemos a considerar el concepto de
\emph{tableau completo}, análogo al visto en lógica proposicional:
\begin{definition}
  Sean $S$ una signatura y $\Phi\subseteq FORM_S$. Un
  \textit{tableau} $T$ es \textit{completo para }\(\Phi\) si cada rama abierta \(r\) suya verifica:
  \begin{enumerate}
  \item \(\Phi\subseteq\Gamma_{r}\)
  \item \(\Gamma_{r}\) es de Hintikka.
  \end{enumerate}

\end{definition}

La principal diferencia que tenemos respecto a la lógica
proposicional es que
en lógica de primer orden hemos visto que, a la hora de hacer
un razonamiento \(\Phi\models\varphi\), el conjunto \(\Phi\) puede ser 
infinito o bien, incluso si el conjunto de fórmulas es finito, la aplicación de reglas de
tipo \(\gamma\) hace que el conjunto de fórmulas que tengamos que
considerar es infinito, dado que el
conjunto de términos suele ser infinito. Esto hace necesario considerar
árboles infinitos para construir un \textit{tableau} completo, lo que llamaremos  \emph{tableau canónico}. En general, es un árbol infinito y por tanto no podremos construirlo en un conjunto
finito de pasos. Podemos, en cambio, decir cómo se construye cada
uno de esos pasos. El límite de los árboles construidos mediante esos pasos será tal \emph{tableau} canónico.

De ahora en adelante, para la construcción del \textit{tableau} canónico, nos vamos a restringir a
signaturas numerables, es decir, aquéllas en que el conjunto de todos los símbolos es numerable.\footnote{En la práctica, necesitaremos algo más fuerte: que la signatura sea efectivamente enumerable, es decir, que haya un algoritmo que permita obtener una numeración de los símbolos. Más información en la sección \ref{teoyenum}.}

A continuación obtenemos un resultado relativo al cierre de Kleene:
\begin{lema}
  Si un conjunto \(A\) es numerable, \(A^{*}\) es numerable.
 \end{lema}
  \begin{proof}
    Consideremos $A_{0}=\{\epsilon\}$, donde $\epsilon$ es la cadena vacía. Sea:
    \begin{displaymath}
      A_{n} = A_{n-1}\cup\{a\omega\ |\ a\in A\ \omega\in
      A_{n-1}\}\footnote{\(a\omega\) denota la concatenación de
        \(a\) y \(\omega\)}
    \end{displaymath}
    Puesto que $A$ es numerable, es fácil ver por inducción que $A_i$ es numerable para cada $i\in\mathbb{N}$.
    Por otro lado, $A^*=\displaystyle\bigcup_{i\in\mathbb{N}} A_i$, por tanto, \(A^{*}\) es numerable.
  \end{proof}

Como consecuencia, el conjunto de términos y fórmulas de una signatura numerable
es numerable.
\\\
Consideremos lo siguiente:
\begin{enumerate}
\item \(S\) una signatura numerable.
\item El conjunto de constantes auxiliares, que supondremos también
  numerable:
  \begin{displaymath}
    C_{A}=\{c_{0}, c_{1},\ldots, c_{k},\ldots\}
  \end{displaymath}
\item \(\overline{S}:=S\cup C_{A}\), que también es numerable.
\item El conjunto de términos, considerando también el conjunto de
  constantes auxiliares. Por lo dicho antes, es numerable. Además, consideramos una enumeración:
  \begin{displaymath}
    TERM_{\overline{S}}=\{t_{0}, t_{1},\ldots, t_{k},\ldots\}
  \end{displaymath}
\begin{comment}
  De modo que si
  \(voc(t_{i})\subseteq voc(t_{j})\), entonces \(i\leq j\).
\end{comment}

\item El conjunto de \(\gamma\)-fórmulas. Puesto que es un subconjunto
  de fórmulas, también es numerable y consideramos una numeración suya:
  \begin{displaymath}
    G:=\{\gamma_{0}, \gamma_{1},\ldots, \gamma_{k},\ldots\}
  \end{displaymath}
\item El conjunto de axiomas de igualdad. Consideramos una numeración
  de estas fórmulas,
  \begin{displaymath}
    \Theta:=\{\theta_{0}, \theta_{1},\ldots, \theta_{k},\ldots\}
  \end{displaymath}
\item El conjunto de fórmulas \(\Phi\) para las que queremos construir
  el \textit{tableau}. Una numeración suya es:
  \begin{displaymath}
    \Phi:=\{\varphi_{0}, \varphi_{1},\ldots, \varphi_{k},\ldots\}
  \end{displaymath}
\end{enumerate}

\\\
Pasamos ahora a construir el \textit{tableau} canónico, teniendo en cuenta todos los anteriores elementos.
\\
Dado un \textit{tableau} finito, vamos a definir varias formas de extenderlo. Esto dará lugar a lo que se llaman \textit{extensiones}. Enumerémoslas a continuación. 

\subsubsection{ABSD-extensión}

Esta extensión la denotaremos como \(\mathbf{ABSD}(T,n)\), donde \(T\) es un
tableau y $n$ es un entero. Esta extensión desplegará por orden todas
las ramas que a profundidad $n$ tengan una fórmula de tipo \(\alpha\),
\(\beta\), \(\sigma\) o \(\delta\). En el siguiente orden:
\begin{enumerate}
\item Fórmulas de tipo \(\alpha\). En cada rama abierta $r$ que tenga
  a profundidad menor o igual que \(n\) una fórmula de tipo \(\alpha\)
  no desplegada, aplicamos a esa fórmula la regla \(\alpha\):
 
% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQQBfU9TXfQijLFqdJq3YAdSUzQALelx4gM2PASLlSAJlEMWbRB2681AomV019Eo0tP8NKbTr3jDx5aseCSpAMxuBlIyjPL0APrE9ip86r5kACxBtiDSsgoR2lyiMFAA5vBEoABmAE4QALZIWiA4EEhkYsGIYMyMjDSM9ABGMIwACnHmRowwJTggNHIw9FDskGBsJiDlVTU09UguzbZtHV29-UNmTiBjE1MgM3MLBMvKa9WItVuIidbuSPud50eDwzOF0m01m8yMiwepQqzyab38nxaP0OfQBp0E53GIOuYLuSyufTA4PIKye202DUQCN2hmRf1RJx87GBVxu4PA9xiZKpFKQHxp33av26DMBGJZoNuEM5pJhSGpbwArJL2ZCuXLEMq6pSAGwqvFQ1Ya16UpqE8EAdiajCw+KMUHocBm831RgUZQwBCY2Jw9CwjHYcggEAA1t6rjYPAACQicSicIA

\begin{center}
    \includegraphics[scale =0.55]{figures/alpha.png}
\end{center}

  
\item Fórmulas de tipo \(\beta\). En cada rama abierta $r$ que tenga
  a profundidad menor o igual que \(n\) una fórmula de tipo \(\beta\)
  no desplegada, aplicamos a esa fórmula la regla \(\beta\):
 % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQQBfU9TXfQijLFqdJq3YAdSQCMYOelx4gM2PASLlSAJlEMWbRB2681AomV019Eo0tP8NKbTr3jDx5aseDkWgMxuBlKy8vQA+sT2Knzqvi6B1u4hcgrh2lyiMFAA5vBEoABmAE4QALZIWiA4EEhkYsGIYMyMjDSM9HKMAAqx5kaMMIU4IDQAFjD0UOyQYGwmICXllTQ1SC4Nts2t7Z0wPX1OIIPDoyATUzME88pLFYhVa4gALEmN223HewdmRycj40m0yMsxuRVK93qT38by2LU+HS6vV+gmOQwB5yBVzmZzkYGB5AWd3Wq1qiBhm0MH12SMOqP+ZwuwPA12ixPJpKQr0pSGpX1pKPYDMBlxBrKJEKQFKeAFYRczQWzJQ9OYh6njgQB2eqMLA4oxQehwCbTeXsMb0YoYAhMDEKLCMc0QCAAa1tZxsHkIEuWHOqZIAbGaxTjOJROEA
  \begin{center}
   \includegraphics[scale =0.55]{figures/beta.png}
  \end{center}
  
\item Fórmulas de tipo \(\sigma\). En cada rama abierta $r$ que tenga
  a profundidad menor o igual que \(n\) una fórmula de tipo \(\sigma\)
  no desplegada, aplicamos a esa fórmula la regla \(\sigma\):
  
 % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQQBfU9TXfQijLFqdJq3YAdSdgDmAW3pceIDNjwEi5UgCZRDFm0QduvdQKJk9NAxOPKz-TSh2794oyZVqngkqQBmd0MpGSwFegB9Yi5RGChZeCJQADMAJwh5JG0QHAgkMjEQxDBmRkYaRnoAIxhGAAU+DUEQRhgUnBAaAAsYeih2SDA2UxB0zOyaPKRXIrtS8sqausbzZ1b2zp6+geMhkZVxrMQc6cQAFhsPJAWK1uWGpotjNo6ukF7+wYID1IzjwpnAJXYq3Ja1R5rFqvLYfHbfYbvWpgXbkUZHGZTfKIYFzIxg+4Q1a+dgw96fXbgH4OMb-JC4s6XPE3Mp3KpEp7rMnbL57anouknLEFGjI3YAdkKjCwiOMUHocF6Ax5lO69DSGAITFhOHoWEY7G6EAgAGtte9bJ5CAKJjjhYgAKwqhEjSicIA
  \begin{center}
    \includegraphics[scale =0.55]{figures/sigma.png}
  \end{center}
\item Fórmulas de tipo \(\delta\). En cada rama abierta $r$ que tenga
  a profundidad menor o igual que \(n\) una fórmula de tipo \(\delta\)
  no desplegada, aplicamos a esa fórmula la regla \(\delta\):
 % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZARgBoAGAXVJADcBDAGwFcYkQQBfU9TXfQijLFqdJq3YAdSbEY56XHiAzY8BIuVIAmUQxZtEHbr1UCiZHTT0TDik-3Uot23eINGlKh4JKkAzK76UjIwcvQAFADGAJRcojBQAObwRKAAZgBOEAC2SJogOBBIZGJBiGDMjIw0jPQARqEACnxqgiCMMGk4IDQAFjD0UOyQYGzGIJk5eTSFSM6lNhVVNfVNLWaGHV09IP2DwwRjSpO5iPmziAAsVm5IS9Xtq4zNpo7tnd19A0OGI0fpWVOJQufhuZXuKwaz3Wby2n123wOox2DTAP3I4xOcxmRUQoIWBghjyhL287DhOz2P3AhzsE0BSHxF2uBLulQetRJMLaFK++1+tMxDLOOOKNFRPwA7CVGFhkYYoPQ4P0hnzqb16BkMAQmPD5FhGOxehAIABrXU7azuQhCqZ40WIACsaqRY0onCAA
  \begin{center}
    \includegraphics[scale =0.55]{figures/delta.png}
  \end{center}
\end{enumerate}

\subsubsection{EF-extensión}
Esta extensión la denominamos \(\mathbf{EF}(T,n)\). Consiste en añadir a cada
rama abierta $r$ de $T$ las fórmulas \(\varphi_{n}\in\Phi\) (según la numeración
del conjunto de fórmulas \(\Phi\)) y la fórmula \(\theta_{n}\in
EQ_{S}\) (según la numeración de las fórmulas de los axiomas de la
igualdad).
\begin{center}
  \includegraphics[scale = 0.55]{figures/ef.png}
\end{center}
\subsubsection{G-extensión}
Esta extensión se denota \(\mathbf{G}(T,n)\). Consiste en extender cada rama
abierta $r$ de $T$ con la fórmula \(\gamma_{i}(t_{j})\) donde el par \((i,j)\in \mathbb{N}\times\mathbb{N}\) es el menor par según el
  siguiente buen orden de \(\mathbb{N}\times\mathbb{N}\)
\[(i_{1},j_{1})< (i_{2},j_{2})\text{ sii }i_{1}+j_{1}<i_{2}+j_{2}\text{ o bien }i_{1}+j_{1}=i_{2}+j_{2}\text{ e }i_{1}<i_{2}\]
\begin{comment}
  \begin{displaymath}
    (i_{1},j_{1})< (i_{2},j_{2}) \quad\mbox{sii}\quad
    \left\{
      \begin{array}{ll}
        i_{1}+j_{1}<i_{2}+j_{2}\\
        i_{1}<i_{2} & \mbox{si}\ i_{1}+j_{1}=i_{2}+j_{2}
      \end{array}
    \right.
  \end{displaymath}
\end{comment}
 tal que $\gamma_{i}\in\Gamma_r$ está a altura $\leq n$,
  \(\gamma_{i}(t_{j})\not\in\Gamma_{r}\) y \(t_{j}\) es adecuado
  para \(\Gamma_{r}\). Si no hay ningún término adecuado para \(\Gamma_{r}\), aplicamos la regla considerando como término adecuado la primera constante auxiliar.
\end{itemize}
\begin{center}
  \includegraphics[scale = 0.55]{figures/gamma.png}
\end{center}

Por ejemplo,
supongamos \(\gamma_{0},\gamma_{2}\in\Gamma_{r}\) y
\(\gamma_{1}\not\in\Gamma_{r}\). Las fórmulas se van poniendo en el
siguiente orden en las ramas: \(\gamma_{0}(t_{0})\),
\(\gamma_{0}(t_{1})\), \(\gamma_{0}(t_{2})\) y \(\gamma_{2}(t_{0})\), donde hemos omitido las fórmulas con $\gamma_1$ ya que \(\gamma_{1}\not\in\Gamma_{r}\).


Veamos finalmente cómo se construye el \textit{tableau} canónico de una secuencia de fórmulas $\Phi=\{\varphi_1,\varphi_2,\dots\}$. Definimos la siguiente secuencia de árboles:
% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAB136AnNACywB9YiAC+pdJlz5CKMgEYqtRizaccfGDjrCxSmFADm8IqABm3CAFskZEDghJ51TXShtIYVqIqigA
\begin{center}
$T_0 = $
\begin{tikzcd}
\varphi_0 \arrow[d, no head] \\
\theta_0                    
\end{tikzcd}
\end{center}
Luego definimos para $n\geq 1$:
\begin{displaymath}
  \begin{array}{l@{\ =\ }l}
    T_{n}^{1}& \mathbf{ABSD}(T_{n-1}, n)\\
    T_{n}^{2}& \mathbf{G}(T_{n}^{1}, n) \\
    T_{n} & \mathbf{EF}(T_{n}^{2}, n)\\
  \end{array}
\end{displaymath}

Tenemos así una secuencia de árboles
\begin{displaymath}
  T_{0}\subseteq T_{1}\subseteq\ldots T_{k}\subseteq T_{k+1}\subseteq\ldots
\end{displaymath}
El \textit{tableau} canónico de un conjunto de fórmulas \(\Phi\), que denotaremos
por \(T_{\Phi}\), se construye como se indica a continuación.
En la secuencia anterior se cumple una de las siguientes condiciones:
\begin{itemize}

\item Existe $n$ tal que \(T_{n}=T_{n+1}\) y $T_n$ no tiene fórmulas a altura $>n$. Eso significa, por como están definidas las reglas, que \(T_{k}=T_{k+1}\) para todo $k\geq n$. El \textit{tableau} canónico es
  $T_{\Phi}=T_{n}$
\item No se da el caso anterior. Entonces tenemos una secuencia infinita y el \textit{tableau} canónico es el límite de
todos los árboles
\begin{displaymath}
  T_{\Phi} = \bigcup_{i\in\mathbb{N}}T_{i}
\end{displaymath}
\end{itemize}

 \begin{comment}
\begin{prop}
 Sea $S$ una signatura y \(\Phi\subseteq FORM_S\). Consideremos la
  secuencia de árboles \(T_{i},\ i\in\mathbb{N}\) que da lugar al \textit{tableau}
  canónico.
  Sea \(n\in\mathbb{N}\) y $r$ una rama abierta de \(T_{n}\).Entonces la longitud de $r$ es mayor que $n$.

  \begin{center}
    \includegraphics[scale= 0.6]{figures/prof.png}
  \end{center}
    \begin{proof}

  \end{proof}
  \end{comment}


\end{prop}


\begin{prop}
  Sea $S$ una signaturas, \(\Phi\subseteq FORM_S\), \(r\) una rama del
  \textit{tableau} canónico \(T_{\Phi}\) y \(\varphi\in\Gamma_{r}\) está a
  profundidad $k$. Entonces ha sido introducida en un paso $l<k$.
\end{prop}
  \begin{proof}
Lo probamos por inducción. En el caso 0 está claro que se cumple. Supongamos que se cumple para $n-1$. Sea $\varphi$ fórmula en $r$ a profundidad $k$, y supongamos que la hemos introducido en el paso $l\geq k$. Pues bien, la fórmula $\psi$ que está encima de $\varphi$, que está a altura $k-1$, ha tenido que ser introducida en la rama en un paso $\leq k-2$ por hipótesis de inducción. Esto significa que desde el \textit{tableau} $T_{l-2}$ a $T_{l-1}$ (es decir, en el paso $l-1$) no se ha añadido ningún elemento a esa rama. El resto se reduce a comprobar regla a regla que si una rama tiene longitud $l-1$ y no hemos añadido ninguna fórmula al aplicar la regla a esa rama en el paso $l-1$, entonces tampoco se añade ninguna fórmula al aplicar esa regla a la rama en el paso $l$, lo cual es una contradicción.
  \end{proof}
\end{corollary}

\begin{theorem}
  Sea $S$ una signaturas y \(\Phi\subseteq FORM_S\). El \texit{tableau} canónico
  \(T_{\Phi}\) es completo.

  \begin{proof}
    Sea $r$ una rama abierta de \(T_{\Phi}\). Hemos de demostrar
    \(\Phi\subseteq\Gamma_{r}\) y \(\Gamma_{r}\) es de Hintikka.\\
    Lo primero es fácil, dada \(\varphi\in\Phi\), existe un $k\in\N$
    tal que \(\varphi=\varphi_{k}\). Esa fórmula ha sido introducida en $r$ en el
    árbol \(T_{k}\) al aplicar la regla \(\mathbf{EF}(T_k^2,n)\), de modo que ya tenemos que $\Phi\subseteq\Gamma_{r}$.\\
    Para ver que \(\Gamma_{r}\) es de Hintikka, comprobamos primero que no puede darse $\bot\in\Gamma_r$ o $\varphi,\neg\varphi\in\Gamma_r$ para ninguna $\varphi$, ya que en ese caso $r$ sería una rama cerrada.
    Veamos que se cumplen el resto condiciones de la definición de Hintikka.
    \begin{description}
    \item[\(\alpha\)-saturación.] Tomemos \(\alpha\in\Gamma_{r}\). Esa
      fórmula estará a una profundidad \(k\) del árbol. Esa fórmula ha
      sido expandida en el el arbol $T_{k}$. Por tanto
      \(\alpha_{1},\alpha_{2}\in\Gamma_{r}\).\\

    \item[\(\beta\)-saturación, \(\sigma\)-saturación,
      \(\delta\)-saturación.] Similar al anterior.\\
    \item[$\gamma$-saturación.]


    Sea \(\gamma\in\Gamma_{r}\) y $t\in TERM_{\overline{S}}$ un
      término adecuado para \(\Gamma_{r}\). Existe
      $n\in\N$ de forma que $\gamma$ está en la rama $r$ en todos
      los \textit{tableaux} $T_{k}$ con $k\geq n$. \\[5pt]
      Además existen $i\in\N$ tal que $\gamma=\gamma_{i}$ (en la numeración de las
      \(\gamma\)-fórmulas) y $j\in\N$ tal que $t=t_{j}$ (en la
      numeración de los términos). Llamamos $l$ a la posición que ocupa el par $(i,j)$ en nuestro buen orden de \(\N\times\N\).\\[5pt]
      Por otro lado, como $t$ es adecuado para \(\Gamma_{r}\) y \(voc(t)\) y $var(t)$ son finitos, hay cierto $m$ tal que $voc(t)\subseteq voc(\Gamma_{r_m})$ y $var(t)\subseteq lib(\Gamma_{r_m})$, es decir, $t$ es adecuado para $\Gamma_{r_m}$, siendo $r_m$ la rama del \textit{tableau} $T_m$ que da lugar a $r$.\\[5pt]
      Tras haber definido $n,m$ y $l$, está claro que en el \textit{tableau} $T_{n+m}$ se cumple que $t$ es adecuado para $\Gamma_{r_{n+m}}$ y $\gamma\in\Gamma_{r_{n+m}}$. De modo que, tras aplicar $l$ veces más la regla \mathbf{G}, es decir, en el \textit{tableau} $T_{n+m+l}$, tenemos que haber añadido en cierto punto la fórmula $\gamma(t)$. Por tanto para todo término $t$ adecuado para $\Gamma_r$, $\gamma(t)$ estará incluida en la rama, como queríamos.
    \end{description}
  \end{proof}
\end{theorem}

\begin{cor} (Completitud)
  Sea $S$ signatura y \(\Phi\subseteq FORM_S\) tal que
  $\text{Insat}(\Phi)$. Entonces:
  \begin{enumerate}[label=\alph*)]
  \item $\Phi$ tiene un \textit{tableau} cerrado finito.
  \item Sea \(\varphi\in FORM_S\) tal que \(\Phi\models\varphi\). Entonces
    \(\Phi\vdash_{tb}\varphi\).
  \end{enumerate}
  \end{cor}

  \begin{proof}
    El segundo apartado es aplicación inmediata del primero al conjunto $\Psi=\Phi\cup\{\neg\varphi\}$. Así que
    demostraremos $b)$. Construimos el \textit{tableau} canónico
    \(T_{\Phi}\). Puesto que \(T_{\Phi}\) es completo para \(\Phi\),
    si \(T_{\Phi}\) tuviera una rama \(r\) abierta tendríamos
    \begin{itemize}
    \item \(\Phi\subseteq \Gamma_{r}\)
    \item \(\Gamma_{r}\) es de Hintikka y por tanto satisfactible.
    \end{itemize}
    Por tanto tendríamos que \(\Phi\) es satisfactible. Por tanto
    \(T_{\Phi}\) ha de ser cerrado. Por el lema \ref{cefi}, el tableau es finito.
  \end{proof}

\begin{theorem}(Teorema de compacidad)\label{compacidad}
  Sea $S$ una signatura, \(\Phi\subseteq FORM_S\).
  \begin{enumerate}[label=\alph*)]
  \item Si $\text{Insat}(\Phi)$, existe $\Phi_{\mathit{fin}}\subseteq\Phi$ finito tal
    que $\text{Insat}(\Phi_{\mathit{fin}})$.
  \item Si todo conjunto finito $\Phi_{\mathit{fin}}\subseteq\Phi$ verifica
    $Sat(\Phi_{\mathit{fin}})$, entonces $Sat(\Phi)$.
  \end{enumerate}
  \begin{proof}
    Puesto que \(\Phi\) es insatisfactible tiene un \textit{tableau} cerrado
    \(T\). Al ser cerrado, es finito. Consideramos entonces
    el conjunto
    \(\Phi_{\mathit{fin}}=\Phi\cap\Gamma_{T}\)\footnote{\(\Gamma_{T}\) es el
      conjunto de fórmulas que aparecen en el \textit{tableau} T.}.
    Veamos que verifica las propiedades buscadas:
    \begin{itemize}
    \item Es finito, al ser $T$ finito.
    \item \(\Phi_{\mathit{fin}}\subseteq\Phi\).
    \item $\text{Insat}(\Phi_{\mathit{fin}})$ puesto que \(T\) también es un \textit{tableau}
      para \(\Phi_{\mathit{fin}}\).
    \end{itemize}
    El segundo apartado es simplemente la afirmación contrarrecíproca del primero.
  \end{proof}
\end{theorem}



\subsection{Ejemplo de \textit{tableau} canónico abierto}
Veamos un ejemplo de \textit{Tableau} canónico abierto. Este ejemplo no tiene funciones, ya que cuando hay funciones el \textit{Tableau} resultante es infinito, al haber infinitos términos que sustituir en las reglas \mathbf{G}. El tableaux siguiente corresponde al conjunto de fórmulas \[\Phi=\{\forall x\;P(x)\lor Q(x),\neg(\forall x\; P(x)\lor \forall x\; Q(x))\}=\{\varphi_0,\varphi_1\}\]
Veremos que este tableau es satisfactible, de modo que al acabar de desarrollarlo tendremos ramas abiertas que nos permitirán encontrar modelos que satisfagan $\Phi$.\\

Para simplificar el \textit{tableau}, al desarrollarlo se van a ignorar los axiomas de igualdad. Veremos que en este caso esto no va a ser un problema ya que vamos a poder encontrar los modelos igualmente.\\

También para simplificar, vamos a enumerar las fórmulas según su altura. Esto dará lugar a que haya varias fórmulas numeradas igual, pero no causará ambiguedades ya que en cada rama solo habrá una fórmula con cada número.\\

Otra anotación importante es que en la versión teórica del algoritmo, tenemos una numeración predefinida de los términos y de las $\gamma$-fórmulas. Sin embargo, en la práctica obviamente solo haremos \textit{tableaux} finitos. Como da igual cambiar el orden de finitos términos, podemos establecer el orden de los finitos términos o $\gamma$-fórmulas que usemos según nos convenga.\\

Se muestra primero el \textit{tableau} construido y a continuación explicamos su construcción paso a paso. 



\hspace{-2cm}
\includegraphics[scale = 0.5]{figures/tableau6.png}


\begin{comment}
% https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRABUB9YkAX1PSZc+QigCM5KrUYs2AAjEA6OQB0VAMwgAnRgzkAPVStIAKAAon9ASiMNtcgIqWrVvgJAZseAkQlip9MysiCAATMoWAMbcNmp2Wo4m0cSu-IJeIkRkoQEywRycYm7pwj7ipDnUgbIhAMzKamAwAOYmapo6DHqGaqRyFta29u3augZGfU7Wqe6epaIkpLW5QWxcocUeQt4LEstVeWwALBFJMZtzO0S1Sys1ICeJyTMlV+VHd-kArA0qTc1GDpjHrGfrOC7bTIoG4fA6rEI-Iz-QGjLoGXpgwYQjJlRZfT5rTi1bHzXykfFw+4ANl+yJGnW6E0S1hJb2QNwp0nhIBpSJaKIZ4wxUxeWxxu1IVIJIQA7LT+VFCqLLlD2ZLpSA5XyAYrQsrIbiyDKNVwvqzVRJjZT8gAOU7RMSxFTxJ5K824m5Wrn3O1g6J6oYJJz+-Xisk2jUATnlAODRNDpOhpAj1rY0e1rqOCbZZEjJs4VPdErzqZCYmI9vjgddtWzqpuJe9+XLlaz1bjWaLWVI5fzNq75V7pZACiUfqVRgAxDK+mIimkxYnkKEe5Rh3PFHHHQO1UOm2wN669TujquNYfdVY1NPZ-PZgaFmQ5-ngOXeDu-P51+Fx7Wdyvn2-ZQ41ra9I1nDYFxVD0ey-fcyx-DsrxUSdwIUSD7zDFBT0A+CQDEH9FU7XgpBgKBmngIhQHULQIAAWyQCQQBwCAkBXPC1GaOg6LouhZxAagGDoAAjGAGDMB82AYGB1BwASQAACxgOgoDYSAmk2Gj6LY6gWKQU88IUrA0BMbdBJEsSJKwkBpNk+SlJUtSCFYBctIYxADL0xAqWHNRRJwPiNnM0TxMkkJbLk6gHNUkJ1Jc9w3P03TWMQGcOJUfy+LkIKbIs0LrIi+zlJi8BnM02j3J85iUptXyVEYNAFKy4lgsssKbJkyLFOKpyNNciqkDSrzwPShqmr6FrcpCqzEw6uyop62Kyv67TEFq6rGKY6p8jUMbmvkoTpvawqFscpa+oSgbEBGryCLqvaJoOvKZreOauui3r4uoq652SxibnS2AGACvozVa-LZpO7qztKi7vtWu6NsQMQDO2tg1CBkG5DBqa2oKzqiphuLyoRgHbqqtGQk47jeP48GXqhN7CZK4mVvclG-uRtLKZAameKyop6eOgnTpZ5bLoRqrbvWnmMbErHCyF-H5uhsW4ZARKuc5sQRtllRMayxXcYh16oY+86vo1n71q80ItsOKmVC4-m6eNhmyiZ0XPpJ9mbpS0J2L153aYUJ6juV97Fthy3NbtznQlRh3eYymAsf7JXIZF1XvbZtimNtr46syvp07d4WVfN6OfbY9jbYppO-NTrLS8OvHM4rqPWYl9yA-j7mG5TtOw7b02s8rrv4Z7wukdCXWB+LhQeAz16tCwZoFMjonxcntjp682oyHShfy2Hk3GbNzvt6t1bQillLant7lG6xk-l-PsfL-V2O76QWpA-npus4l5lwjszHOFBeBAA
\begin{tikzcd}
T_0    & { 1. \forall x \,(P(x) \lor Q(x))} \arrow[d, "{\gamma, 1}", no head]                                                   &                                                                                 &                                                                                           &                     \\
       & 2. P(c_0) \lor Q(c_0) \arrow[d, "hip(1)", no head]                                                                     &                                                                                 &                                                                                           &                     \\
T_1    & {3. \neg(\forall x \, P(x) \lor \forall x \, Q(x))} \arrow[d, "{\beta,2}", no head] \arrow[rrd, "{\beta, 2}", no head] &                                                                                 &                                                                                           &                     \\
T_2    & 4. P(c_0) \arrow[d, "{\alpha, 3}", no head]                                                                            &                                                                                 & 4. Q(c_0) \arrow[d, "{\alpha, 3}", no head]                                               &                     \\
       & {5. \neg \forall x \, P(x)} \arrow[d, "{\alpha, 3}", no head]                                                          &                                                                                 & {5. \neg \forall x\, P(x) } \arrow[d, "{\alpha, 3}", no head]                             &                     \\
T_3    & {6. \neg \forall x \, Q(x)} \arrow[d, "{\delta, 5}", no head]                                                          &                                                                                 & {6. \neg \forall x \, Q(x)} \arrow[d, "{\delta, 5}", no head]                             &                     \\
       & 7. \neg P(c_1) \arrow[d, "{\gamma, 1}", no head]                                                                       &                                                                                 & 7. \neg P(c_2) \arrow[d, "{\gamma, 1}", no head]                                          &                     \\
T_5    & 8. P(c_1) \lor Q(c_1) \arrow[d, "{\delta, 6}", no head]                                                                &                                                                                 & 8. P(c_2) \lor Q(c_2) \arrow[d, "{\delta, 6}", no head]                                   &                     \\
       & 9. \neg Q(c_3) \arrow[d, "{\gamma, 1}", no head]                                                                       &                                                                                 & 9. \neg Q(c_4) \arrow[d, "{\gamma, 1}", no head]                                          &                     \\
T_6    & 10. P(c_3) \lor Q(c_3) \arrow[d, "{\beta, 8}", no head] \arrow[rd, "{\beta, 8}", no head]                              &                                                                                 & 10. P(c_4) \lor Q(c_4) \arrow[d, "{\beta, 8}", no head] \arrow[rd, "{\beta, 8}", no head] &                     \\
T_8    & { 11. P(c_1) \#7, 11}                                                                                                  & 11.Q(c_1) \arrow[ld, "{\beta, 10}"', no head] \arrow[d, "{\beta, 10}", no head] & 11. Q(c_2) \arrow[d, "{\beta, 10}", no head] \arrow[rd, "{\beta, 10}", no head]           & {11. P(c_2)\#7, 11} \\
T_{10} & 12. P(c_3)                                                                                                             & {12. Q(c_3)\#9, 12}                                                             & {12. Q(c_4)\#9, 12}                                                                       & 12. P(c_4)         
\end{tikzcd}
\end{comment}

Comenzamos con la construcción:
\begin{itemize}
    \item $T_0$
    Inicializamos el \textit{tableau} con la primera fórmula de $\Phi$, $\varphi_0$. En el algoritmo completo tendríamos que tener el primer axioma de igualdad, pero como dijimos en la introducción vamos a omitirlos para simplificar.
    \item $T_1$
    \begin{itemize}
        \item \textbf{ABSD}$(T_0,1)$ No hay ninguna fórmula $\alpha,\beta,\sigma$ o $\delta$ que desarrollar a altura 1, de modo que seguimos.
        \item \textbf{G}($T_1^1$) Tenemos una fórmula $\gamma$ a altura $\leq 1$: $\varphi_0$. Como vamos a ir numerando las $\gamma$-fórmulas sobre la marcha, esta será la fórmula $\gamma_0$. Ahora buscamos términos adecuados para $\Gamma_r$. Sin embargo, vemos que no hay variables libres ni símbolos de constante en $\Gamma_r$, por tanto no se puede construir ningún término adecuado para $\Gamma_r$. Como no hay términos adecuados, usaremos la primera constante auxiliar, $c_0$. De modo que añadimos la fórmula $\gamma_0(c_0)$, que es $P(c_0)\lor Q(c_0)$.
        \item \textbf{EF}($T_1^2,1$) Añadimos la segunda fórmula de $\Phi$, $\varphi_1$. Como ya no quedan más fórmulas en $\Phi$ y no estamos usando axiomas de igualdad, no nos hará falta volver a usar la regla \textbf{EF} a partir de ahora.
    \end{itemize}
    Habiendo aplicado todas las reglas, ya tenemos el \textit{tableau} $T_1$. Comenzamos la siguiente fase para extender el \textit{tableau} a $T_2$.
    \item $T_2$
    \begin{itemize}
        \item \textbf{ABSD}$(T_1,2)$ Tenemos una $\beta$-fórmula en altura 2, $P(c_0)\lor Q(c_0)$. Por tanto, le aplicamos la regla $\beta$, dividiendo así el \textit{tableau} en dos ramas, $r_1$, con la fórmula $P(c_0)$, y $r_2$, con la fórmula $Q(c_0)$.
        \item \textbf{G}($T_2^1$) Como ya tenemos una constante, ya tenemos algún término adecuado: $c_0$. Ahora, la única $\gamma$-fórmula a altura $\leq2$ es $\varphi_0=\gamma_0$, pero ya hemos aplicado la regla a esa fórmula con el único término adecuado, $c_0$. Por tanto no añadimos nada en la regla \textbf{G}. Queda completado el \textit{tableau} $T_2$.
    \end{itemize}
    \item $T_3$
    \begin{itemize}
        \item \textbf{ABSD}$(T_2,1)$ En las ramas $r_1$ y $r_2$ tenemos en altura 3 la $\alpha$-fórmula, $\neg(\forall x \, P(x) \lor \forall x \, Q(x))$. Por tanto aplicamos la $\alpha$-fórmula en ambas ramas, añadiendo las fórmulas $\neg\forall x\, P(x)$ y $\neg\forall x\, Q(x)$.
        \item \textbf{G}($T_3^1$) Se da la misma situación que al construir $T_2$, no añadimos fórmulas en la regla \textbf{G}.
    \end{itemize}
    \item $T_4$
    \begin{itemize}
        \item \textbf{ABSD}$(T_3,4)$ No hay fórmulas $\alpha,\beta,\gamma,\delta$ a altura $4$ no extendidas.
        \item \textbf{G}($T_4^1$) Igual que antes no añadimos fórmulas en la regla \textbf{G}.
    \end{itemize}
    Como podemos observar, en el \textit{tableau} $T_4$ no hemos añadido ninguna fórmula nueva. Eso no significa que hayamos acabado, ya que quedan fórmulas a profundidad $>4$. Como tenemos fórmulas de altura hasta 6, tendríamos que llegar a $T_6$ sin ningún cambio para concluir que ya tenemos el \textit{tableau} canónico. Pero veremos que ese no es el caso.
    \item $T_5$
    \begin{itemize}
        \item \textbf{ABSD}$(T_4,5)$ En $r_1$ y $r_2$ tenemos a altura 5 la $\delta$-fórmula $\neg\forall x \, P(x)$. Por tanto, en $r_1$ añadimos la fórmula sustituyendo la primera constante auxiliar que no hemos usado, $c_1$. Es decir, prolongamos $r_1$ con la fórmula $\neg P(c_1)$. Ahora, en $r_2$, usamos la primera constante auxiliar que no habíamos usado hasta ahora, $c_2$, por tanto añadimos a la rama la fórmula $\neg P(c_2)$.\\
        \item \textbf{G}($T_5^1$) Seguimos teniendo una sola fórmula $\gamma$ a altura $\leq5$, que es $\gamma_0=\varphi_0$.\\[5pt]
        Al extender la rama $r_1$, hemos aumentado su vocabulario con un símbolo de constante nuevo: $c_1$. Por tanto tenemos un nuevo término, $c_1$. Como $\gamma_0(c_1)$ no está en $r_1$, añadimos $\gamma_0(c_1)=P(c_1)\lor Q(c_1)$ a $r_1$.\\[5pt]
        En $r_2$, análogamente a $r_1$, tenemos el nuevo término $c_2$, por tanto añadimos $\gamma_0(c_2)=P(c_2)\lor Q(c_2)$.
    \end{itemize}
    \item $T_6$
    \begin{itemize}
        \item \textbf{ABSD}$(T_5,6)$ Hay una $\delta$-fórmula a altura 6 que extender en cada rama, $\neg\forall x\,Q(x)$. Razonando como en $T_5$, a la rama $r_1$ le añadimos la fórmula $\neg Q(c_3)$ y a $r_2$ le añadimos la fórmula $\neg Q(c_4)$.
        \item \textbf{G}($T_6^1$) Igual que hicimos en $T_5$, $\gamma_0$ sigue siendo nuestra única $\gamma$-fórmula, y tenemos los nuevos términos $c_3$ y $c_4$ en $r_1$ y $r_2$ respectivamente, por tanto añadimos a $r_1$ la fórmula $\gamma_0(c_3)$ y añadimos a $r_2$ $\gamma_0(c_4)$.
    \end{itemize}
    \item $T_7$
    \begin{itemize}
        \item \textbf{ABSD}$(T_7,8)$ Ninguna fórmula que extender a altura 7.
        \item \textbf{G}($T_8^1$) De nuevo, en ambas ramas hemos agotado el vocabulario y ya no nos quedan términos adecuados que aplicar a $\gamma_0$, por tanto no añadimos ninguna fórmula.
    \end{itemize}
    \item $T_8$
    \begin{itemize}
        \item \textbf{ABSD}$(T_7,8)$ En $r_1$, tenemos una $\beta$-fórmula a altura 8, $P(c_1)\lor Q(c_1)$. De modo que obtenemos dos nuevas ramas. La de la izquierda, que se forma añadiendo $P(c_1)$, es una rama cerrada ya que contiene las fórmulas $P(c_1)$ y $\neg P(c_1)$. La de la derecha se forma añadiendo $Q(c_1)$.\\[5pt]
        En $r_2$, de igual forma, aplicamos la regla $\beta$ obteniendo dos ramas, una de las cuales se forma añadiendo $Q(c_2)$. La otra se forma añadiendo $P(c_2)$ y queda cerrada al contener a $P(c_2)$ y $\neg P(c_2)$.
        \item \textbf{G}($T_8^1$)Igual que en $T_7$, no añadimos nada.
    \end{itemize}
    \item $T_9$
    Al igual que en $T_4$ y $T_7$, ninguna de las reglas añade ninguna fórmula.
    \item $T_{10}$
    \begin{itemize}
        \item \textbf{ABSD}$(T_9,10)$ En la rama de la izquierda, aplicamos la regla $\beta$ a $P(c_3)\lor Q(c_3)$, obteniendo dos ramas. Una de ellas queda cerrada por contener a $Q(c_3)$ y a $\neg Q(c_3)$. En la rama de la derecha hay una situación similar.
        \item \textbf{G}($T_{10}^1$) Ninguna nueva $\gamma$-fórmula ni vocabulario nuevo en ninguna rama.
    \end{itemize}
    \item $T_{11}$ Ninguna regla añade nada nuevo.
    \item $T_{12}$ De nuevo, ninguna regla añade nada nuevo.\\[5pt]
    Sin embargo, nuestro \textit{tableaux} no tiene fórmulas a altura $>12$. Como además se cumple que $T_{11}=T_{12}$, hemos acabado y ya tenemos nuestro \textit{tableau} canónico.
\end{itemize}

Pues bien, ya tenemos el \textit{tableau} canónico asociado a $\Phi$. Nos quedan dos ramas abiertas. Llamamos al conjunto de fórmulas de la rama abierta de la izquierda $\Phi_1$ y al conjunto de fórmulas de la rama abierta de la derecha $\Phi_2$. Pues bien, como las ramas son abiertas en el \textit{tableau} canónico, $\Phi_1$ y $\Phi_2$ son de Hintikka. Por tanto, conforme a lo visto en la subsección \ref{Hinti33}, podemos crear modelos que satisfacen $\Phi_1$ y $\Phi_2$. Comenzamos con $\Phi_1$.\\[10pt]

En $\Phi_1$, los únicos símbolos de constante o variable que aparecen son $c_0,c_1$ y $c_3$. Como no hay símbolos de función, estos son nuestros únicos términos. Además, como no han aparecido igualdades en el \textit{tableau}, el conjunto soporte coincidirá con el conjunto de términos. Por tanto tenemos nuestro conjunto soporte:
\[T=\{c_0,c_1,c_3\}\]
Ahora, en esta rama solo tenemos dos predicados, $P$ y $Q$, ambos predicados $1$-arios. Para ver cuáles son sus interpretaciones, recordemos que dado un término $t$, definimos $P(t)=V$ si y solo si $P(t)$ aparece en la rama. Por tanto, $P$ será el conjunto de términos tales que $P(t)$ aparece en la rama. Las apariciones de $P$ en la rama son $P(c_0)$ en altura 4 y $P(c_3)$ en altura 12, por tanto:
\[P=\{c_0,c_3\}\]
De igual forma, la única aparición de $Q$ en la rama es $Q(c_1)$ en altura 11, por tanto:
\[Q=\{c_1\}\]\\[10pt]

El caso de $\Phi_2$ es similar al de $\Phi_1$. El conjunto soporte coincide con el conjunto de términos, en este caso como solo aparecen $c_0,c_2,c_4$:
\[T=\{c_0,c_2,c_4\}\]
Y $P$ solo aparece como $P(c_4)$, por tanto $P=\{c_4\}$.
$Q$ aparece como $Q(c_0)$ y $Q(c_2)$, por tanto $Q=\{c_0,c_2\}$.